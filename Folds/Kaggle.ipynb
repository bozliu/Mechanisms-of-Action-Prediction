{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n",
      "gcc (GCC) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check nvcc version\n",
    "!nvcc -V\n",
    "# check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 10 14:18:23 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| 33%   55C    P2   242W / 260W |  13905MiB / 45553MiB |     73%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     On   | 00000000:5E:00.0 Off |                    0 |\n",
      "| 33%   20C    P8    10W / 260W |      0MiB / 45553MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| 33%   20C    P8    11W / 260W |      0MiB / 45553MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:D8:00.0 Off |                    0 |\n",
      "| 33%   51C    P2   228W / 260W |   9657MiB / 45553MiB |     86%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0    128292      C   python3                                    13893MiB |\n",
      "|    3    127755      C   python3                                     9645MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lbz/ML\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atp-sensitive_potassium_channel_antagonist      1\n",
       "erbb2_inhibitor                                 1\n",
       "diuretic                                        6\n",
       "autotaxin_inhibitor                             6\n",
       "protein_phosphatase_inhibitor                   6\n",
       "                                             ... \n",
       "serotonin_receptor_antagonist                 404\n",
       "dopamine_receptor_antagonist                  424\n",
       "cyclooxygenase_inhibitor                      435\n",
       "proteasome_inhibitor                          726\n",
       "nfkb_inhibitor                                832\n",
       "Length: 206, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored.sum()[1:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trt_cp', 'ctl_vehicle'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['cp_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA features + Existing features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 50\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 15\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature Selection using Variance Encoding¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>917</th>\n",
       "      <th>918</th>\n",
       "      <th>919</th>\n",
       "      <th>920</th>\n",
       "      <th>921</th>\n",
       "      <th>922</th>\n",
       "      <th>923</th>\n",
       "      <th>924</th>\n",
       "      <th>925</th>\n",
       "      <th>926</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450285</td>\n",
       "      <td>-0.176778</td>\n",
       "      <td>-1.262943</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>-0.890670</td>\n",
       "      <td>0.393604</td>\n",
       "      <td>-0.703376</td>\n",
       "      <td>-0.615139</td>\n",
       "      <td>0.174407</td>\n",
       "      <td>0.082941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.429385</td>\n",
       "      <td>-0.226422</td>\n",
       "      <td>0.271831</td>\n",
       "      <td>0.863835</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.669397</td>\n",
       "      <td>0.447651</td>\n",
       "      <td>1.207365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115802</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>-0.212644</td>\n",
       "      <td>-0.902482</td>\n",
       "      <td>-0.118799</td>\n",
       "      <td>-0.336548</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.572233</td>\n",
       "      <td>-0.261651</td>\n",
       "      <td>-0.638141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590366</td>\n",
       "      <td>0.698760</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.147857</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>-1.433683</td>\n",
       "      <td>1.323147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.287454</td>\n",
       "      <td>-0.110246</td>\n",
       "      <td>-0.105291</td>\n",
       "      <td>-0.396913</td>\n",
       "      <td>0.090983</td>\n",
       "      <td>-0.211590</td>\n",
       "      <td>0.350304</td>\n",
       "      <td>-0.326626</td>\n",
       "      <td>-0.344389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492270</td>\n",
       "      <td>0.802396</td>\n",
       "      <td>0.332499</td>\n",
       "      <td>-0.204876</td>\n",
       "      <td>0.238577</td>\n",
       "      <td>-0.483204</td>\n",
       "      <td>0.585078</td>\n",
       "      <td>0.173586</td>\n",
       "      <td>-0.611718</td>\n",
       "      <td>1.607084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.364079</td>\n",
       "      <td>-0.375444</td>\n",
       "      <td>-1.433534</td>\n",
       "      <td>-0.858483</td>\n",
       "      <td>1.072457</td>\n",
       "      <td>0.101450</td>\n",
       "      <td>0.435098</td>\n",
       "      <td>-0.219500</td>\n",
       "      <td>0.377156</td>\n",
       "      <td>0.555680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511130</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>-0.166686</td>\n",
       "      <td>-0.458886</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>0.292592</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>0.081750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.129357</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>0.302835</td>\n",
       "      <td>0.776086</td>\n",
       "      <td>-1.737516</td>\n",
       "      <td>-0.531532</td>\n",
       "      <td>-0.351892</td>\n",
       "      <td>0.542268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.549881</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>1.124858</td>\n",
       "      <td>2.358549</td>\n",
       "      <td>4.598061</td>\n",
       "      <td>0.405195</td>\n",
       "      <td>0.448931</td>\n",
       "      <td>3.509945</td>\n",
       "      <td>1.710206</td>\n",
       "      <td>-2.434251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 931 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose       0       1       2  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...     ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "            3       4       5  ...       917       918       919       920  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ... -0.450285 -0.176778 -1.262943  0.219107   \n",
       "1      0.0604  1.0190  0.5207  ...  0.063234  0.658824  0.429385 -0.226422   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.115802  0.726273 -0.212644 -0.902482   \n",
       "3      0.5288  4.0620 -0.8095  ...  0.590366  0.698760  0.050321 -0.793301   \n",
       "4      0.6919  1.4180 -0.8244  ... -0.000223 -0.287454 -0.110246 -0.105291   \n",
       "...       ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ... -0.492270  0.802396  0.332499 -0.204876   \n",
       "23810  0.9905 -0.7178  0.6621  ... -1.364079 -0.375444 -1.433534 -0.858483   \n",
       "23811 -0.7389  0.5505 -0.0159  ... -0.511130 -0.035609 -0.310135 -0.166686   \n",
       "23812  0.2044  0.8531 -0.0343  ... -1.129357  0.020524 -0.043233 -0.440007   \n",
       "23813  0.7952 -0.3611 -3.6750  ...  3.549881  0.367554  1.124858  2.358549   \n",
       "\n",
       "            921       922       923       924       925       926  \n",
       "0     -0.890670  0.393604 -0.703376 -0.615139  0.174407  0.082941  \n",
       "1      0.271831  0.863835  0.003597  0.669397  0.447651  1.207365  \n",
       "2     -0.118799 -0.336548  0.015536  0.572233 -0.261651 -0.638141  \n",
       "3      0.295411  0.147857  0.056161  0.689218 -1.433683  1.323147  \n",
       "4     -0.396913  0.090983 -0.211590  0.350304 -0.326626 -0.344389  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "23809  0.238577 -0.483204  0.585078  0.173586 -0.611718  1.607084  \n",
       "23810  1.072457  0.101450  0.435098 -0.219500  0.377156  0.555680  \n",
       "23811 -0.458886 -0.003948  0.292592  0.331622 -0.006669  0.081750  \n",
       "23812  0.302835  0.776086 -1.737516 -0.531532 -0.351892  0.542268  \n",
       "23813  4.598061  0.405195  0.448931  3.509945  1.710206 -2.434251  \n",
       "\n",
       "[23814 rows x 931 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.5)\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose       0       1       2       3       4  \\\n",
       "0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "            5       6  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0     -1.0120 -1.0220  ...                                      0   \n",
       "1      0.5207  0.2341  ...                                      0   \n",
       "2      1.2390  0.1715  ...                                      0   \n",
       "3     -0.8095 -1.9590  ...                                      0   \n",
       "4     -0.8244 -0.2800  ...                                      0   \n",
       "...       ...     ...  ...                                    ...   \n",
       "21943  0.4256 -0.1166  ...                                      0   \n",
       "21944  0.7201  0.5773  ...                                      0   \n",
       "21945  0.6621 -0.2252  ...                                      0   \n",
       "21946 -0.0343  0.0323  ...                                      0   \n",
       "21947 -3.6750 -1.2420  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "21943             0                0                  0   \n",
       "21944             0                0                  0   \n",
       "21945             0                0                  0   \n",
       "21946             0                0                  0   \n",
       "21947             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "21943                          0                                      0   \n",
       "21944                          0                                      0   \n",
       "21945                          0                                      0   \n",
       "21946                          0                                      0   \n",
       "21947                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "21943                0          0                           0              0  \n",
       "21944                0          0                           0              0  \n",
       "21945                0          0                           0              0  \n",
       "21946                0          0                           0              0  \n",
       "21947                0          0                           0              0  \n",
       "\n",
       "[21948 rows x 1136 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning\n",
    "# for col in GENES:\n",
    "#     train.loc[:, f'{col}_bin'] = pd.cut(train[col], bins=3, labels=False)\n",
    "#     test.loc[:, f'{col}_bin'] = pd.cut(test[col], bins=3, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution plots\n",
    "# plt.figure(figsize=(16,16))\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# gene_choice = np.random.choice(len(GENES), 16)\n",
    "# for i, col in enumerate(gene_choice):\n",
    "#     plt.subplot(4, 4, i+1)\n",
    "#     plt.hist(train_features.loc[:, GENES[col]],bins=100, color='orange')\n",
    "#     plt.title(GENES[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Naive] Outlier Removal¶\n",
    "# train_ = train.copy() [Didn't wanted to actually normalize, so created a copy and normalized that for further calculation]\n",
    "# for col in GENES:\n",
    "    \n",
    "# #     train_[col] = (train[col]-np.mean(train[col])) / (np.std(train[col]))\n",
    "    \n",
    "#     mean = train_[col].mean()\n",
    "#     std = train_[col].std()\n",
    "\n",
    "#     std_r = mean + 4*std\n",
    "#     std_l = mean - 4*std\n",
    "\n",
    "#     drop = train_[col][(train_[col]>std_r) | (train_[col]<std_l)].index.values\n",
    "\n",
    "# train = train.drop(drop).reset_index(drop=True)\n",
    "# # folds = folds.drop(drop).reset_index(drop=True)\n",
    "# target = target.drop(drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose       0       1       2       3       4  \\\n",
       "0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "            5       6  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0     -1.0120 -1.0220  ...             0                0                  0   \n",
       "1      0.5207  0.2341  ...             0                0                  0   \n",
       "2      1.2390  0.1715  ...             0                0                  0   \n",
       "3     -0.8095 -1.9590  ...             0                0                  0   \n",
       "4     -0.8244 -0.2800  ...             0                0                  0   \n",
       "...       ...     ...  ...           ...              ...                ...   \n",
       "21943  0.4256 -0.1166  ...             0                0                  0   \n",
       "21944  0.7201  0.5773  ...             0                0                  0   \n",
       "21945  0.6621 -0.2252  ...             0                0                  0   \n",
       "21946 -0.0343  0.0323  ...             0                0                  0   \n",
       "21947 -3.6750 -1.2420  ...             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "21943                          0                                      0   \n",
       "21944                          0                                      0   \n",
       "21945                          0                                      0   \n",
       "21946                          0                                      0   \n",
       "21947                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                    0          0                           0              0   \n",
       "1                    0          0                           0              0   \n",
       "2                    0          0                           0              0   \n",
       "3                    0          0                           0              0   \n",
       "4                    0          0                           0              0   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943                0          0                           0              0   \n",
       "21944                0          0                           0              0   \n",
       "21945                0          0                           0              0   \n",
       "21946                0          0                           0              0   \n",
       "21947                0          0                           0              0   \n",
       "\n",
       "       kfold  \n",
       "0          0  \n",
       "1          2  \n",
       "2          1  \n",
       "3          2  \n",
       "4          2  \n",
       "...      ...  \n",
       "21943      0  \n",
       "21944      4  \n",
       "21945      0  \n",
       "21946      1  \n",
       "21947      2  \n",
       "\n",
       "[21948 rows x 1137 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1136)\n",
      "(21948, 1137)\n",
      "(3624, 930)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single fold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.5443700503126003\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.03568510147077697\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023244795254499153\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02035433878856046\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.019910719556113083\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01823332668947322\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01868445028051518\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017551363365990776\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01799021893437358\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017370463082832948\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.01758874756405535\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017232250182756356\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01751608162632455\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017093399566199097\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017356589726725782\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017017428390681745\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017436791218115366\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017046274989843367\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017337836095712322\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017071520829839367\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017295910430181284\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017033423536590167\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017329049843322973\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016845661215484142\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01723279893749218\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01691862653408732\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017104352918871933\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016774639167955945\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017035044122325337\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01683932337909937\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.016905949235070442\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016702707431146078\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.016856773513490738\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016623270298753465\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01669725858727875\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016467533367020743\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.01648807148381636\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016310549314532963\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016235781273386186\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016242332756519318\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01599764508748616\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016200611261384827\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.015712004802797153\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016039697080850603\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.015488143774100405\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01601471451244184\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.015286829511540524\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.015977833765958037\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015222032453216936\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01596787603838103\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5439458492927361\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03564135240656989\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.024057482490720955\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020317334096346583\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020000352740179802\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01841514419232096\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018734806777396494\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017858830094337464\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018050490966255682\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01759019611137254\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017705842191218468\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017119028020117964\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017483954803775185\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017053369006940298\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017397453792501186\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017190669051238467\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01735653833526632\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017036846226879527\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01735869659434842\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01722363962658814\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017327544670821964\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017320077706660542\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01730035234620606\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017184998547392232\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01730657594980321\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016988799481519632\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017189363699298407\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016954726273460046\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017072218382542116\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016871981748512812\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01701139370519398\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.016722145756440505\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.016882919058527634\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01666032150387764\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.016681403454825067\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016528799464660033\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01646535628326777\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01641501220209258\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01616822461179201\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016322019988937037\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01595690214763517\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016292849741876125\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01574722722010768\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01614846241261278\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.015475744752726261\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016086447185703685\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.015286861959358921\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01606978468064751\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.01520808276625863\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01609874540673835\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5422669140541035\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.03300049352858748\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02467287870366936\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020114181669695037\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.019998882843208485\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018449818582407067\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018702849070878998\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01778891483055694\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018178283351648977\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017398690112999507\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017673340673301962\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017279492504894734\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017468297881060753\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017649934706943374\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017417684798061415\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017069068790546486\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017296998349922724\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017034002207219602\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01739294882323863\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017090146456445965\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01731055304138125\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.016933641955256463\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01733649161684772\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.016876939444669656\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017218289545912674\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.016979569595839294\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017144051441193922\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01691830176860094\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017081637576600348\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016833770009023804\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.0170226507631225\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016754877008497714\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.016851973045023456\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01667051932641438\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.016640927696573563\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016456639473991733\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01642379871286128\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016398118622601033\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016221405465857708\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016238263249397276\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.015961799588378355\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016080607606896332\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.015764688364351572\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.015969234891235827\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.015453642774103344\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.015976286466632572\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.01529586181530486\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.015917473073516573\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.015236435579540937\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.015890213288366796\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5426301360670207\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.033836303651332854\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023601997171299183\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020181180483528547\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020027017234352188\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018632255388157708\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018620421576813078\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017995570440377508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 4, train_loss: 0.017925005460130997\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01764894774449723\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01759953796863556\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017380821172680173\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017458208384451227\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017402460346264498\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017422814239356398\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017321541027298996\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017293883096156776\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017337085918656417\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017392934158282435\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017390202145491328\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017363358673680086\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01727876527501004\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017347375457377537\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017128254739301546\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01727951333547632\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017154736018606596\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017142583764549614\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017154492411230293\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.016993500177573034\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01702424753457308\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.016922080335949642\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016865803860127926\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01684646852368462\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01683345293360097\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.0166810458202077\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01666294088853257\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.01645985147173422\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016588706789272174\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016258561781243137\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01641629072172301\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01603162435112872\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016377591554607662\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01580694621509832\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016256095788308552\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015510544997464487\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016203927754291466\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.015319975261724945\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016173163508730274\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015259509123321892\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016204638912209444\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5415689355383316\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.03333793516669955\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.023992010756679203\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020389841390507563\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.020088068722490814\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01839259604790381\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.0187661267236631\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017680240316050394\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018058721765713846\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017397923022508623\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.0177070879701363\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017252409271895884\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017468511444125055\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017092829942703246\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017388111736247505\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01716399719672544\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017410683317406885\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017324553962264743\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017302941638922344\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017116436042955943\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01738284439172434\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017007006092795304\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01734702751391392\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016952029562422206\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017254397192079086\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017077200966221947\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017224516719579697\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01682301727788789\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01710261763545914\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016787148054156986\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01698430909005844\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016639442395951068\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.016879544546152803\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016622262900429112\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.016682589062206123\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016554563253053597\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01644261317678552\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016261030946459087\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.016303770966233984\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016212044310356888\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01601709550300586\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01609543899872473\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.015733841509706734\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.015971064647393566\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.015482309740036726\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01587173326739243\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.015309747868635948\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.015907580219209193\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.015262526777181505\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.015896731428802012\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5456733586455601\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.04161456610475268\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.024171648155627907\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.020027153353605952\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020094787904425808\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018296856699245318\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.018683339320663093\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017626643633203848\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.017982947849331125\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017352822396372047\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.01768506194829293\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01721170882561377\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01745132154420666\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017066778295806478\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017413807013814432\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017091628882501805\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017393364017640335\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017051929607987404\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017352579944375633\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01702569614031485\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01737499796528963\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017121636840913976\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01738548170829165\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01700074542313814\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017286983433355024\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.016985427348741464\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017107277022053797\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016939156901623523\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017135642097750002\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016828387949083534\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01702272396642661\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016725294957203523\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.016815273259914873\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016584892411317144\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.016640730647613174\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016484340918915614\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.016486613599556513\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01643766619797264\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01619306441558444\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01625574462647949\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.0159512922451224\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016162193060985635\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.015742728689118572\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016086025323186603\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01548323966562748\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016001921785729272\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.015330541008354528\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.015963377164942876\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015221692054815914\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.015969159746808664\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.540889870159436\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.0374725127858775\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.023613403092367924\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02010175484631743\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.019813244231045246\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018350004138691086\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018816111136929714\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01779441335903747\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.017987825577079817\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017479786729174\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017658627207350473\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017162523631538664\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017445172237205334\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01709714132760252\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017339243634563427\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01741055694541761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 8, train_loss: 0.017343123733619417\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017261562496423723\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017470213922037594\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017129539618534702\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01739181028139116\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01719156511660133\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01730385766891034\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01707800121179649\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017271595683110798\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016939546327505793\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017244966477965532\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017027182132005693\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01715591472938009\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01685487138373511\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.016955674349235884\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01680022225316082\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01686697063859606\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01665883588471583\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.016762978154356064\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.0165233025593417\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.016531968286827854\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016456306938614162\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016295750888631395\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01644221203667777\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.016034728064593197\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016279958241752216\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.015799372780906117\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016161520513040678\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.015576128213517908\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01616197151264974\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.015391454033121683\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016101436370185445\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.0153165719728323\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016088030540517398\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.542610665621317\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.036841429557119096\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.023649014073653496\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01985044702887535\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020032708222667377\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018507388606667518\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018646541746684175\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01778247438903366\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.01809283789328259\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.01730745304375887\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017687889214173174\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01723918616771698\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017437476570299572\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.01720255490924631\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.01742594830178912\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017016236244567804\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01747184352733303\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017134953715971537\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01737629514241564\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01718881210046155\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017330188351426867\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017138675414025785\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017324357536499916\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01700721893991743\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017291489772606587\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017126269106354033\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017231535031527714\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017018276319972107\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017129190583321928\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016810194243277822\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.0169533492754335\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01678787964795317\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01690201837218542\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016581628578049797\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01673373899868001\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016565845906734468\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01644296450810372\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016398472046213492\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016332360733624384\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.0162260859140328\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016054778089881806\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01617400539772851\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.015800142276060324\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01603333151766232\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.01554565801811607\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.015978525712021758\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.015383848448054514\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01595499866775104\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.015256678098407776\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.015942682858024325\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5429555743770755\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.03655918570501464\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023947096915672653\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.02028343411428588\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020040851288839527\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.0188559176666396\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018645155635001003\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018562009132334165\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.01808503126401616\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017653998945440563\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017654673081647226\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017403563910296984\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017331450097802757\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01731816405164344\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01744299080978701\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01720511072448322\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017349879412601393\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017113053399537292\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017249995059725166\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017241815929966313\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017277142761842064\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017289001521255287\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01724655789228669\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017201831537697998\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.0171912119899323\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017178030737808773\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017264931773145992\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017033491390092033\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017115112812514755\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017128675537449973\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.0169378445227293\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01685046282197748\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.016794620824140915\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01678211952426604\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.016645702810121187\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016671272314020564\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.016370627887385046\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01659374705382756\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016210716022043558\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016435193243835654\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01592878544487167\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016364427256797043\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01571291338895326\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016219468148691314\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015483669693703237\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01619336461382253\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.015255147294289824\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016155693493783475\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.01519618406081977\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01615306240107332\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5428279670684234\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.034942405138696946\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.023785045100510983\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02053209144089903\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02008798684708882\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018664702640048096\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.018788434261375147\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017927878004099642\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01798254443143589\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017517603188753127\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017643907593320244\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017308380481387886\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01750192872882969\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017116658868534224\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017472802060723738\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017358753697148392\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017469116425870554\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017125016903238637\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01737420766384921\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017150766695184366\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01741938335497094\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017184303355004107\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017366776816492926\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017046528575675828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 12, train_loss: 0.017327120709840372\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017042480488973003\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017330871915201777\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016985270673675196\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017136776603866314\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01680439311478819\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01701876907136993\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016832211879747254\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.016972970015004925\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01655214476798262\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.016805244812174984\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016512043428208147\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01655671655780811\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01640384008309671\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.016357804263901453\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016225773548441274\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016059895626444748\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016123654320836067\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.015803599237477865\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016034226598484174\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.015564045970044706\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.015959546874676434\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.015483064489250166\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01590957519199167\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01534457485852898\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.0159007603302598\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.544213892136147\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.03287189757185323\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023260102418345818\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02091805333537715\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.0200692145086393\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01830181452844824\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.018797912823873154\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017734926087515694\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01803800639817896\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01732010705662625\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017670402843235195\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017198267153331212\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017499364791033062\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017126046280775752\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017503496077235624\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01727917508355209\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017445566800787397\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017208934708365372\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017322920067100855\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017053741802062306\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.0173249710958613\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017164153765354837\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017301653228376224\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016977653705648015\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01731645496076216\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.017030454347176212\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017230005678383335\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01690180024930409\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01710781495532264\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016789435382400242\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01697332493663914\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016787132514374598\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.016859011414150398\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016608933385993754\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01665174791697359\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016474667377769946\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.016445997029380953\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016402640220310006\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016272558850924605\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016364628874829836\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.015964402425764263\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01613774975495679\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01571804689972297\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016101368756166527\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.015545409105286219\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016070192280624594\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.015314990134936745\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01597719027527741\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015212357840568258\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.015970057328896864\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5431122962601375\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03610237517527171\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.023783483245558498\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.019893069033111846\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.019839495096517647\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018587281767811093\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018623985410870417\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.0180098739319614\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018044922818038343\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017550697390522275\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017604998967515818\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01747045328042337\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017383472629539345\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01709248051047325\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017335616018407156\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017252123834831375\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01741701914537428\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017197005823254584\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01737493898152657\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.016954676088477883\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017398374357625195\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017164378267313752\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017398578303771606\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01703538264014891\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017290285397051037\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017015202290245463\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017315954766303734\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017078666096287113\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017185451165921448\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017016394755670003\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017051913903729208\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.016829679480620793\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01691390099543808\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01674129015633038\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.016747439030449892\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016554134977715355\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01650719514683537\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016442984395793506\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01625143265540617\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016393382900527546\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01607241185274029\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016218360061092035\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01578844643022487\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016141447797417642\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.015573602966100409\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016114673524030617\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.015446876141958046\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016076334326394968\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.015311718803654978\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016077906558556215\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5427071995547285\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.0319805130894695\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02332147684596155\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020558311524135727\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020063241619778717\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01824687708701406\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018659783581244774\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017640548092978343\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.01805059394488732\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017274139262735844\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017736883462825113\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017112836108676026\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017529675554808066\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017174932839615003\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017478478465067303\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01707099817161049\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017489058316509792\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017097307182848454\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017430782507079235\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017223318559782846\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017311470947511818\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017157301918736528\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01737659481232581\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01705102752894163\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017312269448640123\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017021123905267034\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.01722929036865632\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01693431484912123\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01713392677028542\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016834356795464245\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017022865534206663\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016748866545302526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 16, train_loss: 0.01689943252806214\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01659290875707354\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.016716132973037336\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016600101893501622\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.016563245999640312\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01636561727417367\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01626570352042715\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016266629498984133\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016070854634154533\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016160460880824498\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.015766880454738504\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016037146959986006\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.015552471567323242\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016020450847489494\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.015412844683759022\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.015998252507831368\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.015267864409564198\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.015945755770163876\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5439582876861095\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.03270205818116665\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02389100604299186\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020262409214462554\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020112374986427418\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01880829163960048\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.01878851299862499\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01780672576278448\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018017733712559162\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01769778659301145\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01762215725645639\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017439653458339827\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017481809326757986\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017394518878843104\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017444338602270338\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017288157530128957\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01739200634503926\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01724737278584923\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01742416916523075\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017214558672692094\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01733473688364029\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017185668407806328\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01725141741200418\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017257119183029447\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017221589059825394\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017468678898044994\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.01734297128016318\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01708230756755386\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01705975400661861\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016895771585404874\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.016971942739210266\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016960964484938553\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01682052378664198\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016979075861828667\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.016708647818777008\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01666371396609715\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.016488985819877056\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.0166535741516522\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01624647680454064\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016455322849963393\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01595363322564441\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01635247069810118\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.015745170819370644\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01625038396034922\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015473563912446085\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016192709654569627\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.015308296193193266\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01615073438733816\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015228968660306671\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016187322113130773\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5412975052452605\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.03508006940994944\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02392812309435744\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02019527671592576\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.019962198735363243\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01901277309017522\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01863058316318885\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.0176825933690582\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.017918159159413284\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.0172880851530603\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.01764160916344195\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01723488409604345\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017606650870563328\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017162447688835007\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017435068460316328\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01708428697394473\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.01742165399364371\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017200198263994285\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01737345087652405\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01724919102021626\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01742118528868625\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017066066499267306\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01740446373604346\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01714254011000906\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017334777875331\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.016995173799140114\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017293605130111824\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016926093851881367\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017184718525496082\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016716699355414935\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017018788325451853\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.0167716651356646\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.0169553915106192\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016557345246630054\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.016679838191771854\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016524430178105832\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.016464529619754656\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01642224338970014\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.016233384507991697\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016316615949784008\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016015497596421534\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016122908384672233\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.015815384638752195\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.015998208496187414\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.015522536767673666\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01597852028374161\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.015352484365196331\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01595519727894238\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.015261519099653198\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01590684867863144\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5444007328023082\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.033028403084192956\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023379801232637703\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.01996839280639376\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.01983790002439333\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018357354721852712\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01868977507684326\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.01762226354330778\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01809455174277874\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017267800202327117\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017653839574937803\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01716147174260446\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01748092577158325\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017014702648988793\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01736388061924473\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017092329503170082\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01733236186935202\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017087348497339658\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017334628168601488\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017070411145687102\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01726437789266524\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01712696464466197\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017313977473995823\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016950593489621368\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017170338776718447\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.016949084480958325\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017139728046089844\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01691796641264643\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017123291532144598\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016771671947624002\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.016917747357671244\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016680035367608072\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.016798372096989467\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016688170842826366\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.016675456474278715\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.0164652659956898\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.01641823377703195\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016404622394059386\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01618980459086057\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016288094728120737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 20, train_loss: 0.015982115222816017\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01614499618964536\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01570065414694988\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.01604251497026001\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01539474224968665\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016033572676990713\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01528168271255234\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.015975603567702428\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015232374500213326\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.015954404936305115\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5431977039122063\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03615496318255152\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.023613340788237427\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020053368274654662\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020040924917312637\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.0184962909668684\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.01869696517056529\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017737968399056368\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.01799754021635306\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01733901532632964\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017675016858223556\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017294282067034927\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017424374251909878\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01710616299616439\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017367407450101513\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017096575322960106\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01729516491320902\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017137950605579783\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017393167643551376\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017132669713880333\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017364255948991016\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01698381890143667\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.0173676833105476\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.016900173681122916\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017285037731778793\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.0169473902455398\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01719544475655193\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016847362129815985\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01712013702110752\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016787710865693434\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01697268565117881\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01679024270602635\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01686639776048453\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016797194044504846\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.016721835177715704\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016519205511680672\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.016482203375494133\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016443047326590333\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016188650783421337\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01630682892033032\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01604350262146065\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016231183840760163\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.015778176904912445\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01619987365390573\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.015495327517282272\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01611497505967106\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.015332957054825796\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01610504146665335\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.015282077215395975\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016081317833491735\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5437751741189024\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.03315373573984418\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.023960406352104485\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020217564223068103\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020026695509643658\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018703054689935276\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018690335388848747\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017667587846517563\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.01800211032420613\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.01732139148350273\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01771810894454087\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017511692084372043\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017457109761248896\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017321998200246266\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017388563555921766\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017249249321009432\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01741056527564491\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017134571341531617\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01737982279661557\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017210676148533822\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017297578982306994\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017166394075112685\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017287973280780126\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01686887911387852\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017218335518154545\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.016986706161073277\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017192068955172665\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.016832412273756096\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017105770182620356\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01681727594030755\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01698466980208953\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016792556297566208\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01689519419375321\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016618543969733373\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.016677506099306585\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016562446313244956\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.016485902784473223\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016402009315788744\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016262829101280026\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016177916207483836\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.015956208676747654\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01616303412509816\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.015773017627551504\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016017870897693295\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.015537407228966122\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01598451334450926\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.015362994650891726\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01594550463237933\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.015280026625301958\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.015895111060568266\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.544197778986848\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.03215467376368386\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023642199329923893\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020918518677353858\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.01984907623272443\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018811327325446266\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.01861039116519733\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01780962771070855\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018009218421049307\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017604556333805834\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017563106417925894\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01726598289928266\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017367757040251425\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01728336787117379\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01740427382722281\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017407433662031378\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017390585302010826\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01730599185185773\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017398106278446707\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01731699516198465\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01731918014558977\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01721392124891281\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01728590971290849\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01721115168184042\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017212628305930157\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01703522769468171\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017184149858582277\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017111479278121677\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017043507138294153\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016998164781502314\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.016984446770579056\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016922577896288465\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01676619906599323\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016793205136699334\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.016622262500712404\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016715249073292526\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.016453196679282446\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016542760974594523\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01618407544531468\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016509118250438146\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.015905808967848618\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016353819306407655\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01571522479660917\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016248700954020024\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015472733712606672\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016203279394124234\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.015307031970039226\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01619094695363726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 24, train_loss: 0.015142982994354721\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016215516626834868\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5450632183178179\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.033255747705698016\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.0235478019044883\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020098195225000382\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.01999609199339065\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01835161048386778\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01868024141109292\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017774244397878648\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.017977584470603346\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01746804945703064\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.01765168292204971\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01722448045121772\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017456843821412844\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01712947924222265\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017478533541324778\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017085024608033045\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017373373509263216\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017227999892617973\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01740708863497644\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01712480237973588\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01735947420820594\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01711448199514832\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017374722806709833\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016972286200949125\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01730313988240517\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01694476678967476\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01715137412690598\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016829247852521285\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01709970498484546\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016772094448762282\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017073397787854723\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016647243393318994\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01696728153721146\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016584267493869577\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01680163761762821\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016550337895751\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.016511134695315708\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016352946417672293\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01632330742786112\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016262587452573436\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01607523334172109\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016117688215204647\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01587796722120349\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016042218756462848\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.015623195069855537\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.015979131204741343\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01544341378831777\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01594964454748801\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.015352389026109291\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.015962378068694046\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5438213253906672\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.035840887682778495\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023807860816410488\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.021112689801624843\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020075683805929577\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018258417025208473\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01869447465878034\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.01781831349113158\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.017943035662714123\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017393548733421735\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017636997571242027\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017106721018041882\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01739580730867127\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.0171817347407341\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017382426835272625\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017000445909798146\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01734871388939412\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016991060173937252\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017259785743511242\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017063190255846294\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017331463797692803\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01699780659484012\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017276833259055147\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01696051891360964\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017305191700765186\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01683321576565504\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01716924690897914\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017012814192899635\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017114104028197304\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01679552524749722\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017010286119699045\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016710699402860234\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01683226641456502\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016624196512358528\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.016620662043114073\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016500091100377697\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.016452621155674908\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016347210694636616\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01621022218487401\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01622032645557608\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01594117434317435\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01619647352823189\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.015705966640371775\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.015992680431476662\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.015451048635810182\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016017038029219423\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.015343278018838686\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.015981609054974148\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015257708944272304\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.015941673144698142\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5429801710651837\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.035925427398511345\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02401270150490429\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02202952823468617\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020604967720050743\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018684667348861695\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018935474749330595\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017892011787210192\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018310511309275593\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017898925739739623\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017836799872094307\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017341932068978036\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017722144594712965\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017312118969857692\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01751867485354128\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01722827340875353\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017423729736195957\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017102222996098655\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01740989583692905\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017137247776346547\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017320611311689667\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01703492599938597\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017333012803093246\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017058717858578477\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01718974508939014\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017135050067944187\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017171471352702465\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01692567981247391\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017059387578426496\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01688465896461691\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01695597931013807\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.0167632772986378\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01681390497158619\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016607745311089925\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01664122346572686\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016529541329613755\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01649451527096655\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01655645330569574\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016289369594575703\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016329016909003256\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.0160598352794414\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016240492835640906\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.0157790363671771\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016135133749672344\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.015490978983217392\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016105912359697477\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.015348095082394455\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016067776908831936\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.015229957542665627\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016076081964586462\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5429038898884386\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.03603068206991468\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.023844121685386566\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020279359977160183\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020122148305771574\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018515012785792352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 3, train_loss: 0.0187435038185314\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01771478575787374\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018032736003236925\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017356336223227638\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01770238182844891\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017265079436557633\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017511540963112013\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017198951755251202\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017419401461771435\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017113622490848815\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017379848657688803\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01709895051483597\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01744803008151011\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017165878335280077\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017418364150638597\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017148912884294987\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017413903830869906\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.016967016804431165\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01730260394675576\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.016894455812871457\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017220920937108822\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.016814805407609257\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017057586663767048\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016872850326555115\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017002587719563988\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016729920517121043\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.016815112728247608\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.0166214275306889\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.016709644421665133\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01644814293831587\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.016523105868448813\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01636090770895992\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016236311418638714\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016263862858925546\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.015992083445029413\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016108222944395883\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01573378289712296\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016040422474699362\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.015558424021076897\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01600905329521213\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.01537760629899044\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01594421922096184\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.015250698062658741\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01593846614871706\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5406196635702382\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.03224062089409147\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02375025420949079\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.02078054579240935\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.019950722722147686\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018530938934002605\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018638890466072422\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017905844801238604\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.017940672694880894\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017860597717974866\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01756071135320741\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.0174198966473341\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017545215812498245\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01738679730998618\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017363928541865036\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01716012042015791\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01738119388566069\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017335361428558828\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017412933217280584\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017309430800378323\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017403044913342033\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017290172992008072\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017291433900000826\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017128669443939412\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017296294270056314\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01717301585844585\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017188562802376524\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017111035622656347\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017112275943214048\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016957739953483854\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01698310078675116\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016822440150593008\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01682931549874121\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016893889382481576\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.016661601519023163\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016767373095665658\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.016508918734726267\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01664704427655254\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016286738534066557\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01647355061556612\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01600159995554798\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016389968671969006\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01574951695089323\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016277891690177577\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015489215598158215\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016217141146106378\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.015323374541881292\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01619092220706599\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015292481991691866\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016197750956884454\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5418359417252351\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.0401309959590435\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.023573145081383595\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02061485493821757\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.019881703836870365\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018504779732653073\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01866807302703028\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01767297208841358\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018083823284647173\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01742565759590694\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.0176832623158892\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01733138207346201\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017451918258777132\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017209906237465995\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.01740812736333928\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017054980780397144\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.0174318499242266\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01709537777517523\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01750285160201399\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01708761083760432\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01735951497718908\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.016944687334554537\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017397140618413687\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016962008976510592\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01733957954506943\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017020069621503355\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017200932851520138\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016870419840727534\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017216153166162363\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016865036503544876\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01705163499961297\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016738593764603137\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.016938348975626454\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016626052664858955\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.016771207205897223\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016512488068214485\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01650703180770295\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01635306536086968\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.016261430821664955\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01616349071264267\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016100723235665457\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016116641621504512\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.015800705807202536\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016059717402926513\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.015617239282237015\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01594586955117328\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.015425140982952671\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.015941045992076398\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.015331699647873209\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.015928051913423197\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5427268350199945\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.03504463796104704\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023472870821538178\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02042170539498329\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.019984884956932587\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.0188390312982457\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01867008302360773\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017667470233780996\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.017966115557035242\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017426625532763345\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017625273137852764\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01719266612614904\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017382921664503174\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.0171619552852852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 7, train_loss: 0.01745099469722397\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01718003446502345\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017384537050257557\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017146074399352073\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017378464030722778\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017005011386104992\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01734553419890395\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017063785743500506\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01738146605456005\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016972185165754387\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01726998638469672\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.017069742163377147\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01716839997232824\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017163482893790518\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017145884688943624\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01688227863716228\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01695431390291323\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01666050689028842\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.016806445307219805\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016596296642507825\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.016659208357442116\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016459479555487634\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.016454415753537763\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016410672345331737\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016222417597537456\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016285402780132633\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01602205627368412\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016154755013329643\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01575149869735258\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016040691866406373\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.015459132981419132\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01597406462367092\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.015341752944379181\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.0159663693181106\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015248603416957718\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.015985516645014287\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5439881019402242\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03292102191065039\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02403708541954773\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020427960636360303\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.019944471145129723\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.0184881185314485\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018777886344848768\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01777114320014204\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.017973123435470938\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017506284852113044\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.01772460197031066\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017509409306304794\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017450938709890066\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017190941503005368\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017407437415280634\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017334018328360148\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01744883339447172\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017020626073437076\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017340472838638918\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017134760825761725\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01744566001402943\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01715231875755957\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01729640644043684\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.0171056652707713\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01727233745454662\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.0169452590867877\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01716363664878451\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016926836674766882\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01705018914156202\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01691373437643051\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.016993744582261727\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01686664218349116\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.0168224414675564\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01667328394417252\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.016670403340696426\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016617866312818867\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01641902972039753\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01642186710877078\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016212772719724024\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016364266483911444\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.015969817627869223\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01632347915853773\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01565830456767825\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016200052042092596\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.015483378250475811\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016106981996979033\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.015300929917535488\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016092840688569206\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.015221056541886883\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01605857312679291\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5452893596358489\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.03728079998067447\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.023448888819826687\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020258847464408192\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.01977214491183775\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01832904562886272\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018759167058042425\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01780882150466953\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.01809753941210068\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017228979910058635\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017663755474369162\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017152485331254345\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017524567824127018\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017106016193117413\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017347227053149887\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01714689287223986\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.0174133795907424\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017256537079811098\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01742753534294341\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01716791678752218\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01737283255931908\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017151639850011894\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017263365626011207\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017150845990649293\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01729425563193534\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01690754209245954\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017228213908231777\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.016943535528012685\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017171620411555403\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016861201689711638\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01702746596403312\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016625685271407876\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01687731018181944\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01658403335937432\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01671117770930995\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016481856549424783\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.016458845265425633\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016386839960302626\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016254866090805634\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016206275512065205\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016020526637093746\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.0161314794793725\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01575649815166126\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.015995076751070363\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.015533529660677996\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.015954072613801273\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.015372407980317223\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.015878695010074547\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.015322395148214655\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01589741933026484\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5434507519762585\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.03233167225761073\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023541893081172653\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020892381934182986\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.019788903872603954\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018352505511471204\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018643530828041443\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018471218539135796\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.0181087300626804\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017534833614315307\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01754491795124351\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017198199033737184\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017362398601582518\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017455334163137843\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017327987440470337\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017341817409864495\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017298743891381266\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01723894410367523\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017379396095655968\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01715150557990585\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017280982753288918\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017147813364863394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 11, train_loss: 0.017286503032875666\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017236891841249807\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017189651545461104\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01716938064034496\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017089010722449293\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01714643726923636\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017095137751944687\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01695208695850202\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.016944064056851726\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.0169090743043593\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.016806757415010445\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016844423008816584\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.016637554621674877\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016652442674551692\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.01644166861323343\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016567788299705302\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01619405388508154\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01648238655179739\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.015956269590643005\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016323982684739998\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.015647770357790632\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01626364618007626\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015440990217030048\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016217333690396376\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.015318314038702974\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016188390819089755\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015185135902593965\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01620901929480689\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5428409219004106\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.035356555559805464\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.024132335909466812\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020573241423283303\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.020438322095551353\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018659409880638123\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.018865724019976198\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.018521265046937126\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018224800019052582\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01761386383857046\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.01790029073026085\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01742111902151789\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01764258567540758\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017184420063027315\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017436853454758722\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01701250871909516\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017416234425120594\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017119662782975605\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01738169272362754\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017178903546716487\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017372104582255302\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017045368227575505\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01725534162065689\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016945705403174673\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017180980729830007\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.0169382618740201\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017066241518688807\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016768155992031096\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017000943408820076\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01676007208547422\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.016942703394570213\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016665256103234632\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01677420426942948\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01654454969934055\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.016557103441353294\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01642009046460901\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.016351705835457298\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01632769445755652\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01608310616912617\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016158618325633662\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.015883415147824133\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01610708295234612\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01567444403021448\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01596602142921516\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01536411999900272\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01594994491232293\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.015185296947163517\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01591269980583872\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.015071540733502396\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.015878863579460552\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.optim.lr_scheduler #import OneCycleLR\n",
    "SEED = [0, 1, 2, 3 ,4, 5]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014655359766323124\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 207)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
