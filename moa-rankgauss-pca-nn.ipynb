{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:18.317739Z",
     "iopub.status.busy": "2020-11-16T03:53:18.316836Z",
     "iopub.status.idle": "2020-11-16T03:53:18.322306Z",
     "shell.execute_reply": "2020-11-16T03:53:18.321800Z"
    },
    "papermill": {
     "duration": 0.040083,
     "end_time": "2020-11-16T03:53:18.322406",
     "exception": false,
     "start_time": "2020-11-16T03:53:18.282323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:18.381412Z",
     "iopub.status.busy": "2020-11-16T03:53:18.380384Z",
     "iopub.status.idle": "2020-11-16T03:53:19.395741Z",
     "shell.execute_reply": "2020-11-16T03:53:19.394565Z"
    },
    "papermill": {
     "duration": 1.045265,
     "end_time": "2020-11-16T03:53:19.395876",
     "exception": false,
     "start_time": "2020-11-16T03:53:18.350611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install iterative-stratification\n",
    "\"\"\"This file includes multilabel cross validators based on an implementation of\n",
    "the Iterative Stratification algorithm described in the following paper:\n",
    "Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of Multi-\n",
    "Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M. (eds)\n",
    "Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2011. Lecture\n",
    "Notes in Computer Science, vol 6913. Springer, Berlin, Heidelberg.\n",
    "From scikit-learn 0.19.0, StratifiedKFold, RepeatedStratifiedKFold, and\n",
    "StratifiedShuffleSplit were copied and modified, retaining compatibility\n",
    "with scikit-learn.\n",
    "Attribution to authors of scikit-learn/model_selection/_split.py under BSD 3 clause:\n",
    "    Alexandre Gramfort <alexandre.gramfort@inria.fr>,\n",
    "    Gael Varoquaux <gael.varoquaux@normalesup.org>,\n",
    "    Olivier Grisel <olivier.grisel@ensta.org>,\n",
    "    Raghav RV <rvraghav93@gmail.com>\n",
    "\"\"\"\n",
    "\n",
    "# Author: Trent J. Bradberry <trentjason@hotmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, \\\n",
    "    BaseShuffleSplit, _validate_shuffle_split\n",
    "\n",
    "\n",
    "def IterativeStratification(labels, r, random_state):\n",
    "    \"\"\"This function implements the Iterative Stratification algorithm described\n",
    "    in the following paper:\n",
    "    Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of\n",
    "    Multi-Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M.\n",
    "    (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n",
    "    2011. Lecture Notes in Computer Science, vol 6913. Springer, Berlin,\n",
    "    Heidelberg.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = labels.shape[0]\n",
    "    test_folds = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    # Calculate the desired number of examples at each subset\n",
    "    c_folds = r * n_samples\n",
    "\n",
    "    # Calculate the desired number of examples of each label at each subset\n",
    "    c_folds_labels = np.outer(r, labels.sum(axis=0))\n",
    "\n",
    "    labels_not_processed_mask = np.ones(n_samples, dtype=bool)\n",
    "\n",
    "    while np.any(labels_not_processed_mask):\n",
    "        # Find the label with the fewest (but at least one) remaining examples,\n",
    "        # breaking ties randomly\n",
    "        num_labels = labels[labels_not_processed_mask].sum(axis=0)\n",
    "\n",
    "        # Handle case where only all-zero labels are left by distributing\n",
    "        # across all folds as evenly as possible (not in original algorithm but\n",
    "        # mentioned in the text). (By handling this case separately, some\n",
    "        # code redundancy is introduced; however, this approach allows for\n",
    "        # decreased execution time when there are a relatively large number\n",
    "        # of all-zero labels.)\n",
    "        if num_labels.sum() == 0:\n",
    "            sample_idxs = np.where(labels_not_processed_mask)[0]\n",
    "\n",
    "            for sample_idx in sample_idxs:\n",
    "                fold_idx = np.where(c_folds == c_folds.max())[0]\n",
    "\n",
    "                if fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(fold_idx.shape[0])]\n",
    "\n",
    "                test_folds[sample_idx] = fold_idx\n",
    "                c_folds[fold_idx] -= 1\n",
    "\n",
    "            break\n",
    "\n",
    "        label_idx = np.where(num_labels == num_labels[np.nonzero(num_labels)].min())[0]\n",
    "        if label_idx.shape[0] > 1:\n",
    "            label_idx = label_idx[random_state.choice(label_idx.shape[0])]\n",
    "\n",
    "        sample_idxs = np.where(np.logical_and(labels[:, label_idx].flatten(), labels_not_processed_mask))[0]\n",
    "\n",
    "        for sample_idx in sample_idxs:\n",
    "            # Find the subset(s) with the largest number of desired examples\n",
    "            # for this label, breaking ties by considering the largest number\n",
    "            # of desired examples, breaking further ties randomly\n",
    "            label_folds = c_folds_labels[:, label_idx]\n",
    "            fold_idx = np.where(label_folds == label_folds.max())[0]\n",
    "\n",
    "            if fold_idx.shape[0] > 1:\n",
    "                temp_fold_idx = np.where(c_folds[fold_idx] ==\n",
    "                                         c_folds[fold_idx].max())[0]\n",
    "                fold_idx = fold_idx[temp_fold_idx]\n",
    "\n",
    "                if temp_fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(temp_fold_idx.shape[0])]\n",
    "\n",
    "            test_folds[sample_idx] = fold_idx\n",
    "            labels_not_processed_mask[sample_idx] = False\n",
    "\n",
    "            # Update desired number of examples\n",
    "            c_folds_labels[fold_idx, labels[sample_idx]] -= 1\n",
    "            c_folds[fold_idx] -= 1\n",
    "\n",
    "    return test_folds\n",
    "\n",
    "\n",
    "class MultilabelStratifiedKFold(_BaseKFold):\n",
    "    \"\"\"Multilabel stratified K-Folds cross-validator\n",
    "    Provides train/test indices to split multilabel data into train/test sets.\n",
    "    This cross-validation object is a variation of KFold that returns\n",
    "    stratified folds for multilabel data. The folds are made by preserving\n",
    "    the percentage of samples for each label.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle each stratification of the data before splitting\n",
    "        into batches.\n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedKFold that only uses random_state\n",
    "        when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n",
    "    >>> mskf.get_n_splits(X, y)\n",
    "    2\n",
    "    >>> print(mskf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=False)\n",
    "    >>> for train_index, test_index in mskf.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different in each fold.\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedMultilabelStratifiedKFold: Repeats Multilabel Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=3, shuffle=False, random_state=None):\n",
    "        super(MultilabelStratifiedKFold, self).__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def _make_test_folds(self, X, y):\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(type_of_target_y))\n",
    "\n",
    "        num_samples = y.shape[0]\n",
    "\n",
    "        rng = check_random_state(self.random_state)\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng.shuffle(indices)\n",
    "            y = y[indices]\n",
    "\n",
    "        r = np.asarray([1 / self.n_splits] * self.n_splits)\n",
    "\n",
    "        test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "        return test_folds[np.argsort(indices)]\n",
    "\n",
    "    def _iter_test_masks(self, X=None, y=None, groups=None):\n",
    "        test_folds = self._make_test_folds(X, y)\n",
    "        for i in range(self.n_splits):\n",
    "            yield test_folds == i\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedKFold, self).split(X, y, groups)\n",
    "\n",
    "\n",
    "class RepeatedMultilabelStratifiedKFold(_RepeatedSplits):\n",
    "    \"\"\"Repeated Multilabel Stratified K-Fold cross validator.\n",
    "    Repeats Mulilabel Stratified K-Fold n times with different randomization\n",
    "    in each repetition.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "    n_repeats : int, default=10\n",
    "        Number of times cross-validator needs to be repeated.\n",
    "    random_state : None, int or RandomState, default=None\n",
    "        Random state to be used to generate random state for each\n",
    "        repetition as well as randomly breaking ties within the iterative\n",
    "        stratification algorithm.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> rmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2,\n",
    "    ...     random_state=0)\n",
    "    >>> for train_index, test_index in rmskf.split(X, y):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    ...\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [0 1 4 5] TEST: [2 3 6 7]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedStratifiedKFold: Repeats (Non-multilabel) Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n",
    "        super(RepeatedMultilabelStratifiedKFold, self).__init__(\n",
    "            MultilabelStratifiedKFold, n_repeats=n_repeats, random_state=random_state,\n",
    "            n_splits=n_splits)\n",
    "\n",
    "\n",
    "class MultilabelStratifiedShuffleSplit(BaseShuffleSplit):\n",
    "    \"\"\"Multilabel Stratified ShuffleSplit cross-validator\n",
    "    Provides train/test indices to split data into train/test sets.\n",
    "    This cross-validation object is a merge of MultilabelStratifiedKFold and\n",
    "    ShuffleSplit, which returns stratified randomized folds for multilabel\n",
    "    data. The folds are made by preserving the percentage of each label.\n",
    "    Note: like the ShuffleSplit strategy, multilabel stratified random splits\n",
    "    do not guarantee that all folds will be different, although this is\n",
    "    still very likely for sizeable datasets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default 10\n",
    "        Number of re-shuffling & splitting iterations.\n",
    "    test_size : float, int, None, optional\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the test split. If int, represents the\n",
    "        absolute number of test samples. If None, the value is set to the\n",
    "        complement of the train size. By default, the value is set to 0.1.\n",
    "        The default will change in version 0.21. It will remain 0.1 only\n",
    "        if ``train_size`` is unspecified, otherwise it will complement\n",
    "        the specified ``train_size``.\n",
    "    train_size : float, int, or None, default is None\n",
    "        If float, should be between 0.0 and 1.0 and represent the\n",
    "        proportion of the dataset to include in the train split. If\n",
    "        int, represents the absolute number of train samples. If None,\n",
    "        the value is automatically set to the complement of the test size.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedShuffleSplit that only uses\n",
    "        random_state when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> msss = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5,\n",
    "    ...    random_state=0)\n",
    "    >>> msss.get_n_splits(X, y)\n",
    "    3\n",
    "    >>> print(mss)       # doctest: +ELLIPSIS\n",
    "    MultilabelStratifiedShuffleSplit(n_splits=3, random_state=0, test_size=0.5,\n",
    "                                     train_size=None)\n",
    "    >>> for train_index, test_index in msss.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    TRAIN: [1 2 5 6] TEST: [0 3 4 7]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different from desired due to the\n",
    "    preference of stratification over perfectly sized folds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=10, test_size=\"default\", train_size=None,\n",
    "                 random_state=None):\n",
    "        super(MultilabelStratifiedShuffleSplit, self).__init__(\n",
    "            n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups=None):\n",
    "        n_samples = _num_samples(X)\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(\n",
    "                    type_of_target_y))\n",
    "\n",
    "        n_train, n_test = _validate_shuffle_split(n_samples, self.test_size,\n",
    "                                                  self.train_size)\n",
    "\n",
    "        n_samples = y.shape[0]\n",
    "        rng = check_random_state(self.random_state)\n",
    "        y_orig = y.copy()\n",
    "\n",
    "        r = np.array([n_train, n_test]) / (n_train + n_test)\n",
    "\n",
    "        for _ in range(self.n_splits):\n",
    "            indices = np.arange(n_samples)\n",
    "            rng.shuffle(indices)\n",
    "            y = y_orig[indices]\n",
    "\n",
    "            test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "            test_idx = test_folds[np.argsort(indices)] == 1\n",
    "            test = np.where(test_idx)[0]\n",
    "            train = np.where(~test_idx)[0]\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedShuffleSplit, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027038,
     "end_time": "2020-11-16T03:53:19.450897",
     "exception": false,
     "start_time": "2020-11-16T03:53:19.423859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. RankGauss_PCA_FS_NN with Drug_Multilabel_CV_FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:19.515740Z",
     "iopub.status.busy": "2020-11-16T03:53:19.514962Z",
     "iopub.status.idle": "2020-11-16T03:53:23.714625Z",
     "shell.execute_reply": "2020-11-16T03:53:23.713824Z"
    },
    "papermill": {
     "duration": 4.237127,
     "end_time": "2020-11-16T03:53:23.714769",
     "exception": false,
     "start_time": "2020-11-16T03:53:19.477642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:23.779655Z",
     "iopub.status.busy": "2020-11-16T03:53:23.778496Z",
     "iopub.status.idle": "2020-11-16T03:53:30.058636Z",
     "shell.execute_reply": "2020-11-16T03:53:30.059819Z"
    },
    "papermill": {
     "duration": 6.317196,
     "end_time": "2020-11-16T03:53:30.059988",
     "exception": false,
     "start_time": "2020-11-16T03:53:23.742792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 100\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n",
    "\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "print(len(GENES), len(CELLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:30.122647Z",
     "iopub.status.busy": "2020-11-16T03:53:30.120894Z",
     "iopub.status.idle": "2020-11-16T03:53:30.123304Z",
     "shell.execute_reply": "2020-11-16T03:53:30.123774Z"
    },
    "papermill": {
     "duration": 0.036545,
     "end_time": "2020-11-16T03:53:30.123885",
     "exception": false,
     "start_time": "2020-11-16T03:53:30.087340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:30.184937Z",
     "iopub.status.busy": "2020-11-16T03:53:30.184101Z",
     "iopub.status.idle": "2020-11-16T03:53:30.189084Z",
     "shell.execute_reply": "2020-11-16T03:53:30.188536Z"
    },
    "papermill": {
     "duration": 0.037333,
     "end_time": "2020-11-16T03:53:30.189195",
     "exception": false,
     "start_time": "2020-11-16T03:53:30.151862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_comp_GENES 463 n_comp_CELLS 60 total 523\n"
     ]
    }
   ],
   "source": [
    "n_comp_GENES = 463\n",
    "n_comp_CELLS = 60\n",
    "VarianceThreshold_for_FS = 0.9\n",
    "Dropout_Model = 0.25\n",
    "#QT_n_quantile_min=50, \n",
    "#QT_n_quantile_max=1000,\n",
    "print('n_comp_GENES', n_comp_GENES, 'n_comp_CELLS', n_comp_CELLS, 'total', n_comp_GENES + n_comp_CELLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028306,
     "end_time": "2020-11-16T03:53:30.245261",
     "exception": false,
     "start_time": "2020-11-16T03:53:30.216955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### RankGauss¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:30.304752Z",
     "iopub.status.busy": "2020-11-16T03:53:30.304162Z",
     "iopub.status.idle": "2020-11-16T03:53:30.308118Z",
     "shell.execute_reply": "2020-11-16T03:53:30.307638Z"
    },
    "papermill": {
     "duration": 0.035082,
     "end_time": "2020-11-16T03:53:30.308247",
     "exception": false,
     "start_time": "2020-11-16T03:53:30.273165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Search for minimum and maximum values\n",
    "# # df_kurt = pd.DataFrame(columns=['col','train', 'test'])\n",
    "# # i = 0\n",
    "# # for col in (GENES + CELLS):\n",
    "# #     df_kurt.loc[i, 'col'] = col\n",
    "# #     df_kurt.loc[i, 'train'] = kurtosis(train_features[col])\n",
    "# #     df_kurt.loc[i, 'test'] = kurtosis(test_features[col])\n",
    "# #     i += 1\n",
    "# # print(df_kurt.min())\n",
    "# # print(df_kurt.max())\n",
    "\n",
    "# def calc_QT_par_kurt(QT_n_quantile_min=10, QT_n_quantile_max=200):\n",
    "#     # Calculation parameters of function: n_quantile(kurtosis) = k1*kurtosis + k0\n",
    "#     # For Train & Test datasets (GENES + CELLS features): minimum kurtosis = 1.53655, maximum kurtosis = 30.4929\n",
    "    \n",
    "#     a = np.array([[1.53655,1], [30.4929,1]])\n",
    "#     b = np.array([QT_n_quantile_min, QT_n_quantile_max])\n",
    "    \n",
    "#     return np.linalg.solve(a, b)\n",
    "\n",
    "# def n_quantile_for_kurt(kurt, calc_QT_par_kurt_transform):\n",
    "#     # Calculation parameters of function: n_quantile(kurtosis) = calc_QT_par_kurt_transform[0]*kurtosis + calc_QT_par_kurt_transform[1]\n",
    "#     return int(calc_QT_par_kurt_transform[0]*kurt + calc_QT_par_kurt_transform[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:30.377993Z",
     "iopub.status.busy": "2020-11-16T03:53:30.377369Z",
     "iopub.status.idle": "2020-11-16T03:53:39.244649Z",
     "shell.execute_reply": "2020-11-16T03:53:39.244125Z"
    },
    "papermill": {
     "duration": 8.90749,
     "end_time": "2020-11-16T03:53:39.244758",
     "exception": false,
     "start_time": "2020-11-16T03:53:30.337268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410974</td>\n",
       "      <td>0.364819</td>\n",
       "      <td>1.291804</td>\n",
       "      <td>0.835350</td>\n",
       "      <td>-0.240101</td>\n",
       "      <td>1.021706</td>\n",
       "      <td>-0.499652</td>\n",
       "      <td>0.317989</td>\n",
       "      <td>0.545662</td>\n",
       "      <td>0.641339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520372</td>\n",
       "      <td>1.127405</td>\n",
       "      <td>0.716111</td>\n",
       "      <td>0.054620</td>\n",
       "      <td>0.412012</td>\n",
       "      <td>0.744215</td>\n",
       "      <td>0.210242</td>\n",
       "      <td>0.179684</td>\n",
       "      <td>0.919161</td>\n",
       "      <td>1.165833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.828896</td>\n",
       "      <td>-0.740965</td>\n",
       "      <td>0.953239</td>\n",
       "      <td>0.053633</td>\n",
       "      <td>-1.213056</td>\n",
       "      <td>-0.394118</td>\n",
       "      <td>-0.758652</td>\n",
       "      <td>-0.277635</td>\n",
       "      <td>-1.123088</td>\n",
       "      <td>1.089235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.419080</td>\n",
       "      <td>-0.756098</td>\n",
       "      <td>-1.652159</td>\n",
       "      <td>-1.250427</td>\n",
       "      <td>-0.947092</td>\n",
       "      <td>-1.231225</td>\n",
       "      <td>-1.325697</td>\n",
       "      <td>-0.977581</td>\n",
       "      <td>-0.485139</td>\n",
       "      <td>-0.915321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018697</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>1.051051</td>\n",
       "      <td>1.682158</td>\n",
       "      <td>0.796356</td>\n",
       "      <td>-0.378324</td>\n",
       "      <td>0.153519</td>\n",
       "      <td>0.428792</td>\n",
       "      <td>-0.475464</td>\n",
       "      <td>1.119408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277271</td>\n",
       "      <td>0.031834</td>\n",
       "      <td>-0.874312</td>\n",
       "      <td>0.508945</td>\n",
       "      <td>0.772391</td>\n",
       "      <td>-0.402108</td>\n",
       "      <td>0.089794</td>\n",
       "      <td>1.437809</td>\n",
       "      <td>0.782035</td>\n",
       "      <td>0.721611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>0.646365</td>\n",
       "      <td>0.072307</td>\n",
       "      <td>-0.389037</td>\n",
       "      <td>-0.901087</td>\n",
       "      <td>-1.042561</td>\n",
       "      <td>-0.270576</td>\n",
       "      <td>-0.151801</td>\n",
       "      <td>-0.356692</td>\n",
       "      <td>0.566823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.525149</td>\n",
       "      <td>0.631225</td>\n",
       "      <td>0.288173</td>\n",
       "      <td>-1.139968</td>\n",
       "      <td>0.769550</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802650</td>\n",
       "      <td>0.544226</td>\n",
       "      <td>1.168630</td>\n",
       "      <td>0.416970</td>\n",
       "      <td>0.580636</td>\n",
       "      <td>0.996878</td>\n",
       "      <td>0.314929</td>\n",
       "      <td>1.167104</td>\n",
       "      <td>1.020593</td>\n",
       "      <td>0.584393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132408</td>\n",
       "      <td>0.621426</td>\n",
       "      <td>-0.250549</td>\n",
       "      <td>0.228001</td>\n",
       "      <td>2.198247</td>\n",
       "      <td>1.104170</td>\n",
       "      <td>0.239943</td>\n",
       "      <td>1.077975</td>\n",
       "      <td>-0.701998</td>\n",
       "      <td>0.133967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.571641</td>\n",
       "      <td>-1.400249</td>\n",
       "      <td>-1.737165</td>\n",
       "      <td>-1.639028</td>\n",
       "      <td>-1.747229</td>\n",
       "      <td>-1.289910</td>\n",
       "      <td>-1.571384</td>\n",
       "      <td>-0.581703</td>\n",
       "      <td>-1.298407</td>\n",
       "      <td>-1.847225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose       g-0       g-1  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.134849  0.907687   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.119282  0.681738   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.779973  0.946463   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.734910 -0.274641   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.452718 -0.477513   \n",
       "...             ...          ...      ...     ...       ...       ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.209361 -0.022389   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.911021  0.587228   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.525149  0.631225   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.816407  0.417618   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -1.243096  1.567730   \n",
       "\n",
       "            g-2       g-3       g-4       g-5  ...      c-90      c-91  \\\n",
       "0     -0.416385 -0.966814 -0.254723 -1.017473  ...  0.410974  0.364819   \n",
       "1      0.272399  0.080113  1.205169  0.686517  ... -0.520372  1.127405   \n",
       "2      1.425350 -0.132928 -0.006122  1.492493  ... -0.828896 -0.740965   \n",
       "3     -0.438509  0.759097  2.346330 -0.858153  ... -1.419080 -0.756098   \n",
       "4      0.972316  0.970731  1.463427 -0.869555  ...  0.018697  0.002153   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "23809 -0.235888 -0.796989 -0.674009  0.919312  ...  0.277271  0.031834   \n",
       "23810 -0.588417  1.296405 -1.002640  0.850589  ...  0.629200  0.646365   \n",
       "23811  0.288173 -1.139968  0.769550  0.001014  ...  0.802650  0.544226   \n",
       "23812  0.431631  0.300617  1.070346 -0.024189  ... -0.132408  0.621426   \n",
       "23813 -0.269573  1.083636 -0.511235 -2.099634  ... -1.571641 -1.400249   \n",
       "\n",
       "           c-92      c-93      c-94      c-95      c-96      c-97      c-98  \\\n",
       "0      1.291804  0.835350 -0.240101  1.021706 -0.499652  0.317989  0.545662   \n",
       "1      0.716111  0.054620  0.412012  0.744215  0.210242  0.179684  0.919161   \n",
       "2      0.953239  0.053633 -1.213056 -0.394118 -0.758652 -0.277635 -1.123088   \n",
       "3     -1.652159 -1.250427 -0.947092 -1.231225 -1.325697 -0.977581 -0.485139   \n",
       "4      1.051051  1.682158  0.796356 -0.378324  0.153519  0.428792 -0.475464   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23809 -0.874312  0.508945  0.772391 -0.402108  0.089794  1.437809  0.782035   \n",
       "23810  0.072307 -0.389037 -0.901087 -1.042561 -0.270576 -0.151801 -0.356692   \n",
       "23811  1.168630  0.416970  0.580636  0.996878  0.314929  1.167104  1.020593   \n",
       "23812 -0.250549  0.228001  2.198247  1.104170  0.239943  1.077975 -0.701998   \n",
       "23813 -1.737165 -1.639028 -1.747229 -1.289910 -1.571384 -0.581703 -1.298407   \n",
       "\n",
       "           c-99  \n",
       "0      0.641339  \n",
       "1      1.165833  \n",
       "2      1.089235  \n",
       "3     -0.915321  \n",
       "4      1.119408  \n",
       "...         ...  \n",
       "23809  0.721611  \n",
       "23810  0.566823  \n",
       "23811  0.584393  \n",
       "23812  0.133967  \n",
       "23813 -1.847225  \n",
       "\n",
       "[23814 rows x 876 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RankGauss - transform to Gauss\n",
    "\n",
    "for col in (GENES + CELLS):\n",
    "    #kurt = max(kurtosis(train_features[col]), kurtosis(test_features[col]))\n",
    "    #QuantileTransformer_n_quantiles = n_quantile_for_kurt(kurt, calc_QT_par_kurt(QT_n_quantile_min, QT_n_quantile_max))\n",
    "    #transformer = QuantileTransformer(n_quantiles=QuantileTransformer_n_quantiles,random_state=0, output_distribution=\"normal\")\n",
    "    \n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")   # from optimal commit 9\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n",
    "\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:39.362171Z",
     "iopub.status.busy": "2020-11-16T03:53:39.360989Z",
     "iopub.status.idle": "2020-11-16T03:53:41.859635Z",
     "shell.execute_reply": "2020-11-16T03:53:41.860157Z"
    },
    "papermill": {
     "duration": 2.585546,
     "end_time": "2020-11-16T03:53:41.860290",
     "exception": false,
     "start_time": "2020-11-16T03:53:39.274744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.020156</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.013791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032669</td>\n",
       "      <td>-0.046464</td>\n",
       "      <td>-0.016322</td>\n",
       "      <td>-0.057535</td>\n",
       "      <td>-0.060930</td>\n",
       "      <td>-0.008443</td>\n",
       "      <td>-0.046636</td>\n",
       "      <td>-0.008856</td>\n",
       "      <td>-0.012218</td>\n",
       "      <td>-0.002276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.402807</td>\n",
       "      <td>0.993788</td>\n",
       "      <td>0.985891</td>\n",
       "      <td>0.984521</td>\n",
       "      <td>0.986254</td>\n",
       "      <td>0.986489</td>\n",
       "      <td>0.986035</td>\n",
       "      <td>0.983909</td>\n",
       "      <td>0.985789</td>\n",
       "      <td>1.036396</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101037</td>\n",
       "      <td>1.146957</td>\n",
       "      <td>1.043899</td>\n",
       "      <td>1.180349</td>\n",
       "      <td>1.192257</td>\n",
       "      <td>1.016597</td>\n",
       "      <td>1.149248</td>\n",
       "      <td>1.015625</td>\n",
       "      <td>1.027551</td>\n",
       "      <td>0.991200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>-0.674060</td>\n",
       "      <td>-0.674932</td>\n",
       "      <td>-0.674077</td>\n",
       "      <td>-0.673919</td>\n",
       "      <td>-0.673489</td>\n",
       "      <td>-0.674617</td>\n",
       "      <td>-0.674978</td>\n",
       "      <td>-0.674548</td>\n",
       "      <td>-0.674298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.673013</td>\n",
       "      <td>-0.674219</td>\n",
       "      <td>-0.674693</td>\n",
       "      <td>-0.673625</td>\n",
       "      <td>-0.675430</td>\n",
       "      <td>-0.674346</td>\n",
       "      <td>-0.674792</td>\n",
       "      <td>-0.673672</td>\n",
       "      <td>-0.674529</td>\n",
       "      <td>-0.675471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.673632</td>\n",
       "      <td>0.673667</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.672577</td>\n",
       "      <td>0.673751</td>\n",
       "      <td>0.675095</td>\n",
       "      <td>0.675207</td>\n",
       "      <td>0.673704</td>\n",
       "      <td>0.672936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674701</td>\n",
       "      <td>0.674870</td>\n",
       "      <td>0.674531</td>\n",
       "      <td>0.674995</td>\n",
       "      <td>0.674128</td>\n",
       "      <td>0.674368</td>\n",
       "      <td>0.673761</td>\n",
       "      <td>0.674627</td>\n",
       "      <td>0.674523</td>\n",
       "      <td>0.674981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>...</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 873 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cp_time           g-0           g-1           g-2           g-3  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean      48.020156      0.002570      0.000287      0.000456      0.000373   \n",
       "std       19.402807      0.993788      0.985891      0.984521      0.986254   \n",
       "min       24.000000     -5.199338     -5.199338     -5.199338     -5.199338   \n",
       "25%       24.000000     -0.674060     -0.674932     -0.674077     -0.673919   \n",
       "50%       48.000000      0.000332      0.000738      0.000674     -0.001322   \n",
       "75%       72.000000      0.673632      0.673667      0.673961      0.672577   \n",
       "max       72.000000      5.199338      5.199338      5.199338      5.199338   \n",
       "\n",
       "                g-4           g-5           g-6           g-7           g-8  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean      -0.000503     -0.000251      0.000497     -0.000558     -0.013791   \n",
       "std        0.986489      0.986035      0.983909      0.985789      1.036396   \n",
       "min       -5.199338     -5.199338     -5.199338     -5.199338     -5.199338   \n",
       "25%       -0.673489     -0.674617     -0.674978     -0.674548     -0.674298   \n",
       "50%        0.001187      0.001370      0.001920     -0.000736     -0.001887   \n",
       "75%        0.673751      0.675095      0.675207      0.673704      0.672936   \n",
       "max        5.199338      5.199338      5.199338      5.199338      5.199338   \n",
       "\n",
       "       ...          c-90          c-91          c-92          c-93  \\\n",
       "count  ...  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean   ...     -0.032669     -0.046464     -0.016322     -0.057535   \n",
       "std    ...      1.101037      1.146957      1.043899      1.180349   \n",
       "min    ...     -5.199338     -5.199338     -5.199338     -5.199338   \n",
       "25%    ...     -0.673013     -0.674219     -0.674693     -0.673625   \n",
       "50%    ...      0.000193     -0.000055      0.000720      0.001579   \n",
       "75%    ...      0.674701      0.674870      0.674531      0.674995   \n",
       "max    ...      5.199338      5.199338      5.199338      5.199338   \n",
       "\n",
       "               c-94          c-95          c-96          c-97          c-98  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean      -0.060930     -0.008443     -0.046636     -0.008856     -0.012218   \n",
       "std        1.192257      1.016597      1.149248      1.015625      1.027551   \n",
       "min       -5.199338     -5.199338     -5.199338     -5.199338     -5.199338   \n",
       "25%       -0.675430     -0.674346     -0.674792     -0.673672     -0.674529   \n",
       "50%        0.001795      0.000749     -0.000696     -0.000221      0.000891   \n",
       "75%        0.674128      0.674368      0.673761      0.674627      0.674523   \n",
       "max        5.199338      5.199338      5.199338      5.199338      5.199338   \n",
       "\n",
       "               c-99  \n",
       "count  23814.000000  \n",
       "mean      -0.002276  \n",
       "std        0.991200  \n",
       "min       -5.199338  \n",
       "25%       -0.675471  \n",
       "50%        0.001015  \n",
       "75%        0.674981  \n",
       "max        5.199338  \n",
       "\n",
       "[8 rows x 873 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031201,
     "end_time": "2020-11-16T03:53:41.922493",
     "exception": false,
     "start_time": "2020-11-16T03:53:41.891292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### PCA¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:41.998732Z",
     "iopub.status.busy": "2020-11-16T03:53:41.997344Z",
     "iopub.status.idle": "2020-11-16T03:53:50.002891Z",
     "shell.execute_reply": "2020-11-16T03:53:50.003884Z"
    },
    "papermill": {
     "duration": 8.049809,
     "end_time": "2020-11-16T03:53:50.004088",
     "exception": false,
     "start_time": "2020-11-16T03:53:41.954279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES - 772 -> 463\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp_GENES, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\n",
    "\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:50.161247Z",
     "iopub.status.busy": "2020-11-16T03:53:50.160170Z",
     "iopub.status.idle": "2020-11-16T03:53:51.039380Z",
     "shell.execute_reply": "2020-11-16T03:53:51.037708Z"
    },
    "papermill": {
     "duration": 0.936789,
     "end_time": "2020-11-16T03:53:51.039545",
     "exception": false,
     "start_time": "2020-11-16T03:53:50.102756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELLS - 100 -> 60\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp_CELLS, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\n",
    "\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:51.112199Z",
     "iopub.status.busy": "2020-11-16T03:53:51.109947Z",
     "iopub.status.idle": "2020-11-16T03:53:51.153042Z",
     "shell.execute_reply": "2020-11-16T03:53:51.152186Z"
    },
    "papermill": {
     "duration": 0.081909,
     "end_time": "2020-11-16T03:53:51.153164",
     "exception": false,
     "start_time": "2020-11-16T03:53:51.071255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-50</th>\n",
       "      <th>pca_C-51</th>\n",
       "      <th>pca_C-52</th>\n",
       "      <th>pca_C-53</th>\n",
       "      <th>pca_C-54</th>\n",
       "      <th>pca_C-55</th>\n",
       "      <th>pca_C-56</th>\n",
       "      <th>pca_C-57</th>\n",
       "      <th>pca_C-58</th>\n",
       "      <th>pca_C-59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514146</td>\n",
       "      <td>0.727106</td>\n",
       "      <td>0.631370</td>\n",
       "      <td>0.588790</td>\n",
       "      <td>-0.623881</td>\n",
       "      <td>-0.584221</td>\n",
       "      <td>0.139658</td>\n",
       "      <td>-0.748875</td>\n",
       "      <td>-0.090711</td>\n",
       "      <td>0.508949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.439262</td>\n",
       "      <td>0.508808</td>\n",
       "      <td>1.712656</td>\n",
       "      <td>-0.095448</td>\n",
       "      <td>-0.052959</td>\n",
       "      <td>-0.427382</td>\n",
       "      <td>-0.789533</td>\n",
       "      <td>-0.677906</td>\n",
       "      <td>-0.006642</td>\n",
       "      <td>0.581791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491030</td>\n",
       "      <td>0.259354</td>\n",
       "      <td>-0.724947</td>\n",
       "      <td>0.138275</td>\n",
       "      <td>-0.128793</td>\n",
       "      <td>-1.059011</td>\n",
       "      <td>-1.629201</td>\n",
       "      <td>0.177806</td>\n",
       "      <td>-0.776725</td>\n",
       "      <td>-0.204851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545759</td>\n",
       "      <td>0.197091</td>\n",
       "      <td>-0.058694</td>\n",
       "      <td>0.616253</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>0.135783</td>\n",
       "      <td>-0.326965</td>\n",
       "      <td>0.131044</td>\n",
       "      <td>0.061892</td>\n",
       "      <td>-0.054619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774619</td>\n",
       "      <td>0.630446</td>\n",
       "      <td>0.514879</td>\n",
       "      <td>-0.217948</td>\n",
       "      <td>-0.435192</td>\n",
       "      <td>0.350271</td>\n",
       "      <td>-2.249275</td>\n",
       "      <td>-1.029288</td>\n",
       "      <td>0.098284</td>\n",
       "      <td>-0.397215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224994</td>\n",
       "      <td>-1.564986</td>\n",
       "      <td>0.861649</td>\n",
       "      <td>0.791477</td>\n",
       "      <td>-0.099052</td>\n",
       "      <td>-0.107622</td>\n",
       "      <td>-0.391885</td>\n",
       "      <td>-0.041262</td>\n",
       "      <td>-1.079347</td>\n",
       "      <td>-1.271502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181284</td>\n",
       "      <td>0.878467</td>\n",
       "      <td>0.991192</td>\n",
       "      <td>-1.050152</td>\n",
       "      <td>-0.111085</td>\n",
       "      <td>-0.401736</td>\n",
       "      <td>-0.615555</td>\n",
       "      <td>-1.591904</td>\n",
       "      <td>-0.947227</td>\n",
       "      <td>0.453194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.525149</td>\n",
       "      <td>0.631225</td>\n",
       "      <td>0.288173</td>\n",
       "      <td>-1.139968</td>\n",
       "      <td>0.769550</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427199</td>\n",
       "      <td>0.174291</td>\n",
       "      <td>0.790788</td>\n",
       "      <td>-0.510618</td>\n",
       "      <td>0.742410</td>\n",
       "      <td>-0.925307</td>\n",
       "      <td>0.160863</td>\n",
       "      <td>-0.109500</td>\n",
       "      <td>0.123868</td>\n",
       "      <td>-0.297011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>-0.454789</td>\n",
       "      <td>-0.125915</td>\n",
       "      <td>-1.054433</td>\n",
       "      <td>-0.565906</td>\n",
       "      <td>0.724306</td>\n",
       "      <td>0.529664</td>\n",
       "      <td>0.370367</td>\n",
       "      <td>0.804639</td>\n",
       "      <td>-0.122840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097282</td>\n",
       "      <td>0.557285</td>\n",
       "      <td>-0.478856</td>\n",
       "      <td>-0.155787</td>\n",
       "      <td>0.202482</td>\n",
       "      <td>-0.247334</td>\n",
       "      <td>-0.230496</td>\n",
       "      <td>0.199060</td>\n",
       "      <td>0.330461</td>\n",
       "      <td>0.399924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose       g-0       g-1  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.134849  0.907687   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.119282  0.681738   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.779973  0.946463   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.734910 -0.274641   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.452718 -0.477513   \n",
       "...             ...          ...      ...     ...       ...       ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.209361 -0.022389   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.911021  0.587228   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.525149  0.631225   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.816407  0.417618   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -1.243096  1.567730   \n",
       "\n",
       "            g-2       g-3       g-4       g-5  ...  pca_C-50  pca_C-51  \\\n",
       "0     -0.416385 -0.966814 -0.254723 -1.017473  ... -0.514146  0.727106   \n",
       "1      0.272399  0.080113  1.205169  0.686517  ... -1.439262  0.508808   \n",
       "2      1.425350 -0.132928 -0.006122  1.492493  ... -0.491030  0.259354   \n",
       "3     -0.438509  0.759097  2.346330 -0.858153  ...  0.545759  0.197091   \n",
       "4      0.972316  0.970731  1.463427 -0.869555  ...  0.774619  0.630446   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "23809 -0.235888 -0.796989 -0.674009  0.919312  ... -0.224994 -1.564986   \n",
       "23810 -0.588417  1.296405 -1.002640  0.850589  ... -0.181284  0.878467   \n",
       "23811  0.288173 -1.139968  0.769550  0.001014  ...  0.427199  0.174291   \n",
       "23812  0.431631  0.300617  1.070346 -0.024189  ...  0.065973 -0.454789   \n",
       "23813 -0.269573  1.083636 -0.511235 -2.099634  ...  0.097282  0.557285   \n",
       "\n",
       "       pca_C-52  pca_C-53  pca_C-54  pca_C-55  pca_C-56  pca_C-57  pca_C-58  \\\n",
       "0      0.631370  0.588790 -0.623881 -0.584221  0.139658 -0.748875 -0.090711   \n",
       "1      1.712656 -0.095448 -0.052959 -0.427382 -0.789533 -0.677906 -0.006642   \n",
       "2     -0.724947  0.138275 -0.128793 -1.059011 -1.629201  0.177806 -0.776725   \n",
       "3     -0.058694  0.616253 -0.000931  0.135783 -0.326965  0.131044  0.061892   \n",
       "4      0.514879 -0.217948 -0.435192  0.350271 -2.249275 -1.029288  0.098284   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23809  0.861649  0.791477 -0.099052 -0.107622 -0.391885 -0.041262 -1.079347   \n",
       "23810  0.991192 -1.050152 -0.111085 -0.401736 -0.615555 -1.591904 -0.947227   \n",
       "23811  0.790788 -0.510618  0.742410 -0.925307  0.160863 -0.109500  0.123868   \n",
       "23812 -0.125915 -1.054433 -0.565906  0.724306  0.529664  0.370367  0.804639   \n",
       "23813 -0.478856 -0.155787  0.202482 -0.247334 -0.230496  0.199060  0.330461   \n",
       "\n",
       "       pca_C-59  \n",
       "0      0.508949  \n",
       "1      0.581791  \n",
       "2     -0.204851  \n",
       "3     -0.054619  \n",
       "4     -0.397215  \n",
       "...         ...  \n",
       "23809 -1.271502  \n",
       "23810  0.453194  \n",
       "23811 -0.297011  \n",
       "23812 -0.122840  \n",
       "23813  0.399924  \n",
       "\n",
       "[23814 rows x 1399 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030773,
     "end_time": "2020-11-16T03:53:51.221882",
     "exception": false,
     "start_time": "2020-11-16T03:53:51.191109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection using Variance Encoding¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:51.294599Z",
     "iopub.status.busy": "2020-11-16T03:53:51.293365Z",
     "iopub.status.idle": "2020-11-16T03:53:52.232769Z",
     "shell.execute_reply": "2020-11-16T03:53:52.231641Z"
    },
    "papermill": {
     "duration": 0.98014,
     "end_time": "2020-11-16T03:53:52.232893",
     "exception": false,
     "start_time": "2020-11-16T03:53:51.252753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.664511</td>\n",
       "      <td>0.850912</td>\n",
       "      <td>-1.954714</td>\n",
       "      <td>4.877738</td>\n",
       "      <td>1.539579</td>\n",
       "      <td>-1.558672</td>\n",
       "      <td>1.128901</td>\n",
       "      <td>0.913540</td>\n",
       "      <td>-1.087465</td>\n",
       "      <td>0.303792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027446</td>\n",
       "      <td>0.081617</td>\n",
       "      <td>0.540991</td>\n",
       "      <td>5.049432</td>\n",
       "      <td>-0.354706</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>1.013321</td>\n",
       "      <td>-0.502233</td>\n",
       "      <td>0.711812</td>\n",
       "      <td>0.225988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>1.384234</td>\n",
       "      <td>0.498396</td>\n",
       "      <td>-1.391302</td>\n",
       "      <td>0.309869</td>\n",
       "      <td>-0.278836</td>\n",
       "      <td>-0.191459</td>\n",
       "      <td>-0.086282</td>\n",
       "      <td>-0.680219</td>\n",
       "      <td>-0.883705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196117</td>\n",
       "      <td>-0.745072</td>\n",
       "      <td>0.045870</td>\n",
       "      <td>-10.972282</td>\n",
       "      <td>1.157498</td>\n",
       "      <td>-0.947954</td>\n",
       "      <td>-1.585535</td>\n",
       "      <td>0.019060</td>\n",
       "      <td>-1.261338</td>\n",
       "      <td>0.387432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602852</td>\n",
       "      <td>2.202714</td>\n",
       "      <td>0.777727</td>\n",
       "      <td>3.599316</td>\n",
       "      <td>0.556439</td>\n",
       "      <td>-0.668258</td>\n",
       "      <td>-0.301835</td>\n",
       "      <td>0.302974</td>\n",
       "      <td>0.206142</td>\n",
       "      <td>-0.301955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588007</td>\n",
       "      <td>-0.758515</td>\n",
       "      <td>-0.315570</td>\n",
       "      <td>3.689932</td>\n",
       "      <td>-0.164491</td>\n",
       "      <td>1.013069</td>\n",
       "      <td>-0.829323</td>\n",
       "      <td>-0.734291</td>\n",
       "      <td>0.351699</td>\n",
       "      <td>0.515978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.027617</td>\n",
       "      <td>0.718500</td>\n",
       "      <td>-1.403949</td>\n",
       "      <td>0.895711</td>\n",
       "      <td>1.526052</td>\n",
       "      <td>0.901657</td>\n",
       "      <td>-0.007928</td>\n",
       "      <td>0.939157</td>\n",
       "      <td>1.962826</td>\n",
       "      <td>-0.898130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.525149</td>\n",
       "      <td>0.631225</td>\n",
       "      <td>0.288173</td>\n",
       "      <td>-1.139968</td>\n",
       "      <td>0.769550</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645346</td>\n",
       "      <td>0.639015</td>\n",
       "      <td>-0.878651</td>\n",
       "      <td>6.281546</td>\n",
       "      <td>0.979011</td>\n",
       "      <td>-0.186902</td>\n",
       "      <td>0.383471</td>\n",
       "      <td>0.183814</td>\n",
       "      <td>-0.224787</td>\n",
       "      <td>0.695918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.048486</td>\n",
       "      <td>0.797246</td>\n",
       "      <td>0.728899</td>\n",
       "      <td>5.820579</td>\n",
       "      <td>1.876652</td>\n",
       "      <td>-1.208926</td>\n",
       "      <td>0.582925</td>\n",
       "      <td>-1.923191</td>\n",
       "      <td>0.268839</td>\n",
       "      <td>0.902735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.010078</td>\n",
       "      <td>0.896914</td>\n",
       "      <td>-0.377721</td>\n",
       "      <td>-14.001157</td>\n",
       "      <td>0.100654</td>\n",
       "      <td>0.528629</td>\n",
       "      <td>-1.201238</td>\n",
       "      <td>-0.154176</td>\n",
       "      <td>-0.116326</td>\n",
       "      <td>-0.742425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose         0         1  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  1.134849  0.907687   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.119282  0.681738   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.779973  0.946463   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.734910 -0.274641   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.452718 -0.477513   \n",
       "...             ...          ...     ...     ...       ...       ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2  0.209361 -0.022389   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2 -1.911021  0.587228   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.525149  0.631225   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.816407  0.417618   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1 -1.243096  1.567730   \n",
       "\n",
       "              2         3         4         5  ...      1000      1001  \\\n",
       "0     -0.416385 -0.966814 -0.254723 -1.017473  ... -1.664511  0.850912   \n",
       "1      0.272399  0.080113  1.205169  0.686517  ... -0.027446  0.081617   \n",
       "2      1.425350 -0.132928 -0.006122  1.492493  ...  0.047053  1.384234   \n",
       "3     -0.438509  0.759097  2.346330 -0.858153  ...  0.196117 -0.745072   \n",
       "4      0.972316  0.970731  1.463427 -0.869555  ...  0.602852  2.202714   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "23809 -0.235888 -0.796989 -0.674009  0.919312  ...  0.588007 -0.758515   \n",
       "23810 -0.588417  1.296405 -1.002640  0.850589  ... -1.027617  0.718500   \n",
       "23811  0.288173 -1.139968  0.769550  0.001014  ... -0.645346  0.639015   \n",
       "23812  0.431631  0.300617  1.070346 -0.024189  ... -1.048486  0.797246   \n",
       "23813 -0.269573  1.083636 -0.511235 -2.099634  ... -1.010078  0.896914   \n",
       "\n",
       "           1002       1003      1004      1005      1006      1007      1008  \\\n",
       "0     -1.954714   4.877738  1.539579 -1.558672  1.128901  0.913540 -1.087465   \n",
       "1      0.540991   5.049432 -0.354706  0.010856  1.013321 -0.502233  0.711812   \n",
       "2      0.498396  -1.391302  0.309869 -0.278836 -0.191459 -0.086282 -0.680219   \n",
       "3      0.045870 -10.972282  1.157498 -0.947954 -1.585535  0.019060 -1.261338   \n",
       "4      0.777727   3.599316  0.556439 -0.668258 -0.301835  0.302974  0.206142   \n",
       "...         ...        ...       ...       ...       ...       ...       ...   \n",
       "23809 -0.315570   3.689932 -0.164491  1.013069 -0.829323 -0.734291  0.351699   \n",
       "23810 -1.403949   0.895711  1.526052  0.901657 -0.007928  0.939157  1.962826   \n",
       "23811 -0.878651   6.281546  0.979011 -0.186902  0.383471  0.183814 -0.224787   \n",
       "23812  0.728899   5.820579  1.876652 -1.208926  0.582925 -1.923191  0.268839   \n",
       "23813 -0.377721 -14.001157  0.100654  0.528629 -1.201238 -0.154176 -0.116326   \n",
       "\n",
       "           1009  \n",
       "0      0.303792  \n",
       "1      0.225988  \n",
       "2     -0.883705  \n",
       "3      0.387432  \n",
       "4     -0.301955  \n",
       "...         ...  \n",
       "23809  0.515978  \n",
       "23810 -0.898130  \n",
       "23811  0.695918  \n",
       "23812  0.902735  \n",
       "23813 -0.742425  \n",
       "\n",
       "[23814 rows x 1014 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_thresh = VarianceThreshold(threshold=VarianceThreshold_for_FS)\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:52.306603Z",
     "iopub.status.busy": "2020-11-16T03:53:52.305859Z",
     "iopub.status.idle": "2020-11-16T03:53:52.310673Z",
     "shell.execute_reply": "2020-11-16T03:53:52.310202Z"
    },
    "papermill": {
     "duration": 0.042738,
     "end_time": "2020-11-16T03:53:52.310769",
     "exception": false,
     "start_time": "2020-11-16T03:53:52.268031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sig_id', '5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\n",
       "       'acat_inhibitor', 'acetylcholine_receptor_agonist',\n",
       "       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\n",
       "       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\n",
       "       'adenylyl_cyclase_activator',\n",
       "       ...\n",
       "       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\n",
       "       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\n",
       "       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\n",
       "       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\n",
       "      dtype='object', length=207)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:52.385403Z",
     "iopub.status.busy": "2020-11-16T03:53:52.384084Z",
     "iopub.status.idle": "2020-11-16T03:53:52.789048Z",
     "shell.execute_reply": "2020-11-16T03:53:52.789658Z"
    },
    "papermill": {
     "duration": 0.445252,
     "end_time": "2020-11-16T03:53:52.789803",
     "exception": false,
     "start_time": "2020-11-16T03:53:52.344551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...   \n",
       "1      1.205169  0.686517  0.313396  ...   \n",
       "2     -0.006122  1.492493  0.235577  ...   \n",
       "3      2.346330 -0.858153 -2.288417  ...   \n",
       "4      1.463427 -0.869555 -0.375501  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...   \n",
       "21944 -0.674009  0.919312  0.735603  ...   \n",
       "21945 -1.002640  0.850589 -0.304313  ...   \n",
       "21946  1.070346 -0.024189  0.048942  ...   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "21943                                      0             0                0   \n",
       "21944                                      0             0                0   \n",
       "21945                                      0             0                0   \n",
       "21946                                      0             0                0   \n",
       "21947                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "21943                           0              0  \n",
       "21944                           0              0  \n",
       "21945                           0              0  \n",
       "21946                           0              0  \n",
       "21947                           0              0  \n",
       "\n",
       "[21948 rows x 1219 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:52.880469Z",
     "iopub.status.busy": "2020-11-16T03:53:52.878666Z",
     "iopub.status.idle": "2020-11-16T03:53:52.881200Z",
     "shell.execute_reply": "2020-11-16T03:53:52.881797Z"
    },
    "papermill": {
     "duration": 0.053772,
     "end_time": "2020-11-16T03:53:52.881938",
     "exception": false,
     "start_time": "2020-11-16T03:53:52.828166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033095,
     "end_time": "2020-11-16T03:53:52.948640",
     "exception": false,
     "start_time": "2020-11-16T03:53:52.915545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CV folds¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.057353Z",
     "iopub.status.busy": "2020-11-16T03:53:53.056616Z",
     "iopub.status.idle": "2020-11-16T03:53:53.059341Z",
     "shell.execute_reply": "2020-11-16T03:53:53.059778Z"
    },
    "papermill": {
     "duration": 0.057839,
     "end_time": "2020-11-16T03:53:53.059902",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.002063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_folds(num_starts, num_splits):\n",
    "    \"\"\"\n",
    "    num_starts: the number of SEED\n",
    "    num_splits: K-folds\n",
    "    \"\"\"\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    # LOAD FILES\n",
    "    train_feats = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "    scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "    drug = pd.read_csv('/kaggle/input/lish-moa/train_drug.csv')\n",
    "    scored = scored.loc[train_feats['cp_type'] == 'trt_cp', :]\n",
    "    drug = drug.loc[train_feats['cp_type'] == 'trt_cp', :]\n",
    "    targets = scored.columns[1:]\n",
    "    scored = scored.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "    # LOCATE DRUGS\n",
    "    vc = scored.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "    vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "#     vc1 = vc.loc[(vc==6)|(vc==12)|(vc==18)].index.sort_values()\n",
    "#     vc2 = vc.loc[(vc!=6)&(vc!=12)&(vc!=18)].index.sort_values()\n",
    "\n",
    "    for seed in range(num_starts):\n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        dct1 = {}; dct2 = {}\n",
    "        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state=42)\n",
    "        tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[targets])):\n",
    "            dd = {k:fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state=42)\n",
    "        tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[targets])):\n",
    "            dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "        # ASSIGN FOLDS\n",
    "        scored['fold'] = scored.drug_id.map(dct1)\n",
    "        scored.loc[scored.fold.isna(),'fold'] = scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n",
    "        scored.fold = scored.fold.astype('int8')\n",
    "        \n",
    "        folds.append(scored.fold.values)\n",
    "        del scored['fold']\n",
    "\n",
    "    return np.stack(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.133220Z",
     "iopub.status.busy": "2020-11-16T03:53:53.131545Z",
     "iopub.status.idle": "2020-11-16T03:53:53.133913Z",
     "shell.execute_reply": "2020-11-16T03:53:53.134408Z"
    },
    "papermill": {
     "duration": 0.040836,
     "end_time": "2020-11-16T03:53:53.134524",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.093688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folds = train.copy()\n",
    "\n",
    "# mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "# # 'kfold' is the index of validation set\n",
    "# for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "#     print(t_idx, v_idx, len(t_idx), len(v_idx))\n",
    "#     folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "# folds['kfold'] = folds['kfold'].astype(int)\n",
    "# folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.208228Z",
     "iopub.status.busy": "2020-11-16T03:53:53.207419Z",
     "iopub.status.idle": "2020-11-16T03:53:53.212469Z",
     "shell.execute_reply": "2020-11-16T03:53:53.211820Z"
    },
    "papermill": {
     "duration": 0.0444,
     "end_time": "2020-11-16T03:53:53.212592",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.168192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1219)\n",
      "(3624, 1013)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "# print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.290343Z",
     "iopub.status.busy": "2020-11-16T03:53:53.289504Z",
     "iopub.status.idle": "2020-11-16T03:53:53.293759Z",
     "shell.execute_reply": "2020-11-16T03:53:53.292278Z"
    },
    "papermill": {
     "duration": 0.046521,
     "end_time": "2020-11-16T03:53:53.293892",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.247371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.437406Z",
     "iopub.status.busy": "2020-11-16T03:53:53.383956Z",
     "iopub.status.idle": "2020-11-16T03:53:53.545980Z",
     "shell.execute_reply": "2020-11-16T03:53:53.546602Z"
    },
    "papermill": {
     "duration": 0.213047,
     "end_time": "2020-11-16T03:53:53.546751",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.333704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1015"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(train).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034947,
     "end_time": "2020-11-16T03:53:53.617932",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.582985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### DataSet Class¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.699542Z",
     "iopub.status.busy": "2020-11-16T03:53:53.698694Z",
     "iopub.status.idle": "2020-11-16T03:53:53.701165Z",
     "shell.execute_reply": "2020-11-16T03:53:53.701608Z"
    },
    "papermill": {
     "duration": 0.048666,
     "end_time": "2020-11-16T03:53:53.701723",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.653057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035093,
     "end_time": "2020-11-16T03:53:53.773177",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.738084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SmoothBCEwLogits¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.856753Z",
     "iopub.status.busy": "2020-11-16T03:53:53.855900Z",
     "iopub.status.idle": "2020-11-16T03:53:53.859002Z",
     "shell.execute_reply": "2020-11-16T03:53:53.858504Z"
    },
    "papermill": {
     "duration": 0.048355,
     "end_time": "2020-11-16T03:53:53.859093",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.810738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing  # targets + (0.5 - targets) * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1), self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets, self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:53.933639Z",
     "iopub.status.busy": "2020-11-16T03:53:53.932875Z",
     "iopub.status.idle": "2020-11-16T03:53:53.935857Z",
     "shell.execute_reply": "2020-11-16T03:53:53.935354Z"
    },
    "papermill": {
     "duration": 0.041378,
     "end_time": "2020-11-16T03:53:53.935949",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.894571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class LabelSmoothingLoss(nn.Module):\n",
    "#     def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "#         super(LabelSmoothingLoss, self).__init__()\n",
    "#         self.confidence = 1.0 - smoothing\n",
    "#         self.smoothing = smoothing\n",
    "#         self.cls = classes\n",
    "#         self.dim = dim\n",
    "\n",
    "#     def forward(self, pred, target):\n",
    "#         pred = pred.log_softmax(dim=self.dim)\n",
    "#         with torch.no_grad():\n",
    "#             true_dist = torch.zeros_like(pred)\n",
    "#             true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "#             true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "#         return torch.mean(torch.sum(-true_dist * pred, dim=self.dim)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035272,
     "end_time": "2020-11-16T03:53:54.008903",
     "exception": false,
     "start_time": "2020-11-16T03:53:53.973631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:54.445720Z",
     "iopub.status.busy": "2020-11-16T03:53:54.443822Z",
     "iopub.status.idle": "2020-11-16T03:53:54.449188Z",
     "shell.execute_reply": "2020-11-16T03:53:54.448358Z"
    },
    "papermill": {
     "duration": 0.404578,
     "end_time": "2020-11-16T03:53:54.449317",
     "exception": false,
     "start_time": "2020-11-16T03:53:54.044739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:54.546343Z",
     "iopub.status.busy": "2020-11-16T03:53:54.544665Z",
     "iopub.status.idle": "2020-11-16T03:53:54.547089Z",
     "shell.execute_reply": "2020-11-16T03:53:54.547584Z"
    },
    "papermill": {
     "duration": 0.058275,
     "end_time": "2020-11-16T03:53:54.547703",
     "exception": false,
     "start_time": "2020-11-16T03:53:54.489428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(Dropout_Model)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(Dropout_Model)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        self.recalibrate_layer(self.dense1)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        self.recalibrate_layer(self.dense2)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        self.recalibrate_layer(self.dense3)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def recalibrate_layer(self, layer):\n",
    "        # Solve the nan problem\n",
    "        if(torch.isnan(layer.weight_v).sum() > 0):\n",
    "            layer.weight_v = torch.nn.Parameter(torch.where(torch.isnan(layer.weight_v), torch.zeros_like(layer.weight_v), layer.weight_v))\n",
    "            layer.weight_v = torch.nn.Parameter(layer.weight_v + 1e-7)\n",
    "\n",
    "        if(torch.isnan(layer.weight).sum() > 0):\n",
    "            layer.weight = torch.where(torch.isnan(layer.weight), torch.zeros_like(layer.weight), layer.weight)\n",
    "            layer.weight += 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052917,
     "end_time": "2020-11-16T03:53:54.637834",
     "exception": false,
     "start_time": "2020-11-16T03:53:54.584917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:54.762429Z",
     "iopub.status.busy": "2020-11-16T03:53:54.755067Z",
     "iopub.status.idle": "2020-11-16T03:53:54.771430Z",
     "shell.execute_reply": "2020-11-16T03:53:54.770680Z"
    },
    "papermill": {
     "duration": 0.08153,
     "end_time": "2020-11-16T03:53:54.771577",
     "exception": false,
     "start_time": "2020-11-16T03:53:54.690047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())  # [batch_size, num_target = 206]\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:54.920689Z",
     "iopub.status.busy": "2020-11-16T03:53:54.919685Z",
     "iopub.status.idle": "2020-11-16T03:53:54.952111Z",
     "shell.execute_reply": "2020-11-16T03:53:54.953190Z"
    },
    "papermill": {
     "duration": 0.106917,
     "end_time": "2020-11-16T03:53:54.953365",
     "exception": false,
     "start_time": "2020-11-16T03:53:54.846448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # prepare dataset\n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "   \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"[TRAIN]: FOLD: {fold}, EPOCH: {epoch}, LR: {optimizer.param_groups[0]['lr']:.6f}, train_loss: {train_loss:.6f}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"[>>VAL]: FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss:.6f}\")\n",
    "\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061305,
     "end_time": "2020-11-16T03:53:55.110283",
     "exception": false,
     "start_time": "2020-11-16T03:53:55.048978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction & Submission¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:55.300101Z",
     "iopub.status.busy": "2020-11-16T03:53:55.297239Z",
     "iopub.status.idle": "2020-11-16T03:53:55.301467Z",
     "shell.execute_reply": "2020-11-16T03:53:55.302218Z"
    },
    "papermill": {
     "duration": 0.111941,
     "end_time": "2020-11-16T03:53:55.302393",
     "exception": false,
     "start_time": "2020-11-16T03:53:55.190452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T03:53:55.523852Z",
     "iopub.status.busy": "2020-11-16T03:53:55.522978Z",
     "iopub.status.idle": "2020-11-16T04:28:28.667283Z",
     "shell.execute_reply": "2020-11-16T04:28:28.666055Z"
    },
    "papermill": {
     "duration": 2073.267178,
     "end_time": "2020-11-16T04:28:28.667412",
     "exception": false,
     "start_time": "2020-11-16T03:53:55.400234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0 ... 1 5 4]\n",
      " [6 0 0 ... 1 5 4]\n",
      " [6 0 0 ... 1 5 4]\n",
      " ...\n",
      " [6 0 0 ... 1 5 4]\n",
      " [6 0 0 ... 1 5 4]\n",
      " [6 0 0 ... 1 5 4]]\n",
      "\n",
      ">> SEED: 0\n",
      "\n",
      "[TRAIN]: FOLD: 0, EPOCH: 0, LR: 0.003478, train_loss: 0.475558\n",
      "[>>VAL]: FOLD: 0, EPOCH: 0, valid_loss: 0.025120\n",
      "[TRAIN]: FOLD: 0, EPOCH: 1, LR: 0.009066, train_loss: 0.024022\n",
      "[>>VAL]: FOLD: 0, EPOCH: 1, valid_loss: 0.019241\n",
      "[TRAIN]: FOLD: 0, EPOCH: 2, LR: 0.009987, train_loss: 0.022019\n",
      "[>>VAL]: FOLD: 0, EPOCH: 2, valid_loss: 0.018335\n",
      "[TRAIN]: FOLD: 0, EPOCH: 3, LR: 0.009890, train_loss: 0.020667\n",
      "[>>VAL]: FOLD: 0, EPOCH: 3, valid_loss: 0.018080\n",
      "[TRAIN]: FOLD: 0, EPOCH: 4, LR: 0.009697, train_loss: 0.020245\n",
      "[>>VAL]: FOLD: 0, EPOCH: 4, valid_loss: 0.017872\n",
      "[TRAIN]: FOLD: 0, EPOCH: 5, LR: 0.009413, train_loss: 0.020269\n",
      "[>>VAL]: FOLD: 0, EPOCH: 5, valid_loss: 0.017913\n",
      "[TRAIN]: FOLD: 0, EPOCH: 6, LR: 0.009042, train_loss: 0.020232\n",
      "[>>VAL]: FOLD: 0, EPOCH: 6, valid_loss: 0.017896\n",
      "[TRAIN]: FOLD: 0, EPOCH: 7, LR: 0.008593, train_loss: 0.020255\n",
      "[>>VAL]: FOLD: 0, EPOCH: 7, valid_loss: 0.018228\n",
      "[TRAIN]: FOLD: 0, EPOCH: 8, LR: 0.008075, train_loss: 0.020281\n",
      "[>>VAL]: FOLD: 0, EPOCH: 8, valid_loss: 0.017916\n",
      "[TRAIN]: FOLD: 0, EPOCH: 9, LR: 0.007496, train_loss: 0.020264\n",
      "[>>VAL]: FOLD: 0, EPOCH: 9, valid_loss: 0.018189\n",
      "[TRAIN]: FOLD: 0, EPOCH: 10, LR: 0.006869, train_loss: 0.020244\n",
      "[>>VAL]: FOLD: 0, EPOCH: 10, valid_loss: 0.017961\n",
      "[TRAIN]: FOLD: 0, EPOCH: 11, LR: 0.006205, train_loss: 0.020199\n",
      "[>>VAL]: FOLD: 0, EPOCH: 11, valid_loss: 0.018397\n",
      "[TRAIN]: FOLD: 0, EPOCH: 12, LR: 0.005518, train_loss: 0.020073\n",
      "[>>VAL]: FOLD: 0, EPOCH: 12, valid_loss: 0.017756\n",
      "[TRAIN]: FOLD: 0, EPOCH: 13, LR: 0.004821, train_loss: 0.020004\n",
      "[>>VAL]: FOLD: 0, EPOCH: 13, valid_loss: 0.017623\n",
      "[TRAIN]: FOLD: 0, EPOCH: 14, LR: 0.004127, train_loss: 0.019889\n",
      "[>>VAL]: FOLD: 0, EPOCH: 14, valid_loss: 0.017845\n",
      "[TRAIN]: FOLD: 0, EPOCH: 15, LR: 0.003450, train_loss: 0.019731\n",
      "[>>VAL]: FOLD: 0, EPOCH: 15, valid_loss: 0.017596\n",
      "[TRAIN]: FOLD: 0, EPOCH: 16, LR: 0.002804, train_loss: 0.019589\n",
      "[>>VAL]: FOLD: 0, EPOCH: 16, valid_loss: 0.017380\n",
      "[TRAIN]: FOLD: 0, EPOCH: 17, LR: 0.002200, train_loss: 0.019255\n",
      "[>>VAL]: FOLD: 0, EPOCH: 17, valid_loss: 0.017419\n",
      "[TRAIN]: FOLD: 0, EPOCH: 18, LR: 0.001651, train_loss: 0.018978\n",
      "[>>VAL]: FOLD: 0, EPOCH: 18, valid_loss: 0.017496\n",
      "[TRAIN]: FOLD: 0, EPOCH: 19, LR: 0.001167, train_loss: 0.018658\n",
      "[>>VAL]: FOLD: 0, EPOCH: 19, valid_loss: 0.017322\n",
      "[TRAIN]: FOLD: 0, EPOCH: 20, LR: 0.000757, train_loss: 0.018199\n",
      "[>>VAL]: FOLD: 0, EPOCH: 20, valid_loss: 0.017321\n",
      "[TRAIN]: FOLD: 0, EPOCH: 21, LR: 0.000430, train_loss: 0.017774\n",
      "[>>VAL]: FOLD: 0, EPOCH: 21, valid_loss: 0.017274\n",
      "[TRAIN]: FOLD: 0, EPOCH: 22, LR: 0.000192, train_loss: 0.017340\n",
      "[>>VAL]: FOLD: 0, EPOCH: 22, valid_loss: 0.017292\n",
      "[TRAIN]: FOLD: 0, EPOCH: 23, LR: 0.000048, train_loss: 0.016929\n",
      "[>>VAL]: FOLD: 0, EPOCH: 23, valid_loss: 0.017276\n",
      "[TRAIN]: FOLD: 0, EPOCH: 24, LR: 0.000000, train_loss: 0.016765\n",
      "[>>VAL]: FOLD: 0, EPOCH: 24, valid_loss: 0.017293\n",
      "[TRAIN]: FOLD: 1, EPOCH: 0, LR: 0.003478, train_loss: 0.476266\n",
      "[>>VAL]: FOLD: 1, EPOCH: 0, valid_loss: 0.024200\n",
      "[TRAIN]: FOLD: 1, EPOCH: 1, LR: 0.009066, train_loss: 0.023952\n",
      "[>>VAL]: FOLD: 1, EPOCH: 1, valid_loss: 0.019747\n",
      "[TRAIN]: FOLD: 1, EPOCH: 2, LR: 0.009987, train_loss: 0.022264\n",
      "[>>VAL]: FOLD: 1, EPOCH: 2, valid_loss: 0.018126\n",
      "[TRAIN]: FOLD: 1, EPOCH: 3, LR: 0.009890, train_loss: 0.020944\n",
      "[>>VAL]: FOLD: 1, EPOCH: 3, valid_loss: 0.017953\n",
      "[TRAIN]: FOLD: 1, EPOCH: 4, LR: 0.009697, train_loss: 0.020364\n",
      "[>>VAL]: FOLD: 1, EPOCH: 4, valid_loss: 0.017643\n",
      "[TRAIN]: FOLD: 1, EPOCH: 5, LR: 0.009412, train_loss: 0.020269\n",
      "[>>VAL]: FOLD: 1, EPOCH: 5, valid_loss: 0.017793\n",
      "[TRAIN]: FOLD: 1, EPOCH: 6, LR: 0.009042, train_loss: 0.020292\n",
      "[>>VAL]: FOLD: 1, EPOCH: 6, valid_loss: 0.017759\n",
      "[TRAIN]: FOLD: 1, EPOCH: 7, LR: 0.008593, train_loss: 0.020340\n",
      "[>>VAL]: FOLD: 1, EPOCH: 7, valid_loss: 0.017497\n",
      "[TRAIN]: FOLD: 1, EPOCH: 8, LR: 0.008075, train_loss: 0.020286\n",
      "[>>VAL]: FOLD: 1, EPOCH: 8, valid_loss: 0.017513\n",
      "[TRAIN]: FOLD: 1, EPOCH: 9, LR: 0.007496, train_loss: 0.020234\n",
      "[>>VAL]: FOLD: 1, EPOCH: 9, valid_loss: 0.017701\n",
      "[TRAIN]: FOLD: 1, EPOCH: 10, LR: 0.006869, train_loss: 0.020199\n",
      "[>>VAL]: FOLD: 1, EPOCH: 10, valid_loss: 0.017651\n",
      "[TRAIN]: FOLD: 1, EPOCH: 11, LR: 0.006205, train_loss: 0.020216\n",
      "[>>VAL]: FOLD: 1, EPOCH: 11, valid_loss: 0.017558\n",
      "[TRAIN]: FOLD: 1, EPOCH: 12, LR: 0.005518, train_loss: 0.020081\n",
      "[>>VAL]: FOLD: 1, EPOCH: 12, valid_loss: 0.017418\n",
      "[TRAIN]: FOLD: 1, EPOCH: 13, LR: 0.004821, train_loss: 0.019983\n",
      "[>>VAL]: FOLD: 1, EPOCH: 13, valid_loss: 0.017338\n",
      "[TRAIN]: FOLD: 1, EPOCH: 14, LR: 0.004127, train_loss: 0.019904\n",
      "[>>VAL]: FOLD: 1, EPOCH: 14, valid_loss: 0.017420\n",
      "[TRAIN]: FOLD: 1, EPOCH: 15, LR: 0.003450, train_loss: 0.019719\n",
      "[>>VAL]: FOLD: 1, EPOCH: 15, valid_loss: 0.017099\n",
      "[TRAIN]: FOLD: 1, EPOCH: 16, LR: 0.002804, train_loss: 0.019512\n",
      "[>>VAL]: FOLD: 1, EPOCH: 16, valid_loss: 0.017237\n",
      "[TRAIN]: FOLD: 1, EPOCH: 17, LR: 0.002200, train_loss: 0.019310\n",
      "[>>VAL]: FOLD: 1, EPOCH: 17, valid_loss: 0.017173\n",
      "[TRAIN]: FOLD: 1, EPOCH: 18, LR: 0.001651, train_loss: 0.019029\n",
      "[>>VAL]: FOLD: 1, EPOCH: 18, valid_loss: 0.017094\n",
      "[TRAIN]: FOLD: 1, EPOCH: 19, LR: 0.001167, train_loss: 0.018669\n",
      "[>>VAL]: FOLD: 1, EPOCH: 19, valid_loss: 0.017019\n",
      "[TRAIN]: FOLD: 1, EPOCH: 20, LR: 0.000757, train_loss: 0.018193\n",
      "[>>VAL]: FOLD: 1, EPOCH: 20, valid_loss: 0.017013\n",
      "[TRAIN]: FOLD: 1, EPOCH: 21, LR: 0.000430, train_loss: 0.017773\n",
      "[>>VAL]: FOLD: 1, EPOCH: 21, valid_loss: 0.016998\n",
      "[TRAIN]: FOLD: 1, EPOCH: 22, LR: 0.000192, train_loss: 0.017297\n",
      "[>>VAL]: FOLD: 1, EPOCH: 22, valid_loss: 0.017034\n",
      "[TRAIN]: FOLD: 1, EPOCH: 23, LR: 0.000048, train_loss: 0.016956\n",
      "[>>VAL]: FOLD: 1, EPOCH: 23, valid_loss: 0.017026\n",
      "[TRAIN]: FOLD: 1, EPOCH: 24, LR: 0.000000, train_loss: 0.016754\n",
      "[>>VAL]: FOLD: 1, EPOCH: 24, valid_loss: 0.017072\n",
      "[TRAIN]: FOLD: 2, EPOCH: 0, LR: 0.003478, train_loss: 0.474724\n",
      "[>>VAL]: FOLD: 2, EPOCH: 0, valid_loss: 0.024908\n",
      "[TRAIN]: FOLD: 2, EPOCH: 1, LR: 0.009066, train_loss: 0.023871\n",
      "[>>VAL]: FOLD: 2, EPOCH: 1, valid_loss: 0.020598\n",
      "[TRAIN]: FOLD: 2, EPOCH: 2, LR: 0.009987, train_loss: 0.021720\n",
      "[>>VAL]: FOLD: 2, EPOCH: 2, valid_loss: 0.018655\n",
      "[TRAIN]: FOLD: 2, EPOCH: 3, LR: 0.009890, train_loss: 0.020722\n",
      "[>>VAL]: FOLD: 2, EPOCH: 3, valid_loss: 0.018210\n",
      "[TRAIN]: FOLD: 2, EPOCH: 4, LR: 0.009697, train_loss: 0.020156\n",
      "[>>VAL]: FOLD: 2, EPOCH: 4, valid_loss: 0.018519\n",
      "[TRAIN]: FOLD: 2, EPOCH: 5, LR: 0.009413, train_loss: 0.020130\n",
      "[>>VAL]: FOLD: 2, EPOCH: 5, valid_loss: 0.018472\n",
      "[TRAIN]: FOLD: 2, EPOCH: 6, LR: 0.009042, train_loss: 0.020144\n",
      "[>>VAL]: FOLD: 2, EPOCH: 6, valid_loss: 0.018360\n",
      "[TRAIN]: FOLD: 2, EPOCH: 7, LR: 0.008593, train_loss: 0.020173\n",
      "[>>VAL]: FOLD: 2, EPOCH: 7, valid_loss: 0.018279\n",
      "[TRAIN]: FOLD: 2, EPOCH: 8, LR: 0.008075, train_loss: 0.020125\n",
      "[>>VAL]: FOLD: 2, EPOCH: 8, valid_loss: 0.018440\n",
      "[TRAIN]: FOLD: 2, EPOCH: 9, LR: 0.007496, train_loss: 0.020147\n",
      "[>>VAL]: FOLD: 2, EPOCH: 9, valid_loss: 0.018297\n",
      "[TRAIN]: FOLD: 2, EPOCH: 10, LR: 0.006869, train_loss: 0.020161\n",
      "[>>VAL]: FOLD: 2, EPOCH: 10, valid_loss: 0.018662\n",
      "[TRAIN]: FOLD: 2, EPOCH: 11, LR: 0.006205, train_loss: 0.020054\n",
      "[>>VAL]: FOLD: 2, EPOCH: 11, valid_loss: 0.018425\n",
      "[TRAIN]: FOLD: 2, EPOCH: 12, LR: 0.005518, train_loss: 0.019970\n",
      "[>>VAL]: FOLD: 2, EPOCH: 12, valid_loss: 0.018118\n",
      "[TRAIN]: FOLD: 2, EPOCH: 13, LR: 0.004821, train_loss: 0.019917\n",
      "[>>VAL]: FOLD: 2, EPOCH: 13, valid_loss: 0.018175\n",
      "[TRAIN]: FOLD: 2, EPOCH: 14, LR: 0.004127, train_loss: 0.019761\n",
      "[>>VAL]: FOLD: 2, EPOCH: 14, valid_loss: 0.018171\n",
      "[TRAIN]: FOLD: 2, EPOCH: 15, LR: 0.003450, train_loss: 0.019644\n",
      "[>>VAL]: FOLD: 2, EPOCH: 15, valid_loss: 0.018261\n",
      "[TRAIN]: FOLD: 2, EPOCH: 16, LR: 0.002804, train_loss: 0.019447\n",
      "[>>VAL]: FOLD: 2, EPOCH: 16, valid_loss: 0.017962\n",
      "[TRAIN]: FOLD: 2, EPOCH: 17, LR: 0.002200, train_loss: 0.019177\n",
      "[>>VAL]: FOLD: 2, EPOCH: 17, valid_loss: 0.018079\n",
      "[TRAIN]: FOLD: 2, EPOCH: 18, LR: 0.001651, train_loss: 0.018901\n",
      "[>>VAL]: FOLD: 2, EPOCH: 18, valid_loss: 0.017979\n",
      "[TRAIN]: FOLD: 2, EPOCH: 19, LR: 0.001167, train_loss: 0.018555\n",
      "[>>VAL]: FOLD: 2, EPOCH: 19, valid_loss: 0.017960\n",
      "[TRAIN]: FOLD: 2, EPOCH: 20, LR: 0.000757, train_loss: 0.018122\n",
      "[>>VAL]: FOLD: 2, EPOCH: 20, valid_loss: 0.017823\n",
      "[TRAIN]: FOLD: 2, EPOCH: 21, LR: 0.000430, train_loss: 0.017628\n",
      "[>>VAL]: FOLD: 2, EPOCH: 21, valid_loss: 0.017835\n",
      "[TRAIN]: FOLD: 2, EPOCH: 22, LR: 0.000192, train_loss: 0.017155\n",
      "[>>VAL]: FOLD: 2, EPOCH: 22, valid_loss: 0.017873\n",
      "[TRAIN]: FOLD: 2, EPOCH: 23, LR: 0.000048, train_loss: 0.016814\n",
      "[>>VAL]: FOLD: 2, EPOCH: 23, valid_loss: 0.017852\n",
      "[TRAIN]: FOLD: 2, EPOCH: 24, LR: 0.000000, train_loss: 0.016618\n",
      "[>>VAL]: FOLD: 2, EPOCH: 24, valid_loss: 0.017882\n",
      "[TRAIN]: FOLD: 3, EPOCH: 0, LR: 0.003478, train_loss: 0.476143\n",
      "[>>VAL]: FOLD: 3, EPOCH: 0, valid_loss: 0.024847\n",
      "[TRAIN]: FOLD: 3, EPOCH: 1, LR: 0.009066, train_loss: 0.023780\n",
      "[>>VAL]: FOLD: 3, EPOCH: 1, valid_loss: 0.020379\n",
      "[TRAIN]: FOLD: 3, EPOCH: 2, LR: 0.009987, train_loss: 0.021882\n",
      "[>>VAL]: FOLD: 3, EPOCH: 2, valid_loss: 0.021557\n",
      "[TRAIN]: FOLD: 3, EPOCH: 3, LR: 0.009890, train_loss: 0.020994\n",
      "[>>VAL]: FOLD: 3, EPOCH: 3, valid_loss: 0.017955\n",
      "[TRAIN]: FOLD: 3, EPOCH: 4, LR: 0.009697, train_loss: 0.020371\n",
      "[>>VAL]: FOLD: 3, EPOCH: 4, valid_loss: 0.017714\n",
      "[TRAIN]: FOLD: 3, EPOCH: 5, LR: 0.009412, train_loss: 0.020301\n",
      "[>>VAL]: FOLD: 3, EPOCH: 5, valid_loss: 0.017585\n",
      "[TRAIN]: FOLD: 3, EPOCH: 6, LR: 0.009042, train_loss: 0.020317\n",
      "[>>VAL]: FOLD: 3, EPOCH: 6, valid_loss: 0.017518\n",
      "[TRAIN]: FOLD: 3, EPOCH: 7, LR: 0.008593, train_loss: 0.020365\n",
      "[>>VAL]: FOLD: 3, EPOCH: 7, valid_loss: 0.017637\n",
      "[TRAIN]: FOLD: 3, EPOCH: 8, LR: 0.008075, train_loss: 0.020363\n",
      "[>>VAL]: FOLD: 3, EPOCH: 8, valid_loss: 0.017706\n",
      "[TRAIN]: FOLD: 3, EPOCH: 9, LR: 0.007496, train_loss: 0.020309\n",
      "[>>VAL]: FOLD: 3, EPOCH: 9, valid_loss: 0.017881\n",
      "[TRAIN]: FOLD: 3, EPOCH: 10, LR: 0.006869, train_loss: 0.020264\n",
      "[>>VAL]: FOLD: 3, EPOCH: 10, valid_loss: 0.017661\n",
      "[TRAIN]: FOLD: 3, EPOCH: 11, LR: 0.006205, train_loss: 0.020253\n",
      "[>>VAL]: FOLD: 3, EPOCH: 11, valid_loss: 0.017513\n",
      "[TRAIN]: FOLD: 3, EPOCH: 12, LR: 0.005518, train_loss: 0.020143\n",
      "[>>VAL]: FOLD: 3, EPOCH: 12, valid_loss: 0.017712\n",
      "[TRAIN]: FOLD: 3, EPOCH: 13, LR: 0.004821, train_loss: 0.020133\n",
      "[>>VAL]: FOLD: 3, EPOCH: 13, valid_loss: 0.017344\n",
      "[TRAIN]: FOLD: 3, EPOCH: 14, LR: 0.004127, train_loss: 0.019927\n",
      "[>>VAL]: FOLD: 3, EPOCH: 14, valid_loss: 0.017208\n",
      "[TRAIN]: FOLD: 3, EPOCH: 15, LR: 0.003450, train_loss: 0.019742\n",
      "[>>VAL]: FOLD: 3, EPOCH: 15, valid_loss: 0.017345\n",
      "[TRAIN]: FOLD: 3, EPOCH: 16, LR: 0.002804, train_loss: 0.019571\n",
      "[>>VAL]: FOLD: 3, EPOCH: 16, valid_loss: 0.017059\n",
      "[TRAIN]: FOLD: 3, EPOCH: 17, LR: 0.002200, train_loss: 0.019297\n",
      "[>>VAL]: FOLD: 3, EPOCH: 17, valid_loss: 0.017205\n",
      "[TRAIN]: FOLD: 3, EPOCH: 18, LR: 0.001651, train_loss: 0.019062\n",
      "[>>VAL]: FOLD: 3, EPOCH: 18, valid_loss: 0.017033\n",
      "[TRAIN]: FOLD: 3, EPOCH: 19, LR: 0.001167, train_loss: 0.018657\n",
      "[>>VAL]: FOLD: 3, EPOCH: 19, valid_loss: 0.016923\n",
      "[TRAIN]: FOLD: 3, EPOCH: 20, LR: 0.000757, train_loss: 0.018217\n",
      "[>>VAL]: FOLD: 3, EPOCH: 20, valid_loss: 0.016879\n",
      "[TRAIN]: FOLD: 3, EPOCH: 21, LR: 0.000430, train_loss: 0.017780\n",
      "[>>VAL]: FOLD: 3, EPOCH: 21, valid_loss: 0.016780\n",
      "[TRAIN]: FOLD: 3, EPOCH: 22, LR: 0.000192, train_loss: 0.017296\n",
      "[>>VAL]: FOLD: 3, EPOCH: 22, valid_loss: 0.016759\n",
      "[TRAIN]: FOLD: 3, EPOCH: 23, LR: 0.000048, train_loss: 0.016915\n",
      "[>>VAL]: FOLD: 3, EPOCH: 23, valid_loss: 0.016775\n",
      "[TRAIN]: FOLD: 3, EPOCH: 24, LR: 0.000000, train_loss: 0.016711\n",
      "[>>VAL]: FOLD: 3, EPOCH: 24, valid_loss: 0.016745\n",
      "[TRAIN]: FOLD: 4, EPOCH: 0, LR: 0.003478, train_loss: 0.474443\n",
      "[>>VAL]: FOLD: 4, EPOCH: 0, valid_loss: 0.025229\n",
      "[TRAIN]: FOLD: 4, EPOCH: 1, LR: 0.009066, train_loss: 0.023679\n",
      "[>>VAL]: FOLD: 4, EPOCH: 1, valid_loss: 0.019142\n",
      "[TRAIN]: FOLD: 4, EPOCH: 2, LR: 0.009987, train_loss: 0.021813\n",
      "[>>VAL]: FOLD: 4, EPOCH: 2, valid_loss: 0.018561\n",
      "[TRAIN]: FOLD: 4, EPOCH: 3, LR: 0.009890, train_loss: 0.020638\n",
      "[>>VAL]: FOLD: 4, EPOCH: 3, valid_loss: 0.018138\n",
      "[TRAIN]: FOLD: 4, EPOCH: 4, LR: 0.009697, train_loss: 0.020221\n",
      "[>>VAL]: FOLD: 4, EPOCH: 4, valid_loss: 0.018282\n",
      "[TRAIN]: FOLD: 4, EPOCH: 5, LR: 0.009413, train_loss: 0.020154\n",
      "[>>VAL]: FOLD: 4, EPOCH: 5, valid_loss: 0.018145\n",
      "[TRAIN]: FOLD: 4, EPOCH: 6, LR: 0.009042, train_loss: 0.020214\n",
      "[>>VAL]: FOLD: 4, EPOCH: 6, valid_loss: 0.018173\n",
      "[TRAIN]: FOLD: 4, EPOCH: 7, LR: 0.008593, train_loss: 0.020195\n",
      "[>>VAL]: FOLD: 4, EPOCH: 7, valid_loss: 0.018120\n",
      "[TRAIN]: FOLD: 4, EPOCH: 8, LR: 0.008075, train_loss: 0.020190\n",
      "[>>VAL]: FOLD: 4, EPOCH: 8, valid_loss: 0.018050\n",
      "[TRAIN]: FOLD: 4, EPOCH: 9, LR: 0.007496, train_loss: 0.020299\n",
      "[>>VAL]: FOLD: 4, EPOCH: 9, valid_loss: 0.018027\n",
      "[TRAIN]: FOLD: 4, EPOCH: 10, LR: 0.006869, train_loss: 0.020179\n",
      "[>>VAL]: FOLD: 4, EPOCH: 10, valid_loss: 0.017955\n",
      "[TRAIN]: FOLD: 4, EPOCH: 11, LR: 0.006205, train_loss: 0.020157\n",
      "[>>VAL]: FOLD: 4, EPOCH: 11, valid_loss: 0.018013\n",
      "[TRAIN]: FOLD: 4, EPOCH: 12, LR: 0.005518, train_loss: 0.020117\n",
      "[>>VAL]: FOLD: 4, EPOCH: 12, valid_loss: 0.018173\n",
      "[TRAIN]: FOLD: 4, EPOCH: 13, LR: 0.004821, train_loss: 0.019956\n",
      "[>>VAL]: FOLD: 4, EPOCH: 13, valid_loss: 0.017938\n",
      "[TRAIN]: FOLD: 4, EPOCH: 14, LR: 0.004127, train_loss: 0.019808\n",
      "[>>VAL]: FOLD: 4, EPOCH: 14, valid_loss: 0.017985\n",
      "[TRAIN]: FOLD: 4, EPOCH: 15, LR: 0.003450, train_loss: 0.019730\n",
      "[>>VAL]: FOLD: 4, EPOCH: 15, valid_loss: 0.017584\n",
      "[TRAIN]: FOLD: 4, EPOCH: 16, LR: 0.002804, train_loss: 0.019494\n",
      "[>>VAL]: FOLD: 4, EPOCH: 16, valid_loss: 0.017666\n",
      "[TRAIN]: FOLD: 4, EPOCH: 17, LR: 0.002200, train_loss: 0.019201\n",
      "[>>VAL]: FOLD: 4, EPOCH: 17, valid_loss: 0.017676\n",
      "[TRAIN]: FOLD: 4, EPOCH: 18, LR: 0.001651, train_loss: 0.018936\n",
      "[>>VAL]: FOLD: 4, EPOCH: 18, valid_loss: 0.017585\n",
      "[TRAIN]: FOLD: 4, EPOCH: 19, LR: 0.001167, train_loss: 0.018545\n",
      "[>>VAL]: FOLD: 4, EPOCH: 19, valid_loss: 0.017412\n",
      "[TRAIN]: FOLD: 4, EPOCH: 20, LR: 0.000757, train_loss: 0.018159\n",
      "[>>VAL]: FOLD: 4, EPOCH: 20, valid_loss: 0.017536\n",
      "[TRAIN]: FOLD: 4, EPOCH: 21, LR: 0.000430, train_loss: 0.017685\n",
      "[>>VAL]: FOLD: 4, EPOCH: 21, valid_loss: 0.017424\n",
      "[TRAIN]: FOLD: 4, EPOCH: 22, LR: 0.000192, train_loss: 0.017207\n",
      "[>>VAL]: FOLD: 4, EPOCH: 22, valid_loss: 0.017540\n",
      "[TRAIN]: FOLD: 4, EPOCH: 23, LR: 0.000048, train_loss: 0.016888\n",
      "[>>VAL]: FOLD: 4, EPOCH: 23, valid_loss: 0.017529\n",
      "[TRAIN]: FOLD: 4, EPOCH: 24, LR: 0.000000, train_loss: 0.016680\n",
      "[>>VAL]: FOLD: 4, EPOCH: 24, valid_loss: 0.017531\n",
      "[TRAIN]: FOLD: 5, EPOCH: 0, LR: 0.003478, train_loss: 0.476638\n",
      "[>>VAL]: FOLD: 5, EPOCH: 0, valid_loss: 0.025265\n",
      "[TRAIN]: FOLD: 5, EPOCH: 1, LR: 0.009066, train_loss: 0.023834\n",
      "[>>VAL]: FOLD: 5, EPOCH: 1, valid_loss: 0.019661\n",
      "[TRAIN]: FOLD: 5, EPOCH: 2, LR: 0.009987, train_loss: 0.021707\n",
      "[>>VAL]: FOLD: 5, EPOCH: 2, valid_loss: 0.018714\n",
      "[TRAIN]: FOLD: 5, EPOCH: 3, LR: 0.009890, train_loss: 0.020542\n",
      "[>>VAL]: FOLD: 5, EPOCH: 3, valid_loss: 0.018414\n",
      "[TRAIN]: FOLD: 5, EPOCH: 4, LR: 0.009697, train_loss: 0.020190\n",
      "[>>VAL]: FOLD: 5, EPOCH: 4, valid_loss: 0.018404\n",
      "[TRAIN]: FOLD: 5, EPOCH: 5, LR: 0.009412, train_loss: 0.020168\n",
      "[>>VAL]: FOLD: 5, EPOCH: 5, valid_loss: 0.018304\n",
      "[TRAIN]: FOLD: 5, EPOCH: 6, LR: 0.009042, train_loss: 0.020130\n",
      "[>>VAL]: FOLD: 5, EPOCH: 6, valid_loss: 0.018193\n",
      "[TRAIN]: FOLD: 5, EPOCH: 7, LR: 0.008593, train_loss: 0.020106\n",
      "[>>VAL]: FOLD: 5, EPOCH: 7, valid_loss: 0.018396\n",
      "[TRAIN]: FOLD: 5, EPOCH: 8, LR: 0.008075, train_loss: 0.020177\n",
      "[>>VAL]: FOLD: 5, EPOCH: 8, valid_loss: 0.018036\n",
      "[TRAIN]: FOLD: 5, EPOCH: 9, LR: 0.007496, train_loss: 0.020086\n",
      "[>>VAL]: FOLD: 5, EPOCH: 9, valid_loss: 0.018115\n",
      "[TRAIN]: FOLD: 5, EPOCH: 10, LR: 0.006869, train_loss: 0.020057\n",
      "[>>VAL]: FOLD: 5, EPOCH: 10, valid_loss: 0.018173\n",
      "[TRAIN]: FOLD: 5, EPOCH: 11, LR: 0.006205, train_loss: 0.020042\n",
      "[>>VAL]: FOLD: 5, EPOCH: 11, valid_loss: 0.018075\n",
      "[TRAIN]: FOLD: 5, EPOCH: 12, LR: 0.005518, train_loss: 0.019951\n",
      "[>>VAL]: FOLD: 5, EPOCH: 12, valid_loss: 0.018137\n",
      "[TRAIN]: FOLD: 5, EPOCH: 13, LR: 0.004821, train_loss: 0.019849\n",
      "[>>VAL]: FOLD: 5, EPOCH: 13, valid_loss: 0.018011\n",
      "[TRAIN]: FOLD: 5, EPOCH: 14, LR: 0.004127, train_loss: 0.019718\n",
      "[>>VAL]: FOLD: 5, EPOCH: 14, valid_loss: 0.018001\n",
      "[TRAIN]: FOLD: 5, EPOCH: 15, LR: 0.003450, train_loss: 0.019551\n",
      "[>>VAL]: FOLD: 5, EPOCH: 15, valid_loss: 0.018106\n",
      "[TRAIN]: FOLD: 5, EPOCH: 16, LR: 0.002804, train_loss: 0.019331\n",
      "[>>VAL]: FOLD: 5, EPOCH: 16, valid_loss: 0.017957\n",
      "[TRAIN]: FOLD: 5, EPOCH: 17, LR: 0.002200, train_loss: 0.019025\n",
      "[>>VAL]: FOLD: 5, EPOCH: 17, valid_loss: 0.017928\n",
      "[TRAIN]: FOLD: 5, EPOCH: 18, LR: 0.001651, train_loss: 0.018778\n",
      "[>>VAL]: FOLD: 5, EPOCH: 18, valid_loss: 0.017944\n",
      "[TRAIN]: FOLD: 5, EPOCH: 19, LR: 0.001167, train_loss: 0.018340\n",
      "[>>VAL]: FOLD: 5, EPOCH: 19, valid_loss: 0.017881\n",
      "[TRAIN]: FOLD: 5, EPOCH: 20, LR: 0.000757, train_loss: 0.017927\n",
      "[>>VAL]: FOLD: 5, EPOCH: 20, valid_loss: 0.017829\n",
      "[TRAIN]: FOLD: 5, EPOCH: 21, LR: 0.000430, train_loss: 0.017404\n",
      "[>>VAL]: FOLD: 5, EPOCH: 21, valid_loss: 0.017854\n",
      "[TRAIN]: FOLD: 5, EPOCH: 22, LR: 0.000192, train_loss: 0.016894\n",
      "[>>VAL]: FOLD: 5, EPOCH: 22, valid_loss: 0.017891\n",
      "[TRAIN]: FOLD: 5, EPOCH: 23, LR: 0.000048, train_loss: 0.016503\n",
      "[>>VAL]: FOLD: 5, EPOCH: 23, valid_loss: 0.017888\n",
      "[TRAIN]: FOLD: 5, EPOCH: 24, LR: 0.000000, train_loss: 0.016287\n",
      "[>>VAL]: FOLD: 5, EPOCH: 24, valid_loss: 0.017898\n",
      "[TRAIN]: FOLD: 6, EPOCH: 0, LR: 0.003478, train_loss: 0.475163\n",
      "[>>VAL]: FOLD: 6, EPOCH: 0, valid_loss: 0.024199\n",
      "[TRAIN]: FOLD: 6, EPOCH: 1, LR: 0.009066, train_loss: 0.023890\n",
      "[>>VAL]: FOLD: 6, EPOCH: 1, valid_loss: 0.018802\n",
      "[TRAIN]: FOLD: 6, EPOCH: 2, LR: 0.009987, train_loss: 0.021930\n",
      "[>>VAL]: FOLD: 6, EPOCH: 2, valid_loss: 0.018067\n",
      "[TRAIN]: FOLD: 6, EPOCH: 3, LR: 0.009890, train_loss: 0.020849\n",
      "[>>VAL]: FOLD: 6, EPOCH: 3, valid_loss: 0.017632\n",
      "[TRAIN]: FOLD: 6, EPOCH: 4, LR: 0.009697, train_loss: 0.020380\n",
      "[>>VAL]: FOLD: 6, EPOCH: 4, valid_loss: 0.017649\n",
      "[TRAIN]: FOLD: 6, EPOCH: 5, LR: 0.009413, train_loss: 0.020296\n",
      "[>>VAL]: FOLD: 6, EPOCH: 5, valid_loss: 0.017340\n",
      "[TRAIN]: FOLD: 6, EPOCH: 6, LR: 0.009042, train_loss: 0.020314\n",
      "[>>VAL]: FOLD: 6, EPOCH: 6, valid_loss: 0.017415\n",
      "[TRAIN]: FOLD: 6, EPOCH: 7, LR: 0.008593, train_loss: 0.020368\n",
      "[>>VAL]: FOLD: 6, EPOCH: 7, valid_loss: 0.017264\n",
      "[TRAIN]: FOLD: 6, EPOCH: 8, LR: 0.008075, train_loss: 0.020322\n",
      "[>>VAL]: FOLD: 6, EPOCH: 8, valid_loss: 0.017280\n",
      "[TRAIN]: FOLD: 6, EPOCH: 9, LR: 0.007496, train_loss: 0.020307\n",
      "[>>VAL]: FOLD: 6, EPOCH: 9, valid_loss: 0.017420\n",
      "[TRAIN]: FOLD: 6, EPOCH: 10, LR: 0.006869, train_loss: 0.020262\n",
      "[>>VAL]: FOLD: 6, EPOCH: 10, valid_loss: 0.017139\n",
      "[TRAIN]: FOLD: 6, EPOCH: 11, LR: 0.006205, train_loss: 0.020224\n",
      "[>>VAL]: FOLD: 6, EPOCH: 11, valid_loss: 0.017324\n",
      "[TRAIN]: FOLD: 6, EPOCH: 12, LR: 0.005518, train_loss: 0.020189\n",
      "[>>VAL]: FOLD: 6, EPOCH: 12, valid_loss: 0.017110\n",
      "[TRAIN]: FOLD: 6, EPOCH: 13, LR: 0.004821, train_loss: 0.020126\n",
      "[>>VAL]: FOLD: 6, EPOCH: 13, valid_loss: 0.017484\n",
      "[TRAIN]: FOLD: 6, EPOCH: 14, LR: 0.004127, train_loss: 0.019931\n",
      "[>>VAL]: FOLD: 6, EPOCH: 14, valid_loss: 0.017188\n",
      "[TRAIN]: FOLD: 6, EPOCH: 15, LR: 0.003450, train_loss: 0.019808\n",
      "[>>VAL]: FOLD: 6, EPOCH: 15, valid_loss: 0.016961\n",
      "[TRAIN]: FOLD: 6, EPOCH: 16, LR: 0.002804, train_loss: 0.019567\n",
      "[>>VAL]: FOLD: 6, EPOCH: 16, valid_loss: 0.016861\n",
      "[TRAIN]: FOLD: 6, EPOCH: 17, LR: 0.002200, train_loss: 0.019342\n",
      "[>>VAL]: FOLD: 6, EPOCH: 17, valid_loss: 0.016743\n",
      "[TRAIN]: FOLD: 6, EPOCH: 18, LR: 0.001651, train_loss: 0.019026\n",
      "[>>VAL]: FOLD: 6, EPOCH: 18, valid_loss: 0.016855\n",
      "[TRAIN]: FOLD: 6, EPOCH: 19, LR: 0.001167, train_loss: 0.018656\n",
      "[>>VAL]: FOLD: 6, EPOCH: 19, valid_loss: 0.016662\n",
      "[TRAIN]: FOLD: 6, EPOCH: 20, LR: 0.000757, train_loss: 0.018224\n",
      "[>>VAL]: FOLD: 6, EPOCH: 20, valid_loss: 0.016647\n",
      "[TRAIN]: FOLD: 6, EPOCH: 21, LR: 0.000430, train_loss: 0.017771\n",
      "[>>VAL]: FOLD: 6, EPOCH: 21, valid_loss: 0.016668\n",
      "[TRAIN]: FOLD: 6, EPOCH: 22, LR: 0.000192, train_loss: 0.017306\n",
      "[>>VAL]: FOLD: 6, EPOCH: 22, valid_loss: 0.016624\n",
      "[TRAIN]: FOLD: 6, EPOCH: 23, LR: 0.000048, train_loss: 0.016922\n",
      "[>>VAL]: FOLD: 6, EPOCH: 23, valid_loss: 0.016617\n",
      "[TRAIN]: FOLD: 6, EPOCH: 24, LR: 0.000000, train_loss: 0.016751\n",
      "[>>VAL]: FOLD: 6, EPOCH: 24, valid_loss: 0.016667\n",
      "\n",
      ">> SEED: 1\n",
      "\n",
      "[TRAIN]: FOLD: 0, EPOCH: 0, LR: 0.003478, train_loss: 0.475515\n",
      "[>>VAL]: FOLD: 0, EPOCH: 0, valid_loss: 0.025987\n",
      "[TRAIN]: FOLD: 0, EPOCH: 1, LR: 0.009066, train_loss: 0.023880\n",
      "[>>VAL]: FOLD: 0, EPOCH: 1, valid_loss: 0.019370\n",
      "[TRAIN]: FOLD: 0, EPOCH: 2, LR: 0.009987, train_loss: 0.021753\n",
      "[>>VAL]: FOLD: 0, EPOCH: 2, valid_loss: 0.018219\n",
      "[TRAIN]: FOLD: 0, EPOCH: 3, LR: 0.009890, train_loss: 0.020637\n",
      "[>>VAL]: FOLD: 0, EPOCH: 3, valid_loss: 0.017968\n",
      "[TRAIN]: FOLD: 0, EPOCH: 4, LR: 0.009697, train_loss: 0.020359\n",
      "[>>VAL]: FOLD: 0, EPOCH: 4, valid_loss: 0.017987\n",
      "[TRAIN]: FOLD: 0, EPOCH: 5, LR: 0.009413, train_loss: 0.020202\n",
      "[>>VAL]: FOLD: 0, EPOCH: 5, valid_loss: 0.018036\n",
      "[TRAIN]: FOLD: 0, EPOCH: 6, LR: 0.009042, train_loss: 0.020164\n",
      "[>>VAL]: FOLD: 0, EPOCH: 6, valid_loss: 0.018390\n",
      "[TRAIN]: FOLD: 0, EPOCH: 7, LR: 0.008593, train_loss: 0.020272\n",
      "[>>VAL]: FOLD: 0, EPOCH: 7, valid_loss: 0.018046\n",
      "[TRAIN]: FOLD: 0, EPOCH: 8, LR: 0.008075, train_loss: 0.020218\n",
      "[>>VAL]: FOLD: 0, EPOCH: 8, valid_loss: 0.018070\n",
      "[TRAIN]: FOLD: 0, EPOCH: 9, LR: 0.007496, train_loss: 0.020253\n",
      "[>>VAL]: FOLD: 0, EPOCH: 9, valid_loss: 0.017799\n",
      "[TRAIN]: FOLD: 0, EPOCH: 10, LR: 0.006869, train_loss: 0.020208\n",
      "[>>VAL]: FOLD: 0, EPOCH: 10, valid_loss: 0.017648\n",
      "[TRAIN]: FOLD: 0, EPOCH: 11, LR: 0.006205, train_loss: 0.020119\n",
      "[>>VAL]: FOLD: 0, EPOCH: 11, valid_loss: 0.017857\n",
      "[TRAIN]: FOLD: 0, EPOCH: 12, LR: 0.005518, train_loss: 0.020045\n",
      "[>>VAL]: FOLD: 0, EPOCH: 12, valid_loss: 0.017793\n",
      "[TRAIN]: FOLD: 0, EPOCH: 13, LR: 0.004821, train_loss: 0.019962\n",
      "[>>VAL]: FOLD: 0, EPOCH: 13, valid_loss: 0.017688\n",
      "[TRAIN]: FOLD: 0, EPOCH: 14, LR: 0.004127, train_loss: 0.019857\n",
      "[>>VAL]: FOLD: 0, EPOCH: 14, valid_loss: 0.017724\n",
      "[TRAIN]: FOLD: 0, EPOCH: 15, LR: 0.003450, train_loss: 0.019694\n",
      "[>>VAL]: FOLD: 0, EPOCH: 15, valid_loss: 0.017685\n",
      "[TRAIN]: FOLD: 0, EPOCH: 16, LR: 0.002804, train_loss: 0.019458\n",
      "[>>VAL]: FOLD: 0, EPOCH: 16, valid_loss: 0.017474\n",
      "[TRAIN]: FOLD: 0, EPOCH: 17, LR: 0.002200, train_loss: 0.019262\n",
      "[>>VAL]: FOLD: 0, EPOCH: 17, valid_loss: 0.017447\n",
      "[TRAIN]: FOLD: 0, EPOCH: 18, LR: 0.001651, train_loss: 0.018935\n",
      "[>>VAL]: FOLD: 0, EPOCH: 18, valid_loss: 0.017424\n",
      "[TRAIN]: FOLD: 0, EPOCH: 19, LR: 0.001167, train_loss: 0.018576\n",
      "[>>VAL]: FOLD: 0, EPOCH: 19, valid_loss: 0.017383\n",
      "[TRAIN]: FOLD: 0, EPOCH: 20, LR: 0.000757, train_loss: 0.018209\n",
      "[>>VAL]: FOLD: 0, EPOCH: 20, valid_loss: 0.017251\n",
      "[TRAIN]: FOLD: 0, EPOCH: 21, LR: 0.000430, train_loss: 0.017675\n",
      "[>>VAL]: FOLD: 0, EPOCH: 21, valid_loss: 0.017190\n",
      "[TRAIN]: FOLD: 0, EPOCH: 22, LR: 0.000192, train_loss: 0.017233\n",
      "[>>VAL]: FOLD: 0, EPOCH: 22, valid_loss: 0.017201\n",
      "[TRAIN]: FOLD: 0, EPOCH: 23, LR: 0.000048, train_loss: 0.016879\n",
      "[>>VAL]: FOLD: 0, EPOCH: 23, valid_loss: 0.017258\n",
      "[TRAIN]: FOLD: 0, EPOCH: 24, LR: 0.000000, train_loss: 0.016706\n",
      "[>>VAL]: FOLD: 0, EPOCH: 24, valid_loss: 0.017244\n",
      "[TRAIN]: FOLD: 1, EPOCH: 0, LR: 0.003478, train_loss: 0.475719\n",
      "[>>VAL]: FOLD: 1, EPOCH: 0, valid_loss: 0.025171\n",
      "[TRAIN]: FOLD: 1, EPOCH: 1, LR: 0.009066, train_loss: 0.023890\n",
      "[>>VAL]: FOLD: 1, EPOCH: 1, valid_loss: 0.020371\n",
      "[TRAIN]: FOLD: 1, EPOCH: 2, LR: 0.009987, train_loss: 0.022047\n",
      "[>>VAL]: FOLD: 1, EPOCH: 2, valid_loss: 0.018181\n",
      "[TRAIN]: FOLD: 1, EPOCH: 3, LR: 0.009890, train_loss: 0.020690\n",
      "[>>VAL]: FOLD: 1, EPOCH: 3, valid_loss: 0.017583\n",
      "[TRAIN]: FOLD: 1, EPOCH: 4, LR: 0.009697, train_loss: 0.020281\n",
      "[>>VAL]: FOLD: 1, EPOCH: 4, valid_loss: 0.017784\n",
      "[TRAIN]: FOLD: 1, EPOCH: 5, LR: 0.009412, train_loss: 0.020214\n",
      "[>>VAL]: FOLD: 1, EPOCH: 5, valid_loss: 0.017543\n",
      "[TRAIN]: FOLD: 1, EPOCH: 6, LR: 0.009042, train_loss: 0.020273\n",
      "[>>VAL]: FOLD: 1, EPOCH: 6, valid_loss: 0.017934\n",
      "[TRAIN]: FOLD: 1, EPOCH: 7, LR: 0.008593, train_loss: 0.020247\n",
      "[>>VAL]: FOLD: 1, EPOCH: 7, valid_loss: 0.017640\n",
      "[TRAIN]: FOLD: 1, EPOCH: 8, LR: 0.008075, train_loss: 0.020321\n",
      "[>>VAL]: FOLD: 1, EPOCH: 8, valid_loss: 0.017588\n",
      "[TRAIN]: FOLD: 1, EPOCH: 9, LR: 0.007496, train_loss: 0.020240\n",
      "[>>VAL]: FOLD: 1, EPOCH: 9, valid_loss: 0.017545\n",
      "[TRAIN]: FOLD: 1, EPOCH: 10, LR: 0.006869, train_loss: 0.020261\n",
      "[>>VAL]: FOLD: 1, EPOCH: 10, valid_loss: 0.017761\n",
      "[TRAIN]: FOLD: 1, EPOCH: 11, LR: 0.006205, train_loss: 0.020161\n",
      "[>>VAL]: FOLD: 1, EPOCH: 11, valid_loss: 0.017637\n",
      "[TRAIN]: FOLD: 1, EPOCH: 12, LR: 0.005518, train_loss: 0.020094\n",
      "[>>VAL]: FOLD: 1, EPOCH: 12, valid_loss: 0.017582\n",
      "[TRAIN]: FOLD: 1, EPOCH: 13, LR: 0.004821, train_loss: 0.020017\n",
      "[>>VAL]: FOLD: 1, EPOCH: 13, valid_loss: 0.017505\n",
      "[TRAIN]: FOLD: 1, EPOCH: 14, LR: 0.004127, train_loss: 0.019874\n",
      "[>>VAL]: FOLD: 1, EPOCH: 14, valid_loss: 0.017313\n",
      "[TRAIN]: FOLD: 1, EPOCH: 15, LR: 0.003450, train_loss: 0.019780\n",
      "[>>VAL]: FOLD: 1, EPOCH: 15, valid_loss: 0.017402\n",
      "[TRAIN]: FOLD: 1, EPOCH: 16, LR: 0.002804, train_loss: 0.019538\n",
      "[>>VAL]: FOLD: 1, EPOCH: 16, valid_loss: 0.017115\n",
      "[TRAIN]: FOLD: 1, EPOCH: 17, LR: 0.002200, train_loss: 0.019293\n",
      "[>>VAL]: FOLD: 1, EPOCH: 17, valid_loss: 0.017111\n",
      "[TRAIN]: FOLD: 1, EPOCH: 18, LR: 0.001651, train_loss: 0.018958\n",
      "[>>VAL]: FOLD: 1, EPOCH: 18, valid_loss: 0.017179\n",
      "[TRAIN]: FOLD: 1, EPOCH: 19, LR: 0.001167, train_loss: 0.018558\n",
      "[>>VAL]: FOLD: 1, EPOCH: 19, valid_loss: 0.017113\n",
      "[TRAIN]: FOLD: 1, EPOCH: 20, LR: 0.000757, train_loss: 0.018209\n",
      "[>>VAL]: FOLD: 1, EPOCH: 20, valid_loss: 0.017066\n",
      "[TRAIN]: FOLD: 1, EPOCH: 21, LR: 0.000430, train_loss: 0.017712\n",
      "[>>VAL]: FOLD: 1, EPOCH: 21, valid_loss: 0.017012\n",
      "[TRAIN]: FOLD: 1, EPOCH: 22, LR: 0.000192, train_loss: 0.017226\n",
      "[>>VAL]: FOLD: 1, EPOCH: 22, valid_loss: 0.016984\n",
      "[TRAIN]: FOLD: 1, EPOCH: 23, LR: 0.000048, train_loss: 0.016877\n",
      "[>>VAL]: FOLD: 1, EPOCH: 23, valid_loss: 0.016988\n",
      "[TRAIN]: FOLD: 1, EPOCH: 24, LR: 0.000000, train_loss: 0.016707\n",
      "[>>VAL]: FOLD: 1, EPOCH: 24, valid_loss: 0.016997\n",
      "[TRAIN]: FOLD: 2, EPOCH: 0, LR: 0.003478, train_loss: 0.474177\n",
      "[>>VAL]: FOLD: 2, EPOCH: 0, valid_loss: 0.025303\n",
      "[TRAIN]: FOLD: 2, EPOCH: 1, LR: 0.009066, train_loss: 0.023747\n",
      "[>>VAL]: FOLD: 2, EPOCH: 1, valid_loss: 0.020178\n",
      "[TRAIN]: FOLD: 2, EPOCH: 2, LR: 0.009987, train_loss: 0.021878\n",
      "[>>VAL]: FOLD: 2, EPOCH: 2, valid_loss: 0.018610\n",
      "[TRAIN]: FOLD: 2, EPOCH: 3, LR: 0.009890, train_loss: 0.020511\n",
      "[>>VAL]: FOLD: 2, EPOCH: 3, valid_loss: 0.018496\n",
      "[TRAIN]: FOLD: 2, EPOCH: 4, LR: 0.009697, train_loss: 0.020136\n",
      "[>>VAL]: FOLD: 2, EPOCH: 4, valid_loss: 0.018523\n",
      "[TRAIN]: FOLD: 2, EPOCH: 5, LR: 0.009413, train_loss: 0.020104\n",
      "[>>VAL]: FOLD: 2, EPOCH: 5, valid_loss: 0.018889\n",
      "[TRAIN]: FOLD: 2, EPOCH: 6, LR: 0.009042, train_loss: 0.020075\n",
      "[>>VAL]: FOLD: 2, EPOCH: 6, valid_loss: 0.018612\n",
      "[TRAIN]: FOLD: 2, EPOCH: 7, LR: 0.008593, train_loss: 0.020125\n",
      "[>>VAL]: FOLD: 2, EPOCH: 7, valid_loss: 0.018434\n",
      "[TRAIN]: FOLD: 2, EPOCH: 8, LR: 0.008075, train_loss: 0.020151\n",
      "[>>VAL]: FOLD: 2, EPOCH: 8, valid_loss: 0.018577\n",
      "[TRAIN]: FOLD: 2, EPOCH: 9, LR: 0.007496, train_loss: 0.020121\n",
      "[>>VAL]: FOLD: 2, EPOCH: 9, valid_loss: 0.018562\n",
      "[TRAIN]: FOLD: 2, EPOCH: 10, LR: 0.006869, train_loss: 0.020109\n",
      "[>>VAL]: FOLD: 2, EPOCH: 10, valid_loss: 0.018264\n",
      "[TRAIN]: FOLD: 2, EPOCH: 11, LR: 0.006205, train_loss: 0.020064\n",
      "[>>VAL]: FOLD: 2, EPOCH: 11, valid_loss: 0.018400\n",
      "[TRAIN]: FOLD: 2, EPOCH: 12, LR: 0.005518, train_loss: 0.020007\n",
      "[>>VAL]: FOLD: 2, EPOCH: 12, valid_loss: 0.018059\n",
      "[TRAIN]: FOLD: 2, EPOCH: 13, LR: 0.004821, train_loss: 0.019899\n",
      "[>>VAL]: FOLD: 2, EPOCH: 13, valid_loss: 0.018078\n",
      "[TRAIN]: FOLD: 2, EPOCH: 14, LR: 0.004127, train_loss: 0.019771\n",
      "[>>VAL]: FOLD: 2, EPOCH: 14, valid_loss: 0.018311\n",
      "[TRAIN]: FOLD: 2, EPOCH: 15, LR: 0.003450, train_loss: 0.019645\n",
      "[>>VAL]: FOLD: 2, EPOCH: 15, valid_loss: 0.018137\n",
      "[TRAIN]: FOLD: 2, EPOCH: 16, LR: 0.002804, train_loss: 0.019431\n",
      "[>>VAL]: FOLD: 2, EPOCH: 16, valid_loss: 0.018021\n",
      "[TRAIN]: FOLD: 2, EPOCH: 17, LR: 0.002200, train_loss: 0.019159\n",
      "[>>VAL]: FOLD: 2, EPOCH: 17, valid_loss: 0.018015\n",
      "[TRAIN]: FOLD: 2, EPOCH: 18, LR: 0.001651, train_loss: 0.018865\n",
      "[>>VAL]: FOLD: 2, EPOCH: 18, valid_loss: 0.017858\n",
      "[TRAIN]: FOLD: 2, EPOCH: 19, LR: 0.001167, train_loss: 0.018534\n",
      "[>>VAL]: FOLD: 2, EPOCH: 19, valid_loss: 0.017803\n",
      "[TRAIN]: FOLD: 2, EPOCH: 20, LR: 0.000757, train_loss: 0.018049\n",
      "[>>VAL]: FOLD: 2, EPOCH: 20, valid_loss: 0.017913\n",
      "[TRAIN]: FOLD: 2, EPOCH: 21, LR: 0.000430, train_loss: 0.017539\n",
      "[>>VAL]: FOLD: 2, EPOCH: 21, valid_loss: 0.017933\n",
      "[TRAIN]: FOLD: 2, EPOCH: 22, LR: 0.000192, train_loss: 0.017092\n",
      "[>>VAL]: FOLD: 2, EPOCH: 22, valid_loss: 0.017921\n",
      "[TRAIN]: FOLD: 2, EPOCH: 23, LR: 0.000048, train_loss: 0.016710\n",
      "[>>VAL]: FOLD: 2, EPOCH: 23, valid_loss: 0.017907\n",
      "[TRAIN]: FOLD: 2, EPOCH: 24, LR: 0.000000, train_loss: 0.016566\n",
      "[>>VAL]: FOLD: 2, EPOCH: 24, valid_loss: 0.017889\n",
      "[TRAIN]: FOLD: 3, EPOCH: 0, LR: 0.003478, train_loss: 0.475486\n",
      "[>>VAL]: FOLD: 3, EPOCH: 0, valid_loss: 0.025319\n",
      "[TRAIN]: FOLD: 3, EPOCH: 1, LR: 0.009066, train_loss: 0.024004\n",
      "[>>VAL]: FOLD: 3, EPOCH: 1, valid_loss: 0.019234\n",
      "[TRAIN]: FOLD: 3, EPOCH: 2, LR: 0.009987, train_loss: 0.021854\n",
      "[>>VAL]: FOLD: 3, EPOCH: 2, valid_loss: 0.018150\n",
      "[TRAIN]: FOLD: 3, EPOCH: 3, LR: 0.009890, train_loss: 0.020781\n",
      "[>>VAL]: FOLD: 3, EPOCH: 3, valid_loss: 0.017638\n",
      "[TRAIN]: FOLD: 3, EPOCH: 4, LR: 0.009697, train_loss: 0.020296\n",
      "[>>VAL]: FOLD: 3, EPOCH: 4, valid_loss: 0.017654\n",
      "[TRAIN]: FOLD: 3, EPOCH: 5, LR: 0.009412, train_loss: 0.020221\n",
      "[>>VAL]: FOLD: 3, EPOCH: 5, valid_loss: 0.017651\n",
      "[TRAIN]: FOLD: 3, EPOCH: 6, LR: 0.009042, train_loss: 0.020270\n",
      "[>>VAL]: FOLD: 3, EPOCH: 6, valid_loss: 0.017566\n",
      "[TRAIN]: FOLD: 3, EPOCH: 7, LR: 0.008593, train_loss: 0.020316\n",
      "[>>VAL]: FOLD: 3, EPOCH: 7, valid_loss: 0.017719\n",
      "[TRAIN]: FOLD: 3, EPOCH: 8, LR: 0.008075, train_loss: 0.020295\n",
      "[>>VAL]: FOLD: 3, EPOCH: 8, valid_loss: 0.017791\n",
      "[TRAIN]: FOLD: 3, EPOCH: 9, LR: 0.007496, train_loss: 0.020360\n",
      "[>>VAL]: FOLD: 3, EPOCH: 9, valid_loss: 0.017557\n",
      "[TRAIN]: FOLD: 3, EPOCH: 10, LR: 0.006869, train_loss: 0.020281\n",
      "[>>VAL]: FOLD: 3, EPOCH: 10, valid_loss: 0.017693\n",
      "[TRAIN]: FOLD: 3, EPOCH: 11, LR: 0.006205, train_loss: 0.020223\n",
      "[>>VAL]: FOLD: 3, EPOCH: 11, valid_loss: 0.017866\n",
      "[TRAIN]: FOLD: 3, EPOCH: 12, LR: 0.005518, train_loss: 0.020136\n",
      "[>>VAL]: FOLD: 3, EPOCH: 12, valid_loss: 0.017772\n",
      "[TRAIN]: FOLD: 3, EPOCH: 13, LR: 0.004821, train_loss: 0.019986\n",
      "[>>VAL]: FOLD: 3, EPOCH: 13, valid_loss: 0.017442\n",
      "[TRAIN]: FOLD: 3, EPOCH: 14, LR: 0.004127, train_loss: 0.019922\n",
      "[>>VAL]: FOLD: 3, EPOCH: 14, valid_loss: 0.017260\n",
      "[TRAIN]: FOLD: 3, EPOCH: 15, LR: 0.003450, train_loss: 0.019760\n",
      "[>>VAL]: FOLD: 3, EPOCH: 15, valid_loss: 0.017278\n",
      "[TRAIN]: FOLD: 3, EPOCH: 16, LR: 0.002804, train_loss: 0.019444\n",
      "[>>VAL]: FOLD: 3, EPOCH: 16, valid_loss: 0.016981\n",
      "[TRAIN]: FOLD: 3, EPOCH: 17, LR: 0.002200, train_loss: 0.019281\n",
      "[>>VAL]: FOLD: 3, EPOCH: 17, valid_loss: 0.016914\n",
      "[TRAIN]: FOLD: 3, EPOCH: 18, LR: 0.001651, train_loss: 0.018967\n",
      "[>>VAL]: FOLD: 3, EPOCH: 18, valid_loss: 0.017056\n",
      "[TRAIN]: FOLD: 3, EPOCH: 19, LR: 0.001167, train_loss: 0.018586\n",
      "[>>VAL]: FOLD: 3, EPOCH: 19, valid_loss: 0.017113\n",
      "[TRAIN]: FOLD: 3, EPOCH: 20, LR: 0.000757, train_loss: 0.018198\n",
      "[>>VAL]: FOLD: 3, EPOCH: 20, valid_loss: 0.016935\n",
      "[TRAIN]: FOLD: 3, EPOCH: 21, LR: 0.000430, train_loss: 0.017690\n",
      "[>>VAL]: FOLD: 3, EPOCH: 21, valid_loss: 0.016902\n",
      "[TRAIN]: FOLD: 3, EPOCH: 22, LR: 0.000192, train_loss: 0.017184\n",
      "[>>VAL]: FOLD: 3, EPOCH: 22, valid_loss: 0.016935\n",
      "[TRAIN]: FOLD: 3, EPOCH: 23, LR: 0.000048, train_loss: 0.016810\n",
      "[>>VAL]: FOLD: 3, EPOCH: 23, valid_loss: 0.016940\n",
      "[TRAIN]: FOLD: 3, EPOCH: 24, LR: 0.000000, train_loss: 0.016623\n",
      "[>>VAL]: FOLD: 3, EPOCH: 24, valid_loss: 0.016946\n",
      "[TRAIN]: FOLD: 4, EPOCH: 0, LR: 0.003478, train_loss: 0.474678\n",
      "[>>VAL]: FOLD: 4, EPOCH: 0, valid_loss: 0.023944\n",
      "[TRAIN]: FOLD: 4, EPOCH: 1, LR: 0.009066, train_loss: 0.023678\n",
      "[>>VAL]: FOLD: 4, EPOCH: 1, valid_loss: 0.019252\n",
      "[TRAIN]: FOLD: 4, EPOCH: 2, LR: 0.009987, train_loss: 0.022746\n",
      "[>>VAL]: FOLD: 4, EPOCH: 2, valid_loss: 0.018582\n",
      "[TRAIN]: FOLD: 4, EPOCH: 3, LR: 0.009890, train_loss: 0.020991\n",
      "[>>VAL]: FOLD: 4, EPOCH: 3, valid_loss: 0.018262\n",
      "[TRAIN]: FOLD: 4, EPOCH: 4, LR: 0.009697, train_loss: 0.020445\n",
      "[>>VAL]: FOLD: 4, EPOCH: 4, valid_loss: 0.018044\n",
      "[TRAIN]: FOLD: 4, EPOCH: 5, LR: 0.009413, train_loss: 0.020230\n",
      "[>>VAL]: FOLD: 4, EPOCH: 5, valid_loss: 0.018073\n",
      "[TRAIN]: FOLD: 4, EPOCH: 6, LR: 0.009042, train_loss: 0.020176\n",
      "[>>VAL]: FOLD: 4, EPOCH: 6, valid_loss: 0.018557\n",
      "[TRAIN]: FOLD: 4, EPOCH: 7, LR: 0.008593, train_loss: 0.020175\n",
      "[>>VAL]: FOLD: 4, EPOCH: 7, valid_loss: 0.018147\n",
      "[TRAIN]: FOLD: 4, EPOCH: 8, LR: 0.008075, train_loss: 0.020204\n",
      "[>>VAL]: FOLD: 4, EPOCH: 8, valid_loss: 0.018129\n",
      "[TRAIN]: FOLD: 4, EPOCH: 9, LR: 0.007496, train_loss: 0.020193\n",
      "[>>VAL]: FOLD: 4, EPOCH: 9, valid_loss: 0.018220\n",
      "[TRAIN]: FOLD: 4, EPOCH: 10, LR: 0.006869, train_loss: 0.020146\n",
      "[>>VAL]: FOLD: 4, EPOCH: 10, valid_loss: 0.018153\n",
      "[TRAIN]: FOLD: 4, EPOCH: 11, LR: 0.006205, train_loss: 0.020164\n",
      "[>>VAL]: FOLD: 4, EPOCH: 11, valid_loss: 0.017878\n",
      "[TRAIN]: FOLD: 4, EPOCH: 12, LR: 0.005518, train_loss: 0.020079\n",
      "[>>VAL]: FOLD: 4, EPOCH: 12, valid_loss: 0.017954\n",
      "[TRAIN]: FOLD: 4, EPOCH: 13, LR: 0.004821, train_loss: 0.019993\n",
      "[>>VAL]: FOLD: 4, EPOCH: 13, valid_loss: 0.017944\n",
      "[TRAIN]: FOLD: 4, EPOCH: 14, LR: 0.004127, train_loss: 0.019789\n",
      "[>>VAL]: FOLD: 4, EPOCH: 14, valid_loss: 0.017718\n",
      "[TRAIN]: FOLD: 4, EPOCH: 15, LR: 0.003450, train_loss: 0.019636\n",
      "[>>VAL]: FOLD: 4, EPOCH: 15, valid_loss: 0.017688\n",
      "[TRAIN]: FOLD: 4, EPOCH: 16, LR: 0.002804, train_loss: 0.019428\n",
      "[>>VAL]: FOLD: 4, EPOCH: 16, valid_loss: 0.017725\n",
      "[TRAIN]: FOLD: 4, EPOCH: 17, LR: 0.002200, train_loss: 0.019339\n",
      "[>>VAL]: FOLD: 4, EPOCH: 17, valid_loss: 0.017612\n",
      "[TRAIN]: FOLD: 4, EPOCH: 18, LR: 0.001651, train_loss: 0.018928\n",
      "[>>VAL]: FOLD: 4, EPOCH: 18, valid_loss: 0.017555\n",
      "[TRAIN]: FOLD: 4, EPOCH: 19, LR: 0.001167, train_loss: 0.018574\n",
      "[>>VAL]: FOLD: 4, EPOCH: 19, valid_loss: 0.017599\n",
      "[TRAIN]: FOLD: 4, EPOCH: 20, LR: 0.000757, train_loss: 0.018143\n",
      "[>>VAL]: FOLD: 4, EPOCH: 20, valid_loss: 0.017504\n",
      "[TRAIN]: FOLD: 4, EPOCH: 21, LR: 0.000430, train_loss: 0.017634\n",
      "[>>VAL]: FOLD: 4, EPOCH: 21, valid_loss: 0.017524\n",
      "[TRAIN]: FOLD: 4, EPOCH: 22, LR: 0.000192, train_loss: 0.017167\n",
      "[>>VAL]: FOLD: 4, EPOCH: 22, valid_loss: 0.017501\n",
      "[TRAIN]: FOLD: 4, EPOCH: 23, LR: 0.000048, train_loss: 0.016758\n",
      "[>>VAL]: FOLD: 4, EPOCH: 23, valid_loss: 0.017523\n",
      "[TRAIN]: FOLD: 4, EPOCH: 24, LR: 0.000000, train_loss: 0.016548\n",
      "[>>VAL]: FOLD: 4, EPOCH: 24, valid_loss: 0.017499\n",
      "[TRAIN]: FOLD: 5, EPOCH: 0, LR: 0.003478, train_loss: 0.475751\n",
      "[>>VAL]: FOLD: 5, EPOCH: 0, valid_loss: 0.025225\n",
      "[TRAIN]: FOLD: 5, EPOCH: 1, LR: 0.009066, train_loss: 0.023961\n",
      "[>>VAL]: FOLD: 5, EPOCH: 1, valid_loss: 0.019657\n",
      "[TRAIN]: FOLD: 5, EPOCH: 2, LR: 0.009987, train_loss: 0.021645\n",
      "[>>VAL]: FOLD: 5, EPOCH: 2, valid_loss: 0.018715\n",
      "[TRAIN]: FOLD: 5, EPOCH: 3, LR: 0.009890, train_loss: 0.020573\n",
      "[>>VAL]: FOLD: 5, EPOCH: 3, valid_loss: 0.018180\n",
      "[TRAIN]: FOLD: 5, EPOCH: 4, LR: 0.009697, train_loss: 0.020236\n",
      "[>>VAL]: FOLD: 5, EPOCH: 4, valid_loss: 0.018389\n",
      "[TRAIN]: FOLD: 5, EPOCH: 5, LR: 0.009412, train_loss: 0.020123\n",
      "[>>VAL]: FOLD: 5, EPOCH: 5, valid_loss: 0.018324\n",
      "[TRAIN]: FOLD: 5, EPOCH: 6, LR: 0.009042, train_loss: 0.020084\n",
      "[>>VAL]: FOLD: 5, EPOCH: 6, valid_loss: 0.017997\n",
      "[TRAIN]: FOLD: 5, EPOCH: 7, LR: 0.008593, train_loss: 0.020116\n",
      "[>>VAL]: FOLD: 5, EPOCH: 7, valid_loss: 0.018484\n",
      "[TRAIN]: FOLD: 5, EPOCH: 8, LR: 0.008075, train_loss: 0.020183\n",
      "[>>VAL]: FOLD: 5, EPOCH: 8, valid_loss: 0.018135\n",
      "[TRAIN]: FOLD: 5, EPOCH: 9, LR: 0.007496, train_loss: 0.020127\n",
      "[>>VAL]: FOLD: 5, EPOCH: 9, valid_loss: 0.018138\n",
      "[TRAIN]: FOLD: 5, EPOCH: 10, LR: 0.006869, train_loss: 0.020112\n",
      "[>>VAL]: FOLD: 5, EPOCH: 10, valid_loss: 0.018077\n",
      "[TRAIN]: FOLD: 5, EPOCH: 11, LR: 0.006205, train_loss: 0.020105\n",
      "[>>VAL]: FOLD: 5, EPOCH: 11, valid_loss: 0.018123\n",
      "[TRAIN]: FOLD: 5, EPOCH: 12, LR: 0.005518, train_loss: 0.019873\n",
      "[>>VAL]: FOLD: 5, EPOCH: 12, valid_loss: 0.018107\n",
      "[TRAIN]: FOLD: 5, EPOCH: 13, LR: 0.004821, train_loss: 0.019801\n",
      "[>>VAL]: FOLD: 5, EPOCH: 13, valid_loss: 0.018214\n",
      "[TRAIN]: FOLD: 5, EPOCH: 14, LR: 0.004127, train_loss: 0.019680\n",
      "[>>VAL]: FOLD: 5, EPOCH: 14, valid_loss: 0.018107\n",
      "[TRAIN]: FOLD: 5, EPOCH: 15, LR: 0.003450, train_loss: 0.019530\n",
      "[>>VAL]: FOLD: 5, EPOCH: 15, valid_loss: 0.018062\n",
      "[TRAIN]: FOLD: 5, EPOCH: 16, LR: 0.002804, train_loss: 0.019320\n",
      "[>>VAL]: FOLD: 5, EPOCH: 16, valid_loss: 0.017905\n",
      "[TRAIN]: FOLD: 5, EPOCH: 17, LR: 0.002200, train_loss: 0.019052\n",
      "[>>VAL]: FOLD: 5, EPOCH: 17, valid_loss: 0.017894\n",
      "[TRAIN]: FOLD: 5, EPOCH: 18, LR: 0.001651, train_loss: 0.018779\n",
      "[>>VAL]: FOLD: 5, EPOCH: 18, valid_loss: 0.018028\n",
      "[TRAIN]: FOLD: 5, EPOCH: 19, LR: 0.001167, train_loss: 0.018431\n",
      "[>>VAL]: FOLD: 5, EPOCH: 19, valid_loss: 0.017709\n",
      "[TRAIN]: FOLD: 5, EPOCH: 20, LR: 0.000757, train_loss: 0.018006\n",
      "[>>VAL]: FOLD: 5, EPOCH: 20, valid_loss: 0.017991\n",
      "[TRAIN]: FOLD: 5, EPOCH: 21, LR: 0.000430, train_loss: 0.017450\n",
      "[>>VAL]: FOLD: 5, EPOCH: 21, valid_loss: 0.017829\n",
      "[TRAIN]: FOLD: 5, EPOCH: 22, LR: 0.000192, train_loss: 0.017011\n",
      "[>>VAL]: FOLD: 5, EPOCH: 22, valid_loss: 0.017817\n",
      "[TRAIN]: FOLD: 5, EPOCH: 23, LR: 0.000048, train_loss: 0.016688\n",
      "[>>VAL]: FOLD: 5, EPOCH: 23, valid_loss: 0.017864\n",
      "[TRAIN]: FOLD: 5, EPOCH: 24, LR: 0.000000, train_loss: 0.016441\n",
      "[>>VAL]: FOLD: 5, EPOCH: 24, valid_loss: 0.017896\n",
      "[TRAIN]: FOLD: 6, EPOCH: 0, LR: 0.003478, train_loss: 0.475753\n",
      "[>>VAL]: FOLD: 6, EPOCH: 0, valid_loss: 0.024354\n",
      "[TRAIN]: FOLD: 6, EPOCH: 1, LR: 0.009066, train_loss: 0.023883\n",
      "[>>VAL]: FOLD: 6, EPOCH: 1, valid_loss: 0.018619\n",
      "[TRAIN]: FOLD: 6, EPOCH: 2, LR: 0.009987, train_loss: 0.021888\n",
      "[>>VAL]: FOLD: 6, EPOCH: 2, valid_loss: 0.017736\n",
      "[TRAIN]: FOLD: 6, EPOCH: 3, LR: 0.009890, train_loss: 0.020705\n",
      "[>>VAL]: FOLD: 6, EPOCH: 3, valid_loss: 0.017187\n",
      "[TRAIN]: FOLD: 6, EPOCH: 4, LR: 0.009697, train_loss: 0.020327\n",
      "[>>VAL]: FOLD: 6, EPOCH: 4, valid_loss: 0.017225\n",
      "[TRAIN]: FOLD: 6, EPOCH: 5, LR: 0.009413, train_loss: 0.020361\n",
      "[>>VAL]: FOLD: 6, EPOCH: 5, valid_loss: 0.017378\n",
      "[TRAIN]: FOLD: 6, EPOCH: 6, LR: 0.009042, train_loss: 0.020290\n",
      "[>>VAL]: FOLD: 6, EPOCH: 6, valid_loss: 0.017166\n",
      "[TRAIN]: FOLD: 6, EPOCH: 7, LR: 0.008593, train_loss: 0.020314\n",
      "[>>VAL]: FOLD: 6, EPOCH: 7, valid_loss: 0.017250\n",
      "[TRAIN]: FOLD: 6, EPOCH: 8, LR: 0.008075, train_loss: 0.020272\n",
      "[>>VAL]: FOLD: 6, EPOCH: 8, valid_loss: 0.017148\n",
      "[TRAIN]: FOLD: 6, EPOCH: 9, LR: 0.007496, train_loss: 0.020332\n",
      "[>>VAL]: FOLD: 6, EPOCH: 9, valid_loss: 0.017412\n",
      "[TRAIN]: FOLD: 6, EPOCH: 10, LR: 0.006869, train_loss: 0.020257\n",
      "[>>VAL]: FOLD: 6, EPOCH: 10, valid_loss: 0.017155\n",
      "[TRAIN]: FOLD: 6, EPOCH: 11, LR: 0.006205, train_loss: 0.020209\n",
      "[>>VAL]: FOLD: 6, EPOCH: 11, valid_loss: 0.017093\n",
      "[TRAIN]: FOLD: 6, EPOCH: 12, LR: 0.005518, train_loss: 0.020119\n",
      "[>>VAL]: FOLD: 6, EPOCH: 12, valid_loss: 0.017071\n",
      "[TRAIN]: FOLD: 6, EPOCH: 13, LR: 0.004821, train_loss: 0.020076\n",
      "[>>VAL]: FOLD: 6, EPOCH: 13, valid_loss: 0.017518\n",
      "[TRAIN]: FOLD: 6, EPOCH: 14, LR: 0.004127, train_loss: 0.019896\n",
      "[>>VAL]: FOLD: 6, EPOCH: 14, valid_loss: 0.017261\n",
      "[TRAIN]: FOLD: 6, EPOCH: 15, LR: 0.003450, train_loss: 0.019748\n",
      "[>>VAL]: FOLD: 6, EPOCH: 15, valid_loss: 0.017099\n",
      "[TRAIN]: FOLD: 6, EPOCH: 16, LR: 0.002804, train_loss: 0.019556\n",
      "[>>VAL]: FOLD: 6, EPOCH: 16, valid_loss: 0.017202\n",
      "[TRAIN]: FOLD: 6, EPOCH: 17, LR: 0.002200, train_loss: 0.019311\n",
      "[>>VAL]: FOLD: 6, EPOCH: 17, valid_loss: 0.016860\n",
      "[TRAIN]: FOLD: 6, EPOCH: 18, LR: 0.001651, train_loss: 0.019019\n",
      "[>>VAL]: FOLD: 6, EPOCH: 18, valid_loss: 0.016770\n",
      "[TRAIN]: FOLD: 6, EPOCH: 19, LR: 0.001167, train_loss: 0.018641\n",
      "[>>VAL]: FOLD: 6, EPOCH: 19, valid_loss: 0.016682\n",
      "[TRAIN]: FOLD: 6, EPOCH: 20, LR: 0.000757, train_loss: 0.018269\n",
      "[>>VAL]: FOLD: 6, EPOCH: 20, valid_loss: 0.016878\n",
      "[TRAIN]: FOLD: 6, EPOCH: 21, LR: 0.000430, train_loss: 0.017805\n",
      "[>>VAL]: FOLD: 6, EPOCH: 21, valid_loss: 0.016828\n",
      "[TRAIN]: FOLD: 6, EPOCH: 22, LR: 0.000192, train_loss: 0.017357\n",
      "[>>VAL]: FOLD: 6, EPOCH: 22, valid_loss: 0.016769\n",
      "[TRAIN]: FOLD: 6, EPOCH: 23, LR: 0.000048, train_loss: 0.016948\n",
      "[>>VAL]: FOLD: 6, EPOCH: 23, valid_loss: 0.016846\n",
      "[TRAIN]: FOLD: 6, EPOCH: 24, LR: 0.000000, train_loss: 0.016801\n",
      "[>>VAL]: FOLD: 6, EPOCH: 24, valid_loss: 0.016805\n",
      "\n",
      ">> SEED: 2\n",
      "\n",
      "[TRAIN]: FOLD: 0, EPOCH: 0, LR: 0.003478, train_loss: 0.473708\n",
      "[>>VAL]: FOLD: 0, EPOCH: 0, valid_loss: 0.024779\n",
      "[TRAIN]: FOLD: 0, EPOCH: 1, LR: 0.009066, train_loss: 0.023698\n",
      "[>>VAL]: FOLD: 0, EPOCH: 1, valid_loss: 0.019453\n",
      "[TRAIN]: FOLD: 0, EPOCH: 2, LR: 0.009987, train_loss: 0.021815\n",
      "[>>VAL]: FOLD: 0, EPOCH: 2, valid_loss: 0.018314\n",
      "[TRAIN]: FOLD: 0, EPOCH: 3, LR: 0.009890, train_loss: 0.020867\n",
      "[>>VAL]: FOLD: 0, EPOCH: 3, valid_loss: 0.021232\n",
      "[TRAIN]: FOLD: 0, EPOCH: 4, LR: 0.009697, train_loss: 0.020431\n",
      "[>>VAL]: FOLD: 0, EPOCH: 4, valid_loss: 0.018086\n",
      "[TRAIN]: FOLD: 0, EPOCH: 5, LR: 0.009413, train_loss: 0.020196\n",
      "[>>VAL]: FOLD: 0, EPOCH: 5, valid_loss: 0.017791\n",
      "[TRAIN]: FOLD: 0, EPOCH: 6, LR: 0.009042, train_loss: 0.020233\n",
      "[>>VAL]: FOLD: 0, EPOCH: 6, valid_loss: 0.018108\n",
      "[TRAIN]: FOLD: 0, EPOCH: 7, LR: 0.008593, train_loss: 0.020245\n",
      "[>>VAL]: FOLD: 0, EPOCH: 7, valid_loss: 0.017753\n",
      "[TRAIN]: FOLD: 0, EPOCH: 8, LR: 0.008075, train_loss: 0.020194\n",
      "[>>VAL]: FOLD: 0, EPOCH: 8, valid_loss: 0.018666\n",
      "[TRAIN]: FOLD: 0, EPOCH: 9, LR: 0.007496, train_loss: 0.020224\n",
      "[>>VAL]: FOLD: 0, EPOCH: 9, valid_loss: 0.018160\n",
      "[TRAIN]: FOLD: 0, EPOCH: 10, LR: 0.006869, train_loss: 0.020227\n",
      "[>>VAL]: FOLD: 0, EPOCH: 10, valid_loss: 0.018187\n",
      "[TRAIN]: FOLD: 0, EPOCH: 11, LR: 0.006205, train_loss: 0.020203\n",
      "[>>VAL]: FOLD: 0, EPOCH: 11, valid_loss: 0.017836\n",
      "[TRAIN]: FOLD: 0, EPOCH: 12, LR: 0.005518, train_loss: 0.020080\n",
      "[>>VAL]: FOLD: 0, EPOCH: 12, valid_loss: 0.017849\n",
      "[TRAIN]: FOLD: 0, EPOCH: 13, LR: 0.004821, train_loss: 0.019961\n",
      "[>>VAL]: FOLD: 0, EPOCH: 13, valid_loss: 0.017750\n",
      "[TRAIN]: FOLD: 0, EPOCH: 14, LR: 0.004127, train_loss: 0.019811\n",
      "[>>VAL]: FOLD: 0, EPOCH: 14, valid_loss: 0.017629\n",
      "[TRAIN]: FOLD: 0, EPOCH: 15, LR: 0.003450, train_loss: 0.019713\n",
      "[>>VAL]: FOLD: 0, EPOCH: 15, valid_loss: 0.017598\n",
      "[TRAIN]: FOLD: 0, EPOCH: 16, LR: 0.002804, train_loss: 0.019464\n",
      "[>>VAL]: FOLD: 0, EPOCH: 16, valid_loss: 0.017710\n",
      "[TRAIN]: FOLD: 0, EPOCH: 17, LR: 0.002200, train_loss: 0.019242\n",
      "[>>VAL]: FOLD: 0, EPOCH: 17, valid_loss: 0.017583\n",
      "[TRAIN]: FOLD: 0, EPOCH: 18, LR: 0.001651, train_loss: 0.018927\n",
      "[>>VAL]: FOLD: 0, EPOCH: 18, valid_loss: 0.017442\n",
      "[TRAIN]: FOLD: 0, EPOCH: 19, LR: 0.001167, train_loss: 0.018601\n",
      "[>>VAL]: FOLD: 0, EPOCH: 19, valid_loss: 0.017425\n",
      "[TRAIN]: FOLD: 0, EPOCH: 20, LR: 0.000757, train_loss: 0.018163\n",
      "[>>VAL]: FOLD: 0, EPOCH: 20, valid_loss: 0.017305\n",
      "[TRAIN]: FOLD: 0, EPOCH: 21, LR: 0.000430, train_loss: 0.017682\n",
      "[>>VAL]: FOLD: 0, EPOCH: 21, valid_loss: 0.017262\n",
      "[TRAIN]: FOLD: 0, EPOCH: 22, LR: 0.000192, train_loss: 0.017191\n",
      "[>>VAL]: FOLD: 0, EPOCH: 22, valid_loss: 0.017332\n",
      "[TRAIN]: FOLD: 0, EPOCH: 23, LR: 0.000048, train_loss: 0.016829\n",
      "[>>VAL]: FOLD: 0, EPOCH: 23, valid_loss: 0.017336\n",
      "[TRAIN]: FOLD: 0, EPOCH: 24, LR: 0.000000, train_loss: 0.016623\n",
      "[>>VAL]: FOLD: 0, EPOCH: 24, valid_loss: 0.017341\n",
      "[TRAIN]: FOLD: 1, EPOCH: 0, LR: 0.003478, train_loss: 0.475826\n",
      "[>>VAL]: FOLD: 1, EPOCH: 0, valid_loss: 0.024138\n",
      "[TRAIN]: FOLD: 1, EPOCH: 1, LR: 0.009066, train_loss: 0.024127\n",
      "[>>VAL]: FOLD: 1, EPOCH: 1, valid_loss: 0.019006\n",
      "[TRAIN]: FOLD: 1, EPOCH: 2, LR: 0.009987, train_loss: 0.021846\n",
      "[>>VAL]: FOLD: 1, EPOCH: 2, valid_loss: 0.018347\n",
      "[TRAIN]: FOLD: 1, EPOCH: 3, LR: 0.009890, train_loss: 0.020662\n",
      "[>>VAL]: FOLD: 1, EPOCH: 3, valid_loss: 0.018992\n",
      "[TRAIN]: FOLD: 1, EPOCH: 4, LR: 0.009697, train_loss: 0.020295\n",
      "[>>VAL]: FOLD: 1, EPOCH: 4, valid_loss: 0.017462\n",
      "[TRAIN]: FOLD: 1, EPOCH: 5, LR: 0.009412, train_loss: 0.020249\n",
      "[>>VAL]: FOLD: 1, EPOCH: 5, valid_loss: 0.018113\n",
      "[TRAIN]: FOLD: 1, EPOCH: 6, LR: 0.009042, train_loss: 0.020272\n",
      "[>>VAL]: FOLD: 1, EPOCH: 6, valid_loss: 0.017520\n",
      "[TRAIN]: FOLD: 1, EPOCH: 7, LR: 0.008593, train_loss: 0.020249\n",
      "[>>VAL]: FOLD: 1, EPOCH: 7, valid_loss: 0.017660\n",
      "[TRAIN]: FOLD: 1, EPOCH: 8, LR: 0.008075, train_loss: 0.020261\n",
      "[>>VAL]: FOLD: 1, EPOCH: 8, valid_loss: 0.017443\n",
      "[TRAIN]: FOLD: 1, EPOCH: 9, LR: 0.007496, train_loss: 0.020175\n",
      "[>>VAL]: FOLD: 1, EPOCH: 9, valid_loss: 0.017619\n",
      "[TRAIN]: FOLD: 1, EPOCH: 10, LR: 0.006869, train_loss: 0.020159\n",
      "[>>VAL]: FOLD: 1, EPOCH: 10, valid_loss: 0.017644\n",
      "[TRAIN]: FOLD: 1, EPOCH: 11, LR: 0.006205, train_loss: 0.020266\n",
      "[>>VAL]: FOLD: 1, EPOCH: 11, valid_loss: 0.017457\n",
      "[TRAIN]: FOLD: 1, EPOCH: 12, LR: 0.005518, train_loss: 0.020030\n",
      "[>>VAL]: FOLD: 1, EPOCH: 12, valid_loss: 0.017486\n",
      "[TRAIN]: FOLD: 1, EPOCH: 13, LR: 0.004821, train_loss: 0.020061\n",
      "[>>VAL]: FOLD: 1, EPOCH: 13, valid_loss: 0.017265\n",
      "[TRAIN]: FOLD: 1, EPOCH: 14, LR: 0.004127, train_loss: 0.019844\n",
      "[>>VAL]: FOLD: 1, EPOCH: 14, valid_loss: 0.017448\n",
      "[TRAIN]: FOLD: 1, EPOCH: 15, LR: 0.003450, train_loss: 0.019726\n",
      "[>>VAL]: FOLD: 1, EPOCH: 15, valid_loss: 0.017440\n",
      "[TRAIN]: FOLD: 1, EPOCH: 16, LR: 0.002804, train_loss: 0.019489\n",
      "[>>VAL]: FOLD: 1, EPOCH: 16, valid_loss: 0.017079\n",
      "[TRAIN]: FOLD: 1, EPOCH: 17, LR: 0.002200, train_loss: 0.019255\n",
      "[>>VAL]: FOLD: 1, EPOCH: 17, valid_loss: 0.017364\n",
      "[TRAIN]: FOLD: 1, EPOCH: 18, LR: 0.001651, train_loss: 0.018952\n",
      "[>>VAL]: FOLD: 1, EPOCH: 18, valid_loss: 0.017110\n",
      "[TRAIN]: FOLD: 1, EPOCH: 19, LR: 0.001167, train_loss: 0.018598\n",
      "[>>VAL]: FOLD: 1, EPOCH: 19, valid_loss: 0.017001\n",
      "[TRAIN]: FOLD: 1, EPOCH: 20, LR: 0.000757, train_loss: 0.018111\n",
      "[>>VAL]: FOLD: 1, EPOCH: 20, valid_loss: 0.017011\n",
      "[TRAIN]: FOLD: 1, EPOCH: 21, LR: 0.000430, train_loss: 0.017692\n",
      "[>>VAL]: FOLD: 1, EPOCH: 21, valid_loss: 0.016956\n",
      "[TRAIN]: FOLD: 1, EPOCH: 22, LR: 0.000192, train_loss: 0.017289\n",
      "[>>VAL]: FOLD: 1, EPOCH: 22, valid_loss: 0.016974\n",
      "[TRAIN]: FOLD: 1, EPOCH: 23, LR: 0.000048, train_loss: 0.016968\n",
      "[>>VAL]: FOLD: 1, EPOCH: 23, valid_loss: 0.016952\n",
      "[TRAIN]: FOLD: 1, EPOCH: 24, LR: 0.000000, train_loss: 0.016816\n",
      "[>>VAL]: FOLD: 1, EPOCH: 24, valid_loss: 0.016969\n",
      "[TRAIN]: FOLD: 2, EPOCH: 0, LR: 0.003478, train_loss: 0.472963\n",
      "[>>VAL]: FOLD: 2, EPOCH: 0, valid_loss: 0.026069\n",
      "[TRAIN]: FOLD: 2, EPOCH: 1, LR: 0.009066, train_loss: 0.024115\n",
      "[>>VAL]: FOLD: 2, EPOCH: 1, valid_loss: 0.019899\n",
      "[TRAIN]: FOLD: 2, EPOCH: 2, LR: 0.009987, train_loss: 0.021796\n",
      "[>>VAL]: FOLD: 2, EPOCH: 2, valid_loss: 0.018588\n",
      "[TRAIN]: FOLD: 2, EPOCH: 3, LR: 0.009890, train_loss: 0.020587\n",
      "[>>VAL]: FOLD: 2, EPOCH: 3, valid_loss: 0.018278\n",
      "[TRAIN]: FOLD: 2, EPOCH: 4, LR: 0.009697, train_loss: 0.020134\n",
      "[>>VAL]: FOLD: 2, EPOCH: 4, valid_loss: 0.018546\n",
      "[TRAIN]: FOLD: 2, EPOCH: 5, LR: 0.009413, train_loss: 0.020043\n",
      "[>>VAL]: FOLD: 2, EPOCH: 5, valid_loss: 0.018520\n",
      "[TRAIN]: FOLD: 2, EPOCH: 6, LR: 0.009042, train_loss: 0.020063\n",
      "[>>VAL]: FOLD: 2, EPOCH: 6, valid_loss: 0.018472\n",
      "[TRAIN]: FOLD: 2, EPOCH: 7, LR: 0.008593, train_loss: 0.020073\n",
      "[>>VAL]: FOLD: 2, EPOCH: 7, valid_loss: 0.018374\n",
      "[TRAIN]: FOLD: 2, EPOCH: 8, LR: 0.008075, train_loss: 0.020114\n",
      "[>>VAL]: FOLD: 2, EPOCH: 8, valid_loss: 0.018344\n",
      "[TRAIN]: FOLD: 2, EPOCH: 9, LR: 0.007496, train_loss: 0.020125\n",
      "[>>VAL]: FOLD: 2, EPOCH: 9, valid_loss: 0.018529\n",
      "[TRAIN]: FOLD: 2, EPOCH: 10, LR: 0.006869, train_loss: 0.020124\n",
      "[>>VAL]: FOLD: 2, EPOCH: 10, valid_loss: 0.018409\n",
      "[TRAIN]: FOLD: 2, EPOCH: 11, LR: 0.006205, train_loss: 0.019979\n",
      "[>>VAL]: FOLD: 2, EPOCH: 11, valid_loss: 0.018370\n",
      "[TRAIN]: FOLD: 2, EPOCH: 12, LR: 0.005518, train_loss: 0.019985\n",
      "[>>VAL]: FOLD: 2, EPOCH: 12, valid_loss: 0.018347\n",
      "[TRAIN]: FOLD: 2, EPOCH: 13, LR: 0.004821, train_loss: 0.019860\n",
      "[>>VAL]: FOLD: 2, EPOCH: 13, valid_loss: 0.018327\n",
      "[TRAIN]: FOLD: 2, EPOCH: 14, LR: 0.004127, train_loss: 0.019707\n",
      "[>>VAL]: FOLD: 2, EPOCH: 14, valid_loss: 0.018099\n",
      "[TRAIN]: FOLD: 2, EPOCH: 15, LR: 0.003450, train_loss: 0.019616\n",
      "[>>VAL]: FOLD: 2, EPOCH: 15, valid_loss: 0.018286\n",
      "[TRAIN]: FOLD: 2, EPOCH: 16, LR: 0.002804, train_loss: 0.019379\n",
      "[>>VAL]: FOLD: 2, EPOCH: 16, valid_loss: 0.018048\n",
      "[TRAIN]: FOLD: 2, EPOCH: 17, LR: 0.002200, train_loss: 0.019099\n",
      "[>>VAL]: FOLD: 2, EPOCH: 17, valid_loss: 0.017962\n",
      "[TRAIN]: FOLD: 2, EPOCH: 18, LR: 0.001651, train_loss: 0.018815\n",
      "[>>VAL]: FOLD: 2, EPOCH: 18, valid_loss: 0.017943\n",
      "[TRAIN]: FOLD: 2, EPOCH: 19, LR: 0.001167, train_loss: 0.018481\n",
      "[>>VAL]: FOLD: 2, EPOCH: 19, valid_loss: 0.017767\n",
      "[TRAIN]: FOLD: 2, EPOCH: 20, LR: 0.000757, train_loss: 0.018046\n",
      "[>>VAL]: FOLD: 2, EPOCH: 20, valid_loss: 0.017829\n",
      "[TRAIN]: FOLD: 2, EPOCH: 21, LR: 0.000430, train_loss: 0.017524\n",
      "[>>VAL]: FOLD: 2, EPOCH: 21, valid_loss: 0.017765\n",
      "[TRAIN]: FOLD: 2, EPOCH: 22, LR: 0.000192, train_loss: 0.017107\n",
      "[>>VAL]: FOLD: 2, EPOCH: 22, valid_loss: 0.017800\n",
      "[TRAIN]: FOLD: 2, EPOCH: 23, LR: 0.000048, train_loss: 0.016700\n",
      "[>>VAL]: FOLD: 2, EPOCH: 23, valid_loss: 0.017827\n",
      "[TRAIN]: FOLD: 2, EPOCH: 24, LR: 0.000000, train_loss: 0.016523\n",
      "[>>VAL]: FOLD: 2, EPOCH: 24, valid_loss: 0.017833\n",
      "[TRAIN]: FOLD: 3, EPOCH: 0, LR: 0.003478, train_loss: 0.475038\n",
      "[>>VAL]: FOLD: 3, EPOCH: 0, valid_loss: 0.024239\n",
      "[TRAIN]: FOLD: 3, EPOCH: 1, LR: 0.009066, train_loss: 0.023762\n",
      "[>>VAL]: FOLD: 3, EPOCH: 1, valid_loss: 0.019217\n",
      "[TRAIN]: FOLD: 3, EPOCH: 2, LR: 0.009987, train_loss: 0.022051\n",
      "[>>VAL]: FOLD: 3, EPOCH: 2, valid_loss: 0.017994\n",
      "[TRAIN]: FOLD: 3, EPOCH: 3, LR: 0.009890, train_loss: 0.020682\n",
      "[>>VAL]: FOLD: 3, EPOCH: 3, valid_loss: 0.017763\n",
      "[TRAIN]: FOLD: 3, EPOCH: 4, LR: 0.009697, train_loss: 0.020236\n",
      "[>>VAL]: FOLD: 3, EPOCH: 4, valid_loss: 0.017935\n",
      "[TRAIN]: FOLD: 3, EPOCH: 5, LR: 0.009412, train_loss: 0.020259\n",
      "[>>VAL]: FOLD: 3, EPOCH: 5, valid_loss: 0.017741\n",
      "[TRAIN]: FOLD: 3, EPOCH: 6, LR: 0.009042, train_loss: 0.020225\n",
      "[>>VAL]: FOLD: 3, EPOCH: 6, valid_loss: 0.017807\n",
      "[TRAIN]: FOLD: 3, EPOCH: 7, LR: 0.008593, train_loss: 0.020298\n",
      "[>>VAL]: FOLD: 3, EPOCH: 7, valid_loss: 0.018091\n",
      "[TRAIN]: FOLD: 3, EPOCH: 8, LR: 0.008075, train_loss: 0.020313\n",
      "[>>VAL]: FOLD: 3, EPOCH: 8, valid_loss: 0.017483\n",
      "[TRAIN]: FOLD: 3, EPOCH: 9, LR: 0.007496, train_loss: 0.020319\n",
      "[>>VAL]: FOLD: 3, EPOCH: 9, valid_loss: 0.017717\n",
      "[TRAIN]: FOLD: 3, EPOCH: 10, LR: 0.006869, train_loss: 0.020278\n",
      "[>>VAL]: FOLD: 3, EPOCH: 10, valid_loss: 0.017358\n",
      "[TRAIN]: FOLD: 3, EPOCH: 11, LR: 0.006205, train_loss: 0.020225\n",
      "[>>VAL]: FOLD: 3, EPOCH: 11, valid_loss: 0.017715\n",
      "[TRAIN]: FOLD: 3, EPOCH: 12, LR: 0.005518, train_loss: 0.020162\n",
      "[>>VAL]: FOLD: 3, EPOCH: 12, valid_loss: 0.017482\n",
      "[TRAIN]: FOLD: 3, EPOCH: 13, LR: 0.004821, train_loss: 0.020047\n",
      "[>>VAL]: FOLD: 3, EPOCH: 13, valid_loss: 0.017313\n",
      "[TRAIN]: FOLD: 3, EPOCH: 14, LR: 0.004127, train_loss: 0.019982\n",
      "[>>VAL]: FOLD: 3, EPOCH: 14, valid_loss: 0.017558\n",
      "[TRAIN]: FOLD: 3, EPOCH: 15, LR: 0.003450, train_loss: 0.019799\n",
      "[>>VAL]: FOLD: 3, EPOCH: 15, valid_loss: 0.017237\n",
      "[TRAIN]: FOLD: 3, EPOCH: 16, LR: 0.002804, train_loss: 0.019566\n",
      "[>>VAL]: FOLD: 3, EPOCH: 16, valid_loss: 0.017176\n",
      "[TRAIN]: FOLD: 3, EPOCH: 17, LR: 0.002200, train_loss: 0.019336\n",
      "[>>VAL]: FOLD: 3, EPOCH: 17, valid_loss: 0.017179\n",
      "[TRAIN]: FOLD: 3, EPOCH: 18, LR: 0.001651, train_loss: 0.019056\n",
      "[>>VAL]: FOLD: 3, EPOCH: 18, valid_loss: 0.016963\n",
      "[TRAIN]: FOLD: 3, EPOCH: 19, LR: 0.001167, train_loss: 0.018659\n",
      "[>>VAL]: FOLD: 3, EPOCH: 19, valid_loss: 0.016876\n",
      "[TRAIN]: FOLD: 3, EPOCH: 20, LR: 0.000757, train_loss: 0.018227\n",
      "[>>VAL]: FOLD: 3, EPOCH: 20, valid_loss: 0.016928\n",
      "[TRAIN]: FOLD: 3, EPOCH: 21, LR: 0.000430, train_loss: 0.017730\n",
      "[>>VAL]: FOLD: 3, EPOCH: 21, valid_loss: 0.016847\n",
      "[TRAIN]: FOLD: 3, EPOCH: 22, LR: 0.000192, train_loss: 0.017290\n",
      "[>>VAL]: FOLD: 3, EPOCH: 22, valid_loss: 0.016869\n",
      "[TRAIN]: FOLD: 3, EPOCH: 23, LR: 0.000048, train_loss: 0.016932\n",
      "[>>VAL]: FOLD: 3, EPOCH: 23, valid_loss: 0.016891\n",
      "[TRAIN]: FOLD: 3, EPOCH: 24, LR: 0.000000, train_loss: 0.016743\n",
      "[>>VAL]: FOLD: 3, EPOCH: 24, valid_loss: 0.016890\n",
      "[TRAIN]: FOLD: 4, EPOCH: 0, LR: 0.003478, train_loss: 0.474239\n",
      "[>>VAL]: FOLD: 4, EPOCH: 0, valid_loss: 0.024884\n",
      "[TRAIN]: FOLD: 4, EPOCH: 1, LR: 0.009066, train_loss: 0.023636\n",
      "[>>VAL]: FOLD: 4, EPOCH: 1, valid_loss: 0.019301\n",
      "[TRAIN]: FOLD: 4, EPOCH: 2, LR: 0.009987, train_loss: 0.021861\n",
      "[>>VAL]: FOLD: 4, EPOCH: 2, valid_loss: 0.019302\n",
      "[TRAIN]: FOLD: 4, EPOCH: 3, LR: 0.009890, train_loss: 0.020943\n",
      "[>>VAL]: FOLD: 4, EPOCH: 3, valid_loss: 0.018540\n",
      "[TRAIN]: FOLD: 4, EPOCH: 4, LR: 0.009697, train_loss: 0.020254\n",
      "[>>VAL]: FOLD: 4, EPOCH: 4, valid_loss: 0.018139\n",
      "[TRAIN]: FOLD: 4, EPOCH: 5, LR: 0.009413, train_loss: 0.020223\n",
      "[>>VAL]: FOLD: 4, EPOCH: 5, valid_loss: 0.018139\n",
      "[TRAIN]: FOLD: 4, EPOCH: 6, LR: 0.009042, train_loss: 0.020213\n",
      "[>>VAL]: FOLD: 4, EPOCH: 6, valid_loss: 0.018068\n",
      "[TRAIN]: FOLD: 4, EPOCH: 7, LR: 0.008593, train_loss: 0.020222\n",
      "[>>VAL]: FOLD: 4, EPOCH: 7, valid_loss: 0.018232\n",
      "[TRAIN]: FOLD: 4, EPOCH: 8, LR: 0.008075, train_loss: 0.020218\n",
      "[>>VAL]: FOLD: 4, EPOCH: 8, valid_loss: 0.018074\n",
      "[TRAIN]: FOLD: 4, EPOCH: 9, LR: 0.007496, train_loss: 0.020215\n",
      "[>>VAL]: FOLD: 4, EPOCH: 9, valid_loss: 0.018175\n",
      "[TRAIN]: FOLD: 4, EPOCH: 10, LR: 0.006869, train_loss: 0.020114\n",
      "[>>VAL]: FOLD: 4, EPOCH: 10, valid_loss: 0.018006\n",
      "[TRAIN]: FOLD: 4, EPOCH: 11, LR: 0.006205, train_loss: 0.020147\n",
      "[>>VAL]: FOLD: 4, EPOCH: 11, valid_loss: 0.018503\n",
      "[TRAIN]: FOLD: 4, EPOCH: 12, LR: 0.005518, train_loss: 0.020077\n",
      "[>>VAL]: FOLD: 4, EPOCH: 12, valid_loss: 0.018151\n",
      "[TRAIN]: FOLD: 4, EPOCH: 13, LR: 0.004821, train_loss: 0.019938\n",
      "[>>VAL]: FOLD: 4, EPOCH: 13, valid_loss: 0.017871\n",
      "[TRAIN]: FOLD: 4, EPOCH: 14, LR: 0.004127, train_loss: 0.019855\n",
      "[>>VAL]: FOLD: 4, EPOCH: 14, valid_loss: 0.017980\n",
      "[TRAIN]: FOLD: 4, EPOCH: 15, LR: 0.003450, train_loss: 0.019669\n",
      "[>>VAL]: FOLD: 4, EPOCH: 15, valid_loss: 0.017759\n",
      "[TRAIN]: FOLD: 4, EPOCH: 16, LR: 0.002804, train_loss: 0.019494\n",
      "[>>VAL]: FOLD: 4, EPOCH: 16, valid_loss: 0.017740\n",
      "[TRAIN]: FOLD: 4, EPOCH: 17, LR: 0.002200, train_loss: 0.019282\n",
      "[>>VAL]: FOLD: 4, EPOCH: 17, valid_loss: 0.017602\n",
      "[TRAIN]: FOLD: 4, EPOCH: 18, LR: 0.001651, train_loss: 0.018961\n",
      "[>>VAL]: FOLD: 4, EPOCH: 18, valid_loss: 0.017622\n",
      "[TRAIN]: FOLD: 4, EPOCH: 19, LR: 0.001167, train_loss: 0.018635\n",
      "[>>VAL]: FOLD: 4, EPOCH: 19, valid_loss: 0.017553\n",
      "[TRAIN]: FOLD: 4, EPOCH: 20, LR: 0.000757, train_loss: 0.018221\n",
      "[>>VAL]: FOLD: 4, EPOCH: 20, valid_loss: 0.017587\n",
      "[TRAIN]: FOLD: 4, EPOCH: 21, LR: 0.000430, train_loss: 0.017693\n",
      "[>>VAL]: FOLD: 4, EPOCH: 21, valid_loss: 0.017480\n",
      "[TRAIN]: FOLD: 4, EPOCH: 22, LR: 0.000192, train_loss: 0.017240\n",
      "[>>VAL]: FOLD: 4, EPOCH: 22, valid_loss: 0.017471\n",
      "[TRAIN]: FOLD: 4, EPOCH: 23, LR: 0.000048, train_loss: 0.016861\n",
      "[>>VAL]: FOLD: 4, EPOCH: 23, valid_loss: 0.017461\n",
      "[TRAIN]: FOLD: 4, EPOCH: 24, LR: 0.000000, train_loss: 0.016676\n",
      "[>>VAL]: FOLD: 4, EPOCH: 24, valid_loss: 0.017488\n",
      "[TRAIN]: FOLD: 5, EPOCH: 0, LR: 0.003478, train_loss: 0.474981\n",
      "[>>VAL]: FOLD: 5, EPOCH: 0, valid_loss: 0.025279\n",
      "[TRAIN]: FOLD: 5, EPOCH: 1, LR: 0.009066, train_loss: 0.023914\n",
      "[>>VAL]: FOLD: 5, EPOCH: 1, valid_loss: 0.019706\n",
      "[TRAIN]: FOLD: 5, EPOCH: 2, LR: 0.009987, train_loss: 0.021683\n",
      "[>>VAL]: FOLD: 5, EPOCH: 2, valid_loss: 0.018516\n",
      "[TRAIN]: FOLD: 5, EPOCH: 3, LR: 0.009890, train_loss: 0.020573\n",
      "[>>VAL]: FOLD: 5, EPOCH: 3, valid_loss: 0.018349\n",
      "[TRAIN]: FOLD: 5, EPOCH: 4, LR: 0.009697, train_loss: 0.020170\n",
      "[>>VAL]: FOLD: 5, EPOCH: 4, valid_loss: 0.018287\n",
      "[TRAIN]: FOLD: 5, EPOCH: 5, LR: 0.009412, train_loss: 0.020113\n",
      "[>>VAL]: FOLD: 5, EPOCH: 5, valid_loss: 0.018702\n",
      "[TRAIN]: FOLD: 5, EPOCH: 6, LR: 0.009042, train_loss: 0.020123\n",
      "[>>VAL]: FOLD: 5, EPOCH: 6, valid_loss: 0.018622\n",
      "[TRAIN]: FOLD: 5, EPOCH: 7, LR: 0.008593, train_loss: 0.020147\n",
      "[>>VAL]: FOLD: 5, EPOCH: 7, valid_loss: 0.018194\n",
      "[TRAIN]: FOLD: 5, EPOCH: 8, LR: 0.008075, train_loss: 0.020170\n",
      "[>>VAL]: FOLD: 5, EPOCH: 8, valid_loss: 0.018400\n",
      "[TRAIN]: FOLD: 5, EPOCH: 9, LR: 0.007496, train_loss: 0.020105\n",
      "[>>VAL]: FOLD: 5, EPOCH: 9, valid_loss: 0.018277\n",
      "[TRAIN]: FOLD: 5, EPOCH: 10, LR: 0.006869, train_loss: 0.020147\n",
      "[>>VAL]: FOLD: 5, EPOCH: 10, valid_loss: 0.018326\n",
      "[TRAIN]: FOLD: 5, EPOCH: 11, LR: 0.006205, train_loss: 0.020097\n",
      "[>>VAL]: FOLD: 5, EPOCH: 11, valid_loss: 0.018144\n",
      "[TRAIN]: FOLD: 5, EPOCH: 12, LR: 0.005518, train_loss: 0.019985\n",
      "[>>VAL]: FOLD: 5, EPOCH: 12, valid_loss: 0.018029\n",
      "[TRAIN]: FOLD: 5, EPOCH: 13, LR: 0.004821, train_loss: 0.019897\n",
      "[>>VAL]: FOLD: 5, EPOCH: 13, valid_loss: 0.018020\n",
      "[TRAIN]: FOLD: 5, EPOCH: 14, LR: 0.004127, train_loss: 0.019753\n",
      "[>>VAL]: FOLD: 5, EPOCH: 14, valid_loss: 0.018224\n",
      "[TRAIN]: FOLD: 5, EPOCH: 15, LR: 0.003450, train_loss: 0.019615\n",
      "[>>VAL]: FOLD: 5, EPOCH: 15, valid_loss: 0.018049\n",
      "[TRAIN]: FOLD: 5, EPOCH: 16, LR: 0.002804, train_loss: 0.019362\n",
      "[>>VAL]: FOLD: 5, EPOCH: 16, valid_loss: 0.017919\n",
      "[TRAIN]: FOLD: 5, EPOCH: 17, LR: 0.002200, train_loss: 0.019178\n",
      "[>>VAL]: FOLD: 5, EPOCH: 17, valid_loss: 0.018128\n",
      "[TRAIN]: FOLD: 5, EPOCH: 18, LR: 0.001651, train_loss: 0.018895\n",
      "[>>VAL]: FOLD: 5, EPOCH: 18, valid_loss: 0.017766\n",
      "[TRAIN]: FOLD: 5, EPOCH: 19, LR: 0.001167, train_loss: 0.018480\n",
      "[>>VAL]: FOLD: 5, EPOCH: 19, valid_loss: 0.017866\n",
      "[TRAIN]: FOLD: 5, EPOCH: 20, LR: 0.000757, train_loss: 0.018078\n",
      "[>>VAL]: FOLD: 5, EPOCH: 20, valid_loss: 0.017743\n",
      "[TRAIN]: FOLD: 5, EPOCH: 21, LR: 0.000430, train_loss: 0.017589\n",
      "[>>VAL]: FOLD: 5, EPOCH: 21, valid_loss: 0.017767\n",
      "[TRAIN]: FOLD: 5, EPOCH: 22, LR: 0.000192, train_loss: 0.017174\n",
      "[>>VAL]: FOLD: 5, EPOCH: 22, valid_loss: 0.017813\n",
      "[TRAIN]: FOLD: 5, EPOCH: 23, LR: 0.000048, train_loss: 0.016802\n",
      "[>>VAL]: FOLD: 5, EPOCH: 23, valid_loss: 0.017783\n",
      "[TRAIN]: FOLD: 5, EPOCH: 24, LR: 0.000000, train_loss: 0.016631\n",
      "[>>VAL]: FOLD: 5, EPOCH: 24, valid_loss: 0.017827\n",
      "[TRAIN]: FOLD: 6, EPOCH: 0, LR: 0.003478, train_loss: 0.473495\n",
      "[>>VAL]: FOLD: 6, EPOCH: 0, valid_loss: 0.024266\n",
      "[TRAIN]: FOLD: 6, EPOCH: 1, LR: 0.009066, train_loss: 0.023902\n",
      "[>>VAL]: FOLD: 6, EPOCH: 1, valid_loss: 0.018946\n",
      "[TRAIN]: FOLD: 6, EPOCH: 2, LR: 0.009987, train_loss: 0.021894\n",
      "[>>VAL]: FOLD: 6, EPOCH: 2, valid_loss: 0.017825\n",
      "[TRAIN]: FOLD: 6, EPOCH: 3, LR: 0.009890, train_loss: 0.020688\n",
      "[>>VAL]: FOLD: 6, EPOCH: 3, valid_loss: 0.017465\n",
      "[TRAIN]: FOLD: 6, EPOCH: 4, LR: 0.009697, train_loss: 0.020360\n",
      "[>>VAL]: FOLD: 6, EPOCH: 4, valid_loss: 0.017357\n",
      "[TRAIN]: FOLD: 6, EPOCH: 5, LR: 0.009413, train_loss: 0.020218\n",
      "[>>VAL]: FOLD: 6, EPOCH: 5, valid_loss: 0.017229\n",
      "[TRAIN]: FOLD: 6, EPOCH: 6, LR: 0.009042, train_loss: 0.020301\n",
      "[>>VAL]: FOLD: 6, EPOCH: 6, valid_loss: 0.017541\n",
      "[TRAIN]: FOLD: 6, EPOCH: 7, LR: 0.008593, train_loss: 0.020287\n",
      "[>>VAL]: FOLD: 6, EPOCH: 7, valid_loss: 0.017546\n",
      "[TRAIN]: FOLD: 6, EPOCH: 8, LR: 0.008075, train_loss: 0.020345\n",
      "[>>VAL]: FOLD: 6, EPOCH: 8, valid_loss: 0.017254\n",
      "[TRAIN]: FOLD: 6, EPOCH: 9, LR: 0.007496, train_loss: 0.020298\n",
      "[>>VAL]: FOLD: 6, EPOCH: 9, valid_loss: 0.017355\n",
      "[TRAIN]: FOLD: 6, EPOCH: 10, LR: 0.006869, train_loss: 0.020316\n",
      "[>>VAL]: FOLD: 6, EPOCH: 10, valid_loss: 0.017251\n",
      "[TRAIN]: FOLD: 6, EPOCH: 11, LR: 0.006205, train_loss: 0.020223\n",
      "[>>VAL]: FOLD: 6, EPOCH: 11, valid_loss: 0.017330\n",
      "[TRAIN]: FOLD: 6, EPOCH: 12, LR: 0.005518, train_loss: 0.020171\n",
      "[>>VAL]: FOLD: 6, EPOCH: 12, valid_loss: 0.017259\n",
      "[TRAIN]: FOLD: 6, EPOCH: 13, LR: 0.004821, train_loss: 0.020065\n",
      "[>>VAL]: FOLD: 6, EPOCH: 13, valid_loss: 0.017138\n",
      "[TRAIN]: FOLD: 6, EPOCH: 14, LR: 0.004127, train_loss: 0.019936\n",
      "[>>VAL]: FOLD: 6, EPOCH: 14, valid_loss: 0.017268\n",
      "[TRAIN]: FOLD: 6, EPOCH: 15, LR: 0.003450, train_loss: 0.019743\n",
      "[>>VAL]: FOLD: 6, EPOCH: 15, valid_loss: 0.016982\n",
      "[TRAIN]: FOLD: 6, EPOCH: 16, LR: 0.002804, train_loss: 0.019553\n",
      "[>>VAL]: FOLD: 6, EPOCH: 16, valid_loss: 0.016876\n",
      "[TRAIN]: FOLD: 6, EPOCH: 17, LR: 0.002200, train_loss: 0.019328\n",
      "[>>VAL]: FOLD: 6, EPOCH: 17, valid_loss: 0.017020\n",
      "[TRAIN]: FOLD: 6, EPOCH: 18, LR: 0.001651, train_loss: 0.019057\n",
      "[>>VAL]: FOLD: 6, EPOCH: 18, valid_loss: 0.016863\n",
      "[TRAIN]: FOLD: 6, EPOCH: 19, LR: 0.001167, train_loss: 0.018699\n",
      "[>>VAL]: FOLD: 6, EPOCH: 19, valid_loss: 0.016804\n",
      "[TRAIN]: FOLD: 6, EPOCH: 20, LR: 0.000757, train_loss: 0.018266\n",
      "[>>VAL]: FOLD: 6, EPOCH: 20, valid_loss: 0.016678\n",
      "[TRAIN]: FOLD: 6, EPOCH: 21, LR: 0.000430, train_loss: 0.017798\n",
      "[>>VAL]: FOLD: 6, EPOCH: 21, valid_loss: 0.016738\n",
      "[TRAIN]: FOLD: 6, EPOCH: 22, LR: 0.000192, train_loss: 0.017345\n",
      "[>>VAL]: FOLD: 6, EPOCH: 22, valid_loss: 0.016798\n",
      "[TRAIN]: FOLD: 6, EPOCH: 23, LR: 0.000048, train_loss: 0.016940\n",
      "[>>VAL]: FOLD: 6, EPOCH: 23, valid_loss: 0.016774\n",
      "[TRAIN]: FOLD: 6, EPOCH: 24, LR: 0.000000, train_loss: 0.016788\n",
      "[>>VAL]: FOLD: 6, EPOCH: 24, valid_loss: 0.016793\n",
      "\n",
      ">> SEED: 3\n",
      "\n",
      "[TRAIN]: FOLD: 0, EPOCH: 0, LR: 0.003478, train_loss: 0.475301\n",
      "[>>VAL]: FOLD: 0, EPOCH: 0, valid_loss: 0.024978\n",
      "[TRAIN]: FOLD: 0, EPOCH: 1, LR: 0.009066, train_loss: 0.024067\n",
      "[>>VAL]: FOLD: 0, EPOCH: 1, valid_loss: 0.019547\n",
      "[TRAIN]: FOLD: 0, EPOCH: 2, LR: 0.009987, train_loss: 0.021741\n",
      "[>>VAL]: FOLD: 0, EPOCH: 2, valid_loss: 0.018730\n",
      "[TRAIN]: FOLD: 0, EPOCH: 3, LR: 0.009890, train_loss: 0.020618\n",
      "[>>VAL]: FOLD: 0, EPOCH: 3, valid_loss: 0.017875\n",
      "[TRAIN]: FOLD: 0, EPOCH: 4, LR: 0.009697, train_loss: 0.020259\n",
      "[>>VAL]: FOLD: 0, EPOCH: 4, valid_loss: 0.017984\n",
      "[TRAIN]: FOLD: 0, EPOCH: 5, LR: 0.009413, train_loss: 0.020136\n",
      "[>>VAL]: FOLD: 0, EPOCH: 5, valid_loss: 0.017995\n",
      "[TRAIN]: FOLD: 0, EPOCH: 6, LR: 0.009042, train_loss: 0.020249\n",
      "[>>VAL]: FOLD: 0, EPOCH: 6, valid_loss: 0.017917\n",
      "[TRAIN]: FOLD: 0, EPOCH: 7, LR: 0.008593, train_loss: 0.020248\n",
      "[>>VAL]: FOLD: 0, EPOCH: 7, valid_loss: 0.018015\n",
      "[TRAIN]: FOLD: 0, EPOCH: 8, LR: 0.008075, train_loss: 0.020238\n",
      "[>>VAL]: FOLD: 0, EPOCH: 8, valid_loss: 0.017851\n",
      "[TRAIN]: FOLD: 0, EPOCH: 9, LR: 0.007496, train_loss: 0.020141\n",
      "[>>VAL]: FOLD: 0, EPOCH: 9, valid_loss: 0.018130\n",
      "[TRAIN]: FOLD: 0, EPOCH: 10, LR: 0.006869, train_loss: 0.020211\n",
      "[>>VAL]: FOLD: 0, EPOCH: 10, valid_loss: 0.017736\n",
      "[TRAIN]: FOLD: 0, EPOCH: 11, LR: 0.006205, train_loss: 0.020111\n",
      "[>>VAL]: FOLD: 0, EPOCH: 11, valid_loss: 0.017750\n",
      "[TRAIN]: FOLD: 0, EPOCH: 12, LR: 0.005518, train_loss: 0.020092\n",
      "[>>VAL]: FOLD: 0, EPOCH: 12, valid_loss: 0.017673\n",
      "[TRAIN]: FOLD: 0, EPOCH: 13, LR: 0.004821, train_loss: 0.020014\n",
      "[>>VAL]: FOLD: 0, EPOCH: 13, valid_loss: 0.017679\n",
      "[TRAIN]: FOLD: 0, EPOCH: 14, LR: 0.004127, train_loss: 0.019877\n",
      "[>>VAL]: FOLD: 0, EPOCH: 14, valid_loss: 0.017669\n",
      "[TRAIN]: FOLD: 0, EPOCH: 15, LR: 0.003450, train_loss: 0.019708\n",
      "[>>VAL]: FOLD: 0, EPOCH: 15, valid_loss: 0.017607\n",
      "[TRAIN]: FOLD: 0, EPOCH: 16, LR: 0.002804, train_loss: 0.019498\n",
      "[>>VAL]: FOLD: 0, EPOCH: 16, valid_loss: 0.017509\n",
      "[TRAIN]: FOLD: 0, EPOCH: 17, LR: 0.002200, train_loss: 0.019202\n",
      "[>>VAL]: FOLD: 0, EPOCH: 17, valid_loss: 0.017503\n",
      "[TRAIN]: FOLD: 0, EPOCH: 18, LR: 0.001651, train_loss: 0.018974\n",
      "[>>VAL]: FOLD: 0, EPOCH: 18, valid_loss: 0.017429\n",
      "[TRAIN]: FOLD: 0, EPOCH: 19, LR: 0.001167, train_loss: 0.018605\n",
      "[>>VAL]: FOLD: 0, EPOCH: 19, valid_loss: 0.017345\n",
      "[TRAIN]: FOLD: 0, EPOCH: 20, LR: 0.000757, train_loss: 0.018113\n",
      "[>>VAL]: FOLD: 0, EPOCH: 20, valid_loss: 0.017344\n",
      "[TRAIN]: FOLD: 0, EPOCH: 21, LR: 0.000430, train_loss: 0.017672\n",
      "[>>VAL]: FOLD: 0, EPOCH: 21, valid_loss: 0.017336\n",
      "[TRAIN]: FOLD: 0, EPOCH: 22, LR: 0.000192, train_loss: 0.017186\n",
      "[>>VAL]: FOLD: 0, EPOCH: 22, valid_loss: 0.017352\n",
      "[TRAIN]: FOLD: 0, EPOCH: 23, LR: 0.000048, train_loss: 0.016816\n",
      "[>>VAL]: FOLD: 0, EPOCH: 23, valid_loss: 0.017318\n",
      "[TRAIN]: FOLD: 0, EPOCH: 24, LR: 0.000000, train_loss: 0.016627\n",
      "[>>VAL]: FOLD: 0, EPOCH: 24, valid_loss: 0.017348\n",
      "[TRAIN]: FOLD: 1, EPOCH: 0, LR: 0.003478, train_loss: 0.476280\n",
      "[>>VAL]: FOLD: 1, EPOCH: 0, valid_loss: 0.027034\n",
      "[TRAIN]: FOLD: 1, EPOCH: 1, LR: 0.009066, train_loss: 0.024079\n",
      "[>>VAL]: FOLD: 1, EPOCH: 1, valid_loss: 0.018971\n",
      "[TRAIN]: FOLD: 1, EPOCH: 2, LR: 0.009987, train_loss: 0.022015\n",
      "[>>VAL]: FOLD: 1, EPOCH: 2, valid_loss: 0.017996\n",
      "[TRAIN]: FOLD: 1, EPOCH: 3, LR: 0.009890, train_loss: 0.020689\n",
      "[>>VAL]: FOLD: 1, EPOCH: 3, valid_loss: 0.017560\n",
      "[TRAIN]: FOLD: 1, EPOCH: 4, LR: 0.009697, train_loss: 0.020217\n",
      "[>>VAL]: FOLD: 1, EPOCH: 4, valid_loss: 0.017675\n",
      "[TRAIN]: FOLD: 1, EPOCH: 5, LR: 0.009412, train_loss: 0.020191\n",
      "[>>VAL]: FOLD: 1, EPOCH: 5, valid_loss: 0.017515\n",
      "[TRAIN]: FOLD: 1, EPOCH: 6, LR: 0.009042, train_loss: 0.020277\n",
      "[>>VAL]: FOLD: 1, EPOCH: 6, valid_loss: 0.017506\n",
      "[TRAIN]: FOLD: 1, EPOCH: 7, LR: 0.008593, train_loss: 0.020235\n",
      "[>>VAL]: FOLD: 1, EPOCH: 7, valid_loss: 0.017847\n",
      "[TRAIN]: FOLD: 1, EPOCH: 8, LR: 0.008075, train_loss: 0.020294\n",
      "[>>VAL]: FOLD: 1, EPOCH: 8, valid_loss: 0.017688\n",
      "[TRAIN]: FOLD: 1, EPOCH: 9, LR: 0.007496, train_loss: 0.020347\n",
      "[>>VAL]: FOLD: 1, EPOCH: 9, valid_loss: 0.017811\n",
      "[TRAIN]: FOLD: 1, EPOCH: 10, LR: 0.006869, train_loss: 0.020191\n",
      "[>>VAL]: FOLD: 1, EPOCH: 10, valid_loss: 0.017413\n",
      "[TRAIN]: FOLD: 1, EPOCH: 11, LR: 0.006205, train_loss: 0.020184\n",
      "[>>VAL]: FOLD: 1, EPOCH: 11, valid_loss: 0.017433\n",
      "[TRAIN]: FOLD: 1, EPOCH: 12, LR: 0.005518, train_loss: 0.020159\n",
      "[>>VAL]: FOLD: 1, EPOCH: 12, valid_loss: 0.017485\n",
      "[TRAIN]: FOLD: 1, EPOCH: 13, LR: 0.004821, train_loss: 0.020039\n",
      "[>>VAL]: FOLD: 1, EPOCH: 13, valid_loss: 0.017314\n",
      "[TRAIN]: FOLD: 1, EPOCH: 14, LR: 0.004127, train_loss: 0.019888\n",
      "[>>VAL]: FOLD: 1, EPOCH: 14, valid_loss: 0.017392\n",
      "[TRAIN]: FOLD: 1, EPOCH: 15, LR: 0.003450, train_loss: 0.019756\n",
      "[>>VAL]: FOLD: 1, EPOCH: 15, valid_loss: 0.017339\n",
      "[TRAIN]: FOLD: 1, EPOCH: 16, LR: 0.002804, train_loss: 0.019493\n",
      "[>>VAL]: FOLD: 1, EPOCH: 16, valid_loss: 0.017149\n",
      "[TRAIN]: FOLD: 1, EPOCH: 17, LR: 0.002200, train_loss: 0.019325\n",
      "[>>VAL]: FOLD: 1, EPOCH: 17, valid_loss: 0.017230\n",
      "[TRAIN]: FOLD: 1, EPOCH: 18, LR: 0.001651, train_loss: 0.019039\n",
      "[>>VAL]: FOLD: 1, EPOCH: 18, valid_loss: 0.017128\n",
      "[TRAIN]: FOLD: 1, EPOCH: 19, LR: 0.001167, train_loss: 0.018635\n",
      "[>>VAL]: FOLD: 1, EPOCH: 19, valid_loss: 0.017052\n",
      "[TRAIN]: FOLD: 1, EPOCH: 20, LR: 0.000757, train_loss: 0.018275\n",
      "[>>VAL]: FOLD: 1, EPOCH: 20, valid_loss: 0.017095\n",
      "[TRAIN]: FOLD: 1, EPOCH: 21, LR: 0.000430, train_loss: 0.017810\n",
      "[>>VAL]: FOLD: 1, EPOCH: 21, valid_loss: 0.016951\n",
      "[TRAIN]: FOLD: 1, EPOCH: 22, LR: 0.000192, train_loss: 0.017305\n",
      "[>>VAL]: FOLD: 1, EPOCH: 22, valid_loss: 0.017011\n",
      "[TRAIN]: FOLD: 1, EPOCH: 23, LR: 0.000048, train_loss: 0.016968\n",
      "[>>VAL]: FOLD: 1, EPOCH: 23, valid_loss: 0.016993\n",
      "[TRAIN]: FOLD: 1, EPOCH: 24, LR: 0.000000, train_loss: 0.016809\n",
      "[>>VAL]: FOLD: 1, EPOCH: 24, valid_loss: 0.016985\n",
      "[TRAIN]: FOLD: 2, EPOCH: 0, LR: 0.003478, train_loss: 0.474857\n",
      "[>>VAL]: FOLD: 2, EPOCH: 0, valid_loss: 0.025361\n",
      "[TRAIN]: FOLD: 2, EPOCH: 1, LR: 0.009066, train_loss: 0.023868\n",
      "[>>VAL]: FOLD: 2, EPOCH: 1, valid_loss: 0.019763\n",
      "[TRAIN]: FOLD: 2, EPOCH: 2, LR: 0.009987, train_loss: 0.021894\n",
      "[>>VAL]: FOLD: 2, EPOCH: 2, valid_loss: 0.018866\n",
      "[TRAIN]: FOLD: 2, EPOCH: 3, LR: 0.009890, train_loss: 0.020573\n",
      "[>>VAL]: FOLD: 2, EPOCH: 3, valid_loss: 0.018431\n",
      "[TRAIN]: FOLD: 2, EPOCH: 4, LR: 0.009697, train_loss: 0.020166\n",
      "[>>VAL]: FOLD: 2, EPOCH: 4, valid_loss: 0.018367\n",
      "[TRAIN]: FOLD: 2, EPOCH: 5, LR: 0.009413, train_loss: 0.020144\n",
      "[>>VAL]: FOLD: 2, EPOCH: 5, valid_loss: 0.018724\n",
      "[TRAIN]: FOLD: 2, EPOCH: 6, LR: 0.009042, train_loss: 0.020135\n",
      "[>>VAL]: FOLD: 2, EPOCH: 6, valid_loss: 0.018430\n",
      "[TRAIN]: FOLD: 2, EPOCH: 7, LR: 0.008593, train_loss: 0.020088\n",
      "[>>VAL]: FOLD: 2, EPOCH: 7, valid_loss: 0.018520\n",
      "[TRAIN]: FOLD: 2, EPOCH: 8, LR: 0.008075, train_loss: 0.020108\n",
      "[>>VAL]: FOLD: 2, EPOCH: 8, valid_loss: 0.018353\n",
      "[TRAIN]: FOLD: 2, EPOCH: 9, LR: 0.007496, train_loss: 0.020110\n",
      "[>>VAL]: FOLD: 2, EPOCH: 9, valid_loss: 0.018323\n",
      "[TRAIN]: FOLD: 2, EPOCH: 10, LR: 0.006869, train_loss: 0.020112\n",
      "[>>VAL]: FOLD: 2, EPOCH: 10, valid_loss: 0.018343\n",
      "[TRAIN]: FOLD: 2, EPOCH: 11, LR: 0.006205, train_loss: 0.020107\n",
      "[>>VAL]: FOLD: 2, EPOCH: 11, valid_loss: 0.018438\n",
      "[TRAIN]: FOLD: 2, EPOCH: 12, LR: 0.005518, train_loss: 0.019926\n",
      "[>>VAL]: FOLD: 2, EPOCH: 12, valid_loss: 0.018399\n",
      "[TRAIN]: FOLD: 2, EPOCH: 13, LR: 0.004821, train_loss: 0.019930\n",
      "[>>VAL]: FOLD: 2, EPOCH: 13, valid_loss: 0.018146\n",
      "[TRAIN]: FOLD: 2, EPOCH: 14, LR: 0.004127, train_loss: 0.019744\n",
      "[>>VAL]: FOLD: 2, EPOCH: 14, valid_loss: 0.018367\n",
      "[TRAIN]: FOLD: 2, EPOCH: 15, LR: 0.003450, train_loss: 0.019585\n",
      "[>>VAL]: FOLD: 2, EPOCH: 15, valid_loss: 0.017991\n",
      "[TRAIN]: FOLD: 2, EPOCH: 16, LR: 0.002804, train_loss: 0.019354\n",
      "[>>VAL]: FOLD: 2, EPOCH: 16, valid_loss: 0.018044\n",
      "[TRAIN]: FOLD: 2, EPOCH: 17, LR: 0.002200, train_loss: 0.019121\n",
      "[>>VAL]: FOLD: 2, EPOCH: 17, valid_loss: 0.017900\n",
      "[TRAIN]: FOLD: 2, EPOCH: 18, LR: 0.001651, train_loss: 0.018893\n",
      "[>>VAL]: FOLD: 2, EPOCH: 18, valid_loss: 0.017929\n",
      "[TRAIN]: FOLD: 2, EPOCH: 19, LR: 0.001167, train_loss: 0.018451\n",
      "[>>VAL]: FOLD: 2, EPOCH: 19, valid_loss: 0.017891\n",
      "[TRAIN]: FOLD: 2, EPOCH: 20, LR: 0.000757, train_loss: 0.018082\n",
      "[>>VAL]: FOLD: 2, EPOCH: 20, valid_loss: 0.017691\n",
      "[TRAIN]: FOLD: 2, EPOCH: 21, LR: 0.000430, train_loss: 0.017601\n",
      "[>>VAL]: FOLD: 2, EPOCH: 21, valid_loss: 0.017909\n",
      "[TRAIN]: FOLD: 2, EPOCH: 22, LR: 0.000192, train_loss: 0.017143\n",
      "[>>VAL]: FOLD: 2, EPOCH: 22, valid_loss: 0.017809\n",
      "[TRAIN]: FOLD: 2, EPOCH: 23, LR: 0.000048, train_loss: 0.016728\n",
      "[>>VAL]: FOLD: 2, EPOCH: 23, valid_loss: 0.017778\n",
      "[TRAIN]: FOLD: 2, EPOCH: 24, LR: 0.000000, train_loss: 0.016612\n",
      "[>>VAL]: FOLD: 2, EPOCH: 24, valid_loss: 0.017806\n",
      "[TRAIN]: FOLD: 3, EPOCH: 0, LR: 0.003478, train_loss: 0.475495\n",
      "[>>VAL]: FOLD: 3, EPOCH: 0, valid_loss: 0.027065\n",
      "[TRAIN]: FOLD: 3, EPOCH: 1, LR: 0.009066, train_loss: 0.023862\n",
      "[>>VAL]: FOLD: 3, EPOCH: 1, valid_loss: 0.019098\n",
      "[TRAIN]: FOLD: 3, EPOCH: 2, LR: 0.009987, train_loss: 0.021900\n",
      "[>>VAL]: FOLD: 3, EPOCH: 2, valid_loss: 0.018036\n",
      "[TRAIN]: FOLD: 3, EPOCH: 3, LR: 0.009890, train_loss: 0.020629\n",
      "[>>VAL]: FOLD: 3, EPOCH: 3, valid_loss: 0.018085\n",
      "[TRAIN]: FOLD: 3, EPOCH: 4, LR: 0.009697, train_loss: 0.020355\n",
      "[>>VAL]: FOLD: 3, EPOCH: 4, valid_loss: 0.017384\n",
      "[TRAIN]: FOLD: 3, EPOCH: 5, LR: 0.009412, train_loss: 0.020233\n",
      "[>>VAL]: FOLD: 3, EPOCH: 5, valid_loss: 0.017481\n",
      "[TRAIN]: FOLD: 3, EPOCH: 6, LR: 0.009042, train_loss: 0.020247\n",
      "[>>VAL]: FOLD: 3, EPOCH: 6, valid_loss: 0.017873\n",
      "[TRAIN]: FOLD: 3, EPOCH: 7, LR: 0.008593, train_loss: 0.020301\n",
      "[>>VAL]: FOLD: 3, EPOCH: 7, valid_loss: 0.017601\n",
      "[TRAIN]: FOLD: 3, EPOCH: 8, LR: 0.008075, train_loss: 0.020324\n",
      "[>>VAL]: FOLD: 3, EPOCH: 8, valid_loss: 0.017550\n",
      "[TRAIN]: FOLD: 3, EPOCH: 9, LR: 0.007496, train_loss: 0.020304\n",
      "[>>VAL]: FOLD: 3, EPOCH: 9, valid_loss: 0.017530\n",
      "[TRAIN]: FOLD: 3, EPOCH: 10, LR: 0.006869, train_loss: 0.020229\n",
      "[>>VAL]: FOLD: 3, EPOCH: 10, valid_loss: 0.017657\n",
      "[TRAIN]: FOLD: 3, EPOCH: 11, LR: 0.006205, train_loss: 0.020261\n",
      "[>>VAL]: FOLD: 3, EPOCH: 11, valid_loss: 0.017645\n",
      "[TRAIN]: FOLD: 3, EPOCH: 12, LR: 0.005518, train_loss: 0.020128\n",
      "[>>VAL]: FOLD: 3, EPOCH: 12, valid_loss: 0.017233\n",
      "[TRAIN]: FOLD: 3, EPOCH: 13, LR: 0.004821, train_loss: 0.019984\n",
      "[>>VAL]: FOLD: 3, EPOCH: 13, valid_loss: 0.017395\n",
      "[TRAIN]: FOLD: 3, EPOCH: 14, LR: 0.004127, train_loss: 0.019895\n",
      "[>>VAL]: FOLD: 3, EPOCH: 14, valid_loss: 0.017216\n",
      "[TRAIN]: FOLD: 3, EPOCH: 15, LR: 0.003450, train_loss: 0.019741\n",
      "[>>VAL]: FOLD: 3, EPOCH: 15, valid_loss: 0.017167\n",
      "[TRAIN]: FOLD: 3, EPOCH: 16, LR: 0.002804, train_loss: 0.019541\n",
      "[>>VAL]: FOLD: 3, EPOCH: 16, valid_loss: 0.017117\n",
      "[TRAIN]: FOLD: 3, EPOCH: 17, LR: 0.002200, train_loss: 0.019225\n",
      "[>>VAL]: FOLD: 3, EPOCH: 17, valid_loss: 0.017142\n",
      "[TRAIN]: FOLD: 3, EPOCH: 18, LR: 0.001651, train_loss: 0.019064\n",
      "[>>VAL]: FOLD: 3, EPOCH: 18, valid_loss: 0.017152\n",
      "[TRAIN]: FOLD: 3, EPOCH: 19, LR: 0.001167, train_loss: 0.018607\n",
      "[>>VAL]: FOLD: 3, EPOCH: 19, valid_loss: 0.016880\n",
      "[TRAIN]: FOLD: 3, EPOCH: 20, LR: 0.000757, train_loss: 0.018223\n",
      "[>>VAL]: FOLD: 3, EPOCH: 20, valid_loss: 0.016961\n",
      "[TRAIN]: FOLD: 3, EPOCH: 21, LR: 0.000430, train_loss: 0.017708\n",
      "[>>VAL]: FOLD: 3, EPOCH: 21, valid_loss: 0.016902\n",
      "[TRAIN]: FOLD: 3, EPOCH: 22, LR: 0.000192, train_loss: 0.017241\n",
      "[>>VAL]: FOLD: 3, EPOCH: 22, valid_loss: 0.016896\n",
      "[TRAIN]: FOLD: 3, EPOCH: 23, LR: 0.000048, train_loss: 0.016879\n",
      "[>>VAL]: FOLD: 3, EPOCH: 23, valid_loss: 0.016880\n",
      "[TRAIN]: FOLD: 3, EPOCH: 24, LR: 0.000000, train_loss: 0.016715\n",
      "[>>VAL]: FOLD: 3, EPOCH: 24, valid_loss: 0.016884\n",
      "[TRAIN]: FOLD: 4, EPOCH: 0, LR: 0.003478, train_loss: 0.474210\n",
      "[>>VAL]: FOLD: 4, EPOCH: 0, valid_loss: 0.024726\n",
      "[TRAIN]: FOLD: 4, EPOCH: 1, LR: 0.009066, train_loss: 0.023665\n",
      "[>>VAL]: FOLD: 4, EPOCH: 1, valid_loss: 0.019230\n",
      "[TRAIN]: FOLD: 4, EPOCH: 2, LR: 0.009987, train_loss: 0.021917\n",
      "[>>VAL]: FOLD: 4, EPOCH: 2, valid_loss: 0.018456\n",
      "[TRAIN]: FOLD: 4, EPOCH: 3, LR: 0.009890, train_loss: 0.020683\n",
      "[>>VAL]: FOLD: 4, EPOCH: 3, valid_loss: 0.018335\n",
      "[TRAIN]: FOLD: 4, EPOCH: 4, LR: 0.009697, train_loss: 0.020244\n",
      "[>>VAL]: FOLD: 4, EPOCH: 4, valid_loss: 0.018268\n",
      "[TRAIN]: FOLD: 4, EPOCH: 5, LR: 0.009413, train_loss: 0.020177\n",
      "[>>VAL]: FOLD: 4, EPOCH: 5, valid_loss: 0.018233\n",
      "[TRAIN]: FOLD: 4, EPOCH: 6, LR: 0.009042, train_loss: 0.020183\n",
      "[>>VAL]: FOLD: 4, EPOCH: 6, valid_loss: 0.018591\n",
      "[TRAIN]: FOLD: 4, EPOCH: 7, LR: 0.008593, train_loss: 0.020238\n",
      "[>>VAL]: FOLD: 4, EPOCH: 7, valid_loss: 0.018043\n",
      "[TRAIN]: FOLD: 4, EPOCH: 8, LR: 0.008075, train_loss: 0.020176\n",
      "[>>VAL]: FOLD: 4, EPOCH: 8, valid_loss: 0.018073\n",
      "[TRAIN]: FOLD: 4, EPOCH: 9, LR: 0.007496, train_loss: 0.020208\n",
      "[>>VAL]: FOLD: 4, EPOCH: 9, valid_loss: 0.018017\n",
      "[TRAIN]: FOLD: 4, EPOCH: 10, LR: 0.006869, train_loss: 0.020152\n",
      "[>>VAL]: FOLD: 4, EPOCH: 10, valid_loss: 0.017897\n",
      "[TRAIN]: FOLD: 4, EPOCH: 11, LR: 0.006205, train_loss: 0.020128\n",
      "[>>VAL]: FOLD: 4, EPOCH: 11, valid_loss: 0.018010\n",
      "[TRAIN]: FOLD: 4, EPOCH: 12, LR: 0.005518, train_loss: 0.020051\n",
      "[>>VAL]: FOLD: 4, EPOCH: 12, valid_loss: 0.018038\n",
      "[TRAIN]: FOLD: 4, EPOCH: 13, LR: 0.004821, train_loss: 0.019881\n",
      "[>>VAL]: FOLD: 4, EPOCH: 13, valid_loss: 0.017901\n",
      "[TRAIN]: FOLD: 4, EPOCH: 14, LR: 0.004127, train_loss: 0.019793\n",
      "[>>VAL]: FOLD: 4, EPOCH: 14, valid_loss: 0.017855\n",
      "[TRAIN]: FOLD: 4, EPOCH: 15, LR: 0.003450, train_loss: 0.019605\n",
      "[>>VAL]: FOLD: 4, EPOCH: 15, valid_loss: 0.017658\n",
      "[TRAIN]: FOLD: 4, EPOCH: 16, LR: 0.002804, train_loss: 0.019446\n",
      "[>>VAL]: FOLD: 4, EPOCH: 16, valid_loss: 0.017788\n",
      "[TRAIN]: FOLD: 4, EPOCH: 17, LR: 0.002200, train_loss: 0.019191\n",
      "[>>VAL]: FOLD: 4, EPOCH: 17, valid_loss: 0.017634\n",
      "[TRAIN]: FOLD: 4, EPOCH: 18, LR: 0.001651, train_loss: 0.018869\n",
      "[>>VAL]: FOLD: 4, EPOCH: 18, valid_loss: 0.017717\n",
      "[TRAIN]: FOLD: 4, EPOCH: 19, LR: 0.001167, train_loss: 0.018534\n",
      "[>>VAL]: FOLD: 4, EPOCH: 19, valid_loss: 0.017518\n",
      "[TRAIN]: FOLD: 4, EPOCH: 20, LR: 0.000757, train_loss: 0.018102\n",
      "[>>VAL]: FOLD: 4, EPOCH: 20, valid_loss: 0.017402\n",
      "[TRAIN]: FOLD: 4, EPOCH: 21, LR: 0.000430, train_loss: 0.017580\n",
      "[>>VAL]: FOLD: 4, EPOCH: 21, valid_loss: 0.017471\n",
      "[TRAIN]: FOLD: 4, EPOCH: 22, LR: 0.000192, train_loss: 0.017104\n",
      "[>>VAL]: FOLD: 4, EPOCH: 22, valid_loss: 0.017468\n",
      "[TRAIN]: FOLD: 4, EPOCH: 23, LR: 0.000048, train_loss: 0.016740\n",
      "[>>VAL]: FOLD: 4, EPOCH: 23, valid_loss: 0.017433\n",
      "[TRAIN]: FOLD: 4, EPOCH: 24, LR: 0.000000, train_loss: 0.016542\n",
      "[>>VAL]: FOLD: 4, EPOCH: 24, valid_loss: 0.017447\n",
      "[TRAIN]: FOLD: 5, EPOCH: 0, LR: 0.003478, train_loss: 0.475282\n",
      "[>>VAL]: FOLD: 5, EPOCH: 0, valid_loss: 0.027410\n",
      "[TRAIN]: FOLD: 5, EPOCH: 1, LR: 0.009066, train_loss: 0.023877\n",
      "[>>VAL]: FOLD: 5, EPOCH: 1, valid_loss: 0.019477\n",
      "[TRAIN]: FOLD: 5, EPOCH: 2, LR: 0.009987, train_loss: 0.021644\n",
      "[>>VAL]: FOLD: 5, EPOCH: 2, valid_loss: 0.018980\n",
      "[TRAIN]: FOLD: 5, EPOCH: 3, LR: 0.009890, train_loss: 0.020577\n",
      "[>>VAL]: FOLD: 5, EPOCH: 3, valid_loss: 0.018366\n",
      "[TRAIN]: FOLD: 5, EPOCH: 4, LR: 0.009697, train_loss: 0.020157\n",
      "[>>VAL]: FOLD: 5, EPOCH: 4, valid_loss: 0.018179\n",
      "[TRAIN]: FOLD: 5, EPOCH: 5, LR: 0.009412, train_loss: 0.020069\n",
      "[>>VAL]: FOLD: 5, EPOCH: 5, valid_loss: 0.018565\n",
      "[TRAIN]: FOLD: 5, EPOCH: 6, LR: 0.009042, train_loss: 0.020075\n",
      "[>>VAL]: FOLD: 5, EPOCH: 6, valid_loss: 0.018366\n",
      "[TRAIN]: FOLD: 5, EPOCH: 7, LR: 0.008593, train_loss: 0.020128\n",
      "[>>VAL]: FOLD: 5, EPOCH: 7, valid_loss: 0.018111\n",
      "[TRAIN]: FOLD: 5, EPOCH: 8, LR: 0.008075, train_loss: 0.020061\n",
      "[>>VAL]: FOLD: 5, EPOCH: 8, valid_loss: 0.018201\n",
      "[TRAIN]: FOLD: 5, EPOCH: 9, LR: 0.007496, train_loss: 0.020049\n",
      "[>>VAL]: FOLD: 5, EPOCH: 9, valid_loss: 0.018140\n",
      "[TRAIN]: FOLD: 5, EPOCH: 10, LR: 0.006869, train_loss: 0.020075\n",
      "[>>VAL]: FOLD: 5, EPOCH: 10, valid_loss: 0.018270\n",
      "[TRAIN]: FOLD: 5, EPOCH: 11, LR: 0.006205, train_loss: 0.019991\n",
      "[>>VAL]: FOLD: 5, EPOCH: 11, valid_loss: 0.018095\n",
      "[TRAIN]: FOLD: 5, EPOCH: 12, LR: 0.005518, train_loss: 0.019929\n",
      "[>>VAL]: FOLD: 5, EPOCH: 12, valid_loss: 0.018148\n",
      "[TRAIN]: FOLD: 5, EPOCH: 13, LR: 0.004821, train_loss: 0.019886\n",
      "[>>VAL]: FOLD: 5, EPOCH: 13, valid_loss: 0.018331\n",
      "[TRAIN]: FOLD: 5, EPOCH: 14, LR: 0.004127, train_loss: 0.019719\n",
      "[>>VAL]: FOLD: 5, EPOCH: 14, valid_loss: 0.017880\n",
      "[TRAIN]: FOLD: 5, EPOCH: 15, LR: 0.003450, train_loss: 0.019564\n",
      "[>>VAL]: FOLD: 5, EPOCH: 15, valid_loss: 0.018191\n",
      "[TRAIN]: FOLD: 5, EPOCH: 16, LR: 0.002804, train_loss: 0.019312\n",
      "[>>VAL]: FOLD: 5, EPOCH: 16, valid_loss: 0.018225\n",
      "[TRAIN]: FOLD: 5, EPOCH: 17, LR: 0.002200, train_loss: 0.019066\n",
      "[>>VAL]: FOLD: 5, EPOCH: 17, valid_loss: 0.017902\n",
      "[TRAIN]: FOLD: 5, EPOCH: 18, LR: 0.001651, train_loss: 0.018755\n",
      "[>>VAL]: FOLD: 5, EPOCH: 18, valid_loss: 0.017963\n",
      "[TRAIN]: FOLD: 5, EPOCH: 19, LR: 0.001167, train_loss: 0.018413\n",
      "[>>VAL]: FOLD: 5, EPOCH: 19, valid_loss: 0.017933\n",
      "[TRAIN]: FOLD: 5, EPOCH: 20, LR: 0.000757, train_loss: 0.017967\n",
      "[>>VAL]: FOLD: 5, EPOCH: 20, valid_loss: 0.017892\n",
      "[TRAIN]: FOLD: 5, EPOCH: 21, LR: 0.000430, train_loss: 0.017513\n",
      "[>>VAL]: FOLD: 5, EPOCH: 21, valid_loss: 0.017876\n",
      "[TRAIN]: FOLD: 5, EPOCH: 22, LR: 0.000192, train_loss: 0.017031\n",
      "[>>VAL]: FOLD: 5, EPOCH: 22, valid_loss: 0.017901\n",
      "[TRAIN]: FOLD: 5, EPOCH: 23, LR: 0.000048, train_loss: 0.016627\n",
      "[>>VAL]: FOLD: 5, EPOCH: 23, valid_loss: 0.017920\n",
      "[TRAIN]: FOLD: 5, EPOCH: 24, LR: 0.000000, train_loss: 0.016490\n",
      "[>>VAL]: FOLD: 5, EPOCH: 24, valid_loss: 0.017938\n",
      "[TRAIN]: FOLD: 6, EPOCH: 0, LR: 0.003478, train_loss: 0.475488\n",
      "[>>VAL]: FOLD: 6, EPOCH: 0, valid_loss: 0.026876\n",
      "[TRAIN]: FOLD: 6, EPOCH: 1, LR: 0.009066, train_loss: 0.024040\n",
      "[>>VAL]: FOLD: 6, EPOCH: 1, valid_loss: 0.019508\n",
      "[TRAIN]: FOLD: 6, EPOCH: 2, LR: 0.009987, train_loss: 0.021813\n",
      "[>>VAL]: FOLD: 6, EPOCH: 2, valid_loss: 0.018045\n",
      "[TRAIN]: FOLD: 6, EPOCH: 3, LR: 0.009890, train_loss: 0.020681\n",
      "[>>VAL]: FOLD: 6, EPOCH: 3, valid_loss: 0.017366\n",
      "[TRAIN]: FOLD: 6, EPOCH: 4, LR: 0.009697, train_loss: 0.020343\n",
      "[>>VAL]: FOLD: 6, EPOCH: 4, valid_loss: 0.017262\n",
      "[TRAIN]: FOLD: 6, EPOCH: 5, LR: 0.009413, train_loss: 0.020262\n",
      "[>>VAL]: FOLD: 6, EPOCH: 5, valid_loss: 0.017250\n",
      "[TRAIN]: FOLD: 6, EPOCH: 6, LR: 0.009042, train_loss: 0.020268\n",
      "[>>VAL]: FOLD: 6, EPOCH: 6, valid_loss: 0.017696\n",
      "[TRAIN]: FOLD: 6, EPOCH: 7, LR: 0.008593, train_loss: 0.020283\n",
      "[>>VAL]: FOLD: 6, EPOCH: 7, valid_loss: 0.017216\n",
      "[TRAIN]: FOLD: 6, EPOCH: 8, LR: 0.008075, train_loss: 0.020322\n",
      "[>>VAL]: FOLD: 6, EPOCH: 8, valid_loss: 0.017198\n",
      "[TRAIN]: FOLD: 6, EPOCH: 9, LR: 0.007496, train_loss: 0.020320\n",
      "[>>VAL]: FOLD: 6, EPOCH: 9, valid_loss: 0.017184\n",
      "[TRAIN]: FOLD: 6, EPOCH: 10, LR: 0.006869, train_loss: 0.020226\n",
      "[>>VAL]: FOLD: 6, EPOCH: 10, valid_loss: 0.017222\n",
      "[TRAIN]: FOLD: 6, EPOCH: 11, LR: 0.006205, train_loss: 0.020190\n",
      "[>>VAL]: FOLD: 6, EPOCH: 11, valid_loss: 0.017212\n",
      "[TRAIN]: FOLD: 6, EPOCH: 12, LR: 0.005518, train_loss: 0.020083\n",
      "[>>VAL]: FOLD: 6, EPOCH: 12, valid_loss: 0.017240\n",
      "[TRAIN]: FOLD: 6, EPOCH: 13, LR: 0.004821, train_loss: 0.020036\n",
      "[>>VAL]: FOLD: 6, EPOCH: 13, valid_loss: 0.016944\n",
      "[TRAIN]: FOLD: 6, EPOCH: 14, LR: 0.004127, train_loss: 0.019845\n",
      "[>>VAL]: FOLD: 6, EPOCH: 14, valid_loss: 0.017260\n",
      "[TRAIN]: FOLD: 6, EPOCH: 15, LR: 0.003450, train_loss: 0.019712\n",
      "[>>VAL]: FOLD: 6, EPOCH: 15, valid_loss: 0.017055\n",
      "[TRAIN]: FOLD: 6, EPOCH: 16, LR: 0.002804, train_loss: 0.019580\n",
      "[>>VAL]: FOLD: 6, EPOCH: 16, valid_loss: 0.017065\n",
      "[TRAIN]: FOLD: 6, EPOCH: 17, LR: 0.002200, train_loss: 0.019248\n",
      "[>>VAL]: FOLD: 6, EPOCH: 17, valid_loss: 0.016899\n",
      "[TRAIN]: FOLD: 6, EPOCH: 18, LR: 0.001651, train_loss: 0.018966\n",
      "[>>VAL]: FOLD: 6, EPOCH: 18, valid_loss: 0.016764\n",
      "[TRAIN]: FOLD: 6, EPOCH: 19, LR: 0.001167, train_loss: 0.018608\n",
      "[>>VAL]: FOLD: 6, EPOCH: 19, valid_loss: 0.016761\n",
      "[TRAIN]: FOLD: 6, EPOCH: 20, LR: 0.000757, train_loss: 0.018134\n",
      "[>>VAL]: FOLD: 6, EPOCH: 20, valid_loss: 0.016748\n",
      "[TRAIN]: FOLD: 6, EPOCH: 21, LR: 0.000430, train_loss: 0.017654\n",
      "[>>VAL]: FOLD: 6, EPOCH: 21, valid_loss: 0.016771\n",
      "[TRAIN]: FOLD: 6, EPOCH: 22, LR: 0.000192, train_loss: 0.017162\n",
      "[>>VAL]: FOLD: 6, EPOCH: 22, valid_loss: 0.016816\n",
      "[TRAIN]: FOLD: 6, EPOCH: 23, LR: 0.000048, train_loss: 0.016784\n",
      "[>>VAL]: FOLD: 6, EPOCH: 23, valid_loss: 0.016798\n",
      "[TRAIN]: FOLD: 6, EPOCH: 24, LR: 0.000000, train_loss: 0.016596\n",
      "[>>VAL]: FOLD: 6, EPOCH: 24, valid_loss: 0.016780\n",
      "\n",
      ">> SEED: 4\n",
      "\n",
      "[TRAIN]: FOLD: 0, EPOCH: 0, LR: 0.003478, train_loss: 0.475882\n",
      "[>>VAL]: FOLD: 0, EPOCH: 0, valid_loss: 0.025530\n",
      "[TRAIN]: FOLD: 0, EPOCH: 1, LR: 0.009066, train_loss: 0.023912\n",
      "[>>VAL]: FOLD: 0, EPOCH: 1, valid_loss: 0.019548\n",
      "[TRAIN]: FOLD: 0, EPOCH: 2, LR: 0.009987, train_loss: 0.021669\n",
      "[>>VAL]: FOLD: 0, EPOCH: 2, valid_loss: 0.018605\n",
      "[TRAIN]: FOLD: 0, EPOCH: 3, LR: 0.009890, train_loss: 0.020685\n",
      "[>>VAL]: FOLD: 0, EPOCH: 3, valid_loss: 0.017808\n",
      "[TRAIN]: FOLD: 0, EPOCH: 4, LR: 0.009697, train_loss: 0.020288\n",
      "[>>VAL]: FOLD: 0, EPOCH: 4, valid_loss: 0.018287\n",
      "[TRAIN]: FOLD: 0, EPOCH: 5, LR: 0.009413, train_loss: 0.020232\n",
      "[>>VAL]: FOLD: 0, EPOCH: 5, valid_loss: 0.017881\n",
      "[TRAIN]: FOLD: 0, EPOCH: 6, LR: 0.009042, train_loss: 0.020303\n",
      "[>>VAL]: FOLD: 0, EPOCH: 6, valid_loss: 0.017816\n",
      "[TRAIN]: FOLD: 0, EPOCH: 7, LR: 0.008593, train_loss: 0.020289\n",
      "[>>VAL]: FOLD: 0, EPOCH: 7, valid_loss: 0.017941\n",
      "[TRAIN]: FOLD: 0, EPOCH: 8, LR: 0.008075, train_loss: 0.020289\n",
      "[>>VAL]: FOLD: 0, EPOCH: 8, valid_loss: 0.017917\n",
      "[TRAIN]: FOLD: 0, EPOCH: 9, LR: 0.007496, train_loss: 0.020280\n",
      "[>>VAL]: FOLD: 0, EPOCH: 9, valid_loss: 0.018149\n",
      "[TRAIN]: FOLD: 0, EPOCH: 10, LR: 0.006869, train_loss: 0.020203\n",
      "[>>VAL]: FOLD: 0, EPOCH: 10, valid_loss: 0.017899\n",
      "[TRAIN]: FOLD: 0, EPOCH: 11, LR: 0.006205, train_loss: 0.020152\n",
      "[>>VAL]: FOLD: 0, EPOCH: 11, valid_loss: 0.018160\n",
      "[TRAIN]: FOLD: 0, EPOCH: 12, LR: 0.005518, train_loss: 0.020107\n",
      "[>>VAL]: FOLD: 0, EPOCH: 12, valid_loss: 0.017768\n",
      "[TRAIN]: FOLD: 0, EPOCH: 13, LR: 0.004821, train_loss: 0.019974\n",
      "[>>VAL]: FOLD: 0, EPOCH: 13, valid_loss: 0.017810\n",
      "[TRAIN]: FOLD: 0, EPOCH: 14, LR: 0.004127, train_loss: 0.019867\n",
      "[>>VAL]: FOLD: 0, EPOCH: 14, valid_loss: 0.017632\n",
      "[TRAIN]: FOLD: 0, EPOCH: 15, LR: 0.003450, train_loss: 0.019720\n",
      "[>>VAL]: FOLD: 0, EPOCH: 15, valid_loss: 0.017532\n",
      "[TRAIN]: FOLD: 0, EPOCH: 16, LR: 0.002804, train_loss: 0.019583\n",
      "[>>VAL]: FOLD: 0, EPOCH: 16, valid_loss: 0.017543\n",
      "[TRAIN]: FOLD: 0, EPOCH: 17, LR: 0.002200, train_loss: 0.019280\n",
      "[>>VAL]: FOLD: 0, EPOCH: 17, valid_loss: 0.017446\n",
      "[TRAIN]: FOLD: 0, EPOCH: 18, LR: 0.001651, train_loss: 0.018972\n",
      "[>>VAL]: FOLD: 0, EPOCH: 18, valid_loss: 0.017294\n",
      "[TRAIN]: FOLD: 0, EPOCH: 19, LR: 0.001167, train_loss: 0.018602\n",
      "[>>VAL]: FOLD: 0, EPOCH: 19, valid_loss: 0.017433\n",
      "[TRAIN]: FOLD: 0, EPOCH: 20, LR: 0.000757, train_loss: 0.018221\n",
      "[>>VAL]: FOLD: 0, EPOCH: 20, valid_loss: 0.017360\n",
      "[TRAIN]: FOLD: 0, EPOCH: 21, LR: 0.000430, train_loss: 0.017775\n",
      "[>>VAL]: FOLD: 0, EPOCH: 21, valid_loss: 0.017337\n",
      "[TRAIN]: FOLD: 0, EPOCH: 22, LR: 0.000192, train_loss: 0.017312\n",
      "[>>VAL]: FOLD: 0, EPOCH: 22, valid_loss: 0.017324\n",
      "[TRAIN]: FOLD: 0, EPOCH: 23, LR: 0.000048, train_loss: 0.016962\n",
      "[>>VAL]: FOLD: 0, EPOCH: 23, valid_loss: 0.017295\n",
      "[TRAIN]: FOLD: 0, EPOCH: 24, LR: 0.000000, train_loss: 0.016811\n",
      "[>>VAL]: FOLD: 0, EPOCH: 24, valid_loss: 0.017279\n",
      "[TRAIN]: FOLD: 1, EPOCH: 0, LR: 0.003478, train_loss: 0.475980\n",
      "[>>VAL]: FOLD: 1, EPOCH: 0, valid_loss: 0.023864\n",
      "[TRAIN]: FOLD: 1, EPOCH: 1, LR: 0.009066, train_loss: 0.023904\n",
      "[>>VAL]: FOLD: 1, EPOCH: 1, valid_loss: 0.019055\n",
      "[TRAIN]: FOLD: 1, EPOCH: 2, LR: 0.009987, train_loss: 0.021912\n",
      "[>>VAL]: FOLD: 1, EPOCH: 2, valid_loss: 0.017858\n",
      "[TRAIN]: FOLD: 1, EPOCH: 3, LR: 0.009890, train_loss: 0.020852\n",
      "[>>VAL]: FOLD: 1, EPOCH: 3, valid_loss: 0.017619\n",
      "[TRAIN]: FOLD: 1, EPOCH: 4, LR: 0.009697, train_loss: 0.020305\n",
      "[>>VAL]: FOLD: 1, EPOCH: 4, valid_loss: 0.017614\n",
      "[TRAIN]: FOLD: 1, EPOCH: 5, LR: 0.009412, train_loss: 0.020282\n",
      "[>>VAL]: FOLD: 1, EPOCH: 5, valid_loss: 0.017631\n",
      "[TRAIN]: FOLD: 1, EPOCH: 6, LR: 0.009042, train_loss: 0.020250\n",
      "[>>VAL]: FOLD: 1, EPOCH: 6, valid_loss: 0.018467\n",
      "[TRAIN]: FOLD: 1, EPOCH: 7, LR: 0.008593, train_loss: 0.020323\n",
      "[>>VAL]: FOLD: 1, EPOCH: 7, valid_loss: 0.017662\n",
      "[TRAIN]: FOLD: 1, EPOCH: 8, LR: 0.008075, train_loss: 0.020308\n",
      "[>>VAL]: FOLD: 1, EPOCH: 8, valid_loss: 0.017596\n",
      "[TRAIN]: FOLD: 1, EPOCH: 9, LR: 0.007496, train_loss: 0.020242\n",
      "[>>VAL]: FOLD: 1, EPOCH: 9, valid_loss: 0.017526\n",
      "[TRAIN]: FOLD: 1, EPOCH: 10, LR: 0.006869, train_loss: 0.020249\n",
      "[>>VAL]: FOLD: 1, EPOCH: 10, valid_loss: 0.017737\n",
      "[TRAIN]: FOLD: 1, EPOCH: 11, LR: 0.006205, train_loss: 0.020129\n",
      "[>>VAL]: FOLD: 1, EPOCH: 11, valid_loss: 0.017483\n",
      "[TRAIN]: FOLD: 1, EPOCH: 12, LR: 0.005518, train_loss: 0.020136\n",
      "[>>VAL]: FOLD: 1, EPOCH: 12, valid_loss: 0.017316\n",
      "[TRAIN]: FOLD: 1, EPOCH: 13, LR: 0.004821, train_loss: 0.020073\n",
      "[>>VAL]: FOLD: 1, EPOCH: 13, valid_loss: 0.017326\n",
      "[TRAIN]: FOLD: 1, EPOCH: 14, LR: 0.004127, train_loss: 0.019907\n",
      "[>>VAL]: FOLD: 1, EPOCH: 14, valid_loss: 0.017381\n",
      "[TRAIN]: FOLD: 1, EPOCH: 15, LR: 0.003450, train_loss: 0.019736\n",
      "[>>VAL]: FOLD: 1, EPOCH: 15, valid_loss: 0.017216\n",
      "[TRAIN]: FOLD: 1, EPOCH: 16, LR: 0.002804, train_loss: 0.019560\n",
      "[>>VAL]: FOLD: 1, EPOCH: 16, valid_loss: 0.017190\n",
      "[TRAIN]: FOLD: 1, EPOCH: 17, LR: 0.002200, train_loss: 0.019242\n",
      "[>>VAL]: FOLD: 1, EPOCH: 17, valid_loss: 0.017306\n",
      "[TRAIN]: FOLD: 1, EPOCH: 18, LR: 0.001651, train_loss: 0.018974\n",
      "[>>VAL]: FOLD: 1, EPOCH: 18, valid_loss: 0.016981\n",
      "[TRAIN]: FOLD: 1, EPOCH: 19, LR: 0.001167, train_loss: 0.018591\n",
      "[>>VAL]: FOLD: 1, EPOCH: 19, valid_loss: 0.017165\n",
      "[TRAIN]: FOLD: 1, EPOCH: 20, LR: 0.000757, train_loss: 0.018186\n",
      "[>>VAL]: FOLD: 1, EPOCH: 20, valid_loss: 0.017030\n",
      "[TRAIN]: FOLD: 1, EPOCH: 21, LR: 0.000430, train_loss: 0.017699\n",
      "[>>VAL]: FOLD: 1, EPOCH: 21, valid_loss: 0.016949\n",
      "[TRAIN]: FOLD: 1, EPOCH: 22, LR: 0.000192, train_loss: 0.017266\n",
      "[>>VAL]: FOLD: 1, EPOCH: 22, valid_loss: 0.017005\n",
      "[TRAIN]: FOLD: 1, EPOCH: 23, LR: 0.000048, train_loss: 0.016867\n",
      "[>>VAL]: FOLD: 1, EPOCH: 23, valid_loss: 0.017009\n",
      "[TRAIN]: FOLD: 1, EPOCH: 24, LR: 0.000000, train_loss: 0.016693\n",
      "[>>VAL]: FOLD: 1, EPOCH: 24, valid_loss: 0.017007\n",
      "[TRAIN]: FOLD: 2, EPOCH: 0, LR: 0.003478, train_loss: 0.475528\n",
      "[>>VAL]: FOLD: 2, EPOCH: 0, valid_loss: 0.027102\n",
      "[TRAIN]: FOLD: 2, EPOCH: 1, LR: 0.009066, train_loss: 0.023948\n",
      "[>>VAL]: FOLD: 2, EPOCH: 1, valid_loss: 0.019634\n",
      "[TRAIN]: FOLD: 2, EPOCH: 2, LR: 0.009987, train_loss: 0.021807\n",
      "[>>VAL]: FOLD: 2, EPOCH: 2, valid_loss: 0.018830\n",
      "[TRAIN]: FOLD: 2, EPOCH: 3, LR: 0.009890, train_loss: 0.020609\n",
      "[>>VAL]: FOLD: 2, EPOCH: 3, valid_loss: 0.018639\n",
      "[TRAIN]: FOLD: 2, EPOCH: 4, LR: 0.009697, train_loss: 0.020078\n",
      "[>>VAL]: FOLD: 2, EPOCH: 4, valid_loss: 0.018366\n",
      "[TRAIN]: FOLD: 2, EPOCH: 5, LR: 0.009413, train_loss: 0.020066\n",
      "[>>VAL]: FOLD: 2, EPOCH: 5, valid_loss: 0.018405\n",
      "[TRAIN]: FOLD: 2, EPOCH: 6, LR: 0.009042, train_loss: 0.020108\n",
      "[>>VAL]: FOLD: 2, EPOCH: 6, valid_loss: 0.018606\n",
      "[TRAIN]: FOLD: 2, EPOCH: 7, LR: 0.008593, train_loss: 0.020146\n",
      "[>>VAL]: FOLD: 2, EPOCH: 7, valid_loss: 0.018351\n",
      "[TRAIN]: FOLD: 2, EPOCH: 8, LR: 0.008075, train_loss: 0.020103\n",
      "[>>VAL]: FOLD: 2, EPOCH: 8, valid_loss: 0.018238\n",
      "[TRAIN]: FOLD: 2, EPOCH: 9, LR: 0.007496, train_loss: 0.020074\n",
      "[>>VAL]: FOLD: 2, EPOCH: 9, valid_loss: 0.018584\n",
      "[TRAIN]: FOLD: 2, EPOCH: 10, LR: 0.006869, train_loss: 0.020104\n",
      "[>>VAL]: FOLD: 2, EPOCH: 10, valid_loss: 0.018422\n",
      "[TRAIN]: FOLD: 2, EPOCH: 11, LR: 0.006205, train_loss: 0.020052\n",
      "[>>VAL]: FOLD: 2, EPOCH: 11, valid_loss: 0.018402\n",
      "[TRAIN]: FOLD: 2, EPOCH: 12, LR: 0.005518, train_loss: 0.019948\n",
      "[>>VAL]: FOLD: 2, EPOCH: 12, valid_loss: 0.018267\n",
      "[TRAIN]: FOLD: 2, EPOCH: 13, LR: 0.004821, train_loss: 0.019864\n",
      "[>>VAL]: FOLD: 2, EPOCH: 13, valid_loss: 0.018157\n",
      "[TRAIN]: FOLD: 2, EPOCH: 14, LR: 0.004127, train_loss: 0.019697\n",
      "[>>VAL]: FOLD: 2, EPOCH: 14, valid_loss: 0.018415\n",
      "[TRAIN]: FOLD: 2, EPOCH: 15, LR: 0.003450, train_loss: 0.019579\n",
      "[>>VAL]: FOLD: 2, EPOCH: 15, valid_loss: 0.018002\n",
      "[TRAIN]: FOLD: 2, EPOCH: 16, LR: 0.002804, train_loss: 0.019329\n",
      "[>>VAL]: FOLD: 2, EPOCH: 16, valid_loss: 0.017992\n",
      "[TRAIN]: FOLD: 2, EPOCH: 17, LR: 0.002200, train_loss: 0.019069\n",
      "[>>VAL]: FOLD: 2, EPOCH: 17, valid_loss: 0.017938\n",
      "[TRAIN]: FOLD: 2, EPOCH: 18, LR: 0.001651, train_loss: 0.018820\n",
      "[>>VAL]: FOLD: 2, EPOCH: 18, valid_loss: 0.017753\n",
      "[TRAIN]: FOLD: 2, EPOCH: 19, LR: 0.001167, train_loss: 0.018404\n",
      "[>>VAL]: FOLD: 2, EPOCH: 19, valid_loss: 0.017772\n",
      "[TRAIN]: FOLD: 2, EPOCH: 20, LR: 0.000757, train_loss: 0.018012\n",
      "[>>VAL]: FOLD: 2, EPOCH: 20, valid_loss: 0.017813\n",
      "[TRAIN]: FOLD: 2, EPOCH: 21, LR: 0.000430, train_loss: 0.017516\n",
      "[>>VAL]: FOLD: 2, EPOCH: 21, valid_loss: 0.017760\n",
      "[TRAIN]: FOLD: 2, EPOCH: 22, LR: 0.000192, train_loss: 0.016977\n",
      "[>>VAL]: FOLD: 2, EPOCH: 22, valid_loss: 0.017880\n",
      "[TRAIN]: FOLD: 2, EPOCH: 23, LR: 0.000048, train_loss: 0.016611\n",
      "[>>VAL]: FOLD: 2, EPOCH: 23, valid_loss: 0.017852\n",
      "[TRAIN]: FOLD: 2, EPOCH: 24, LR: 0.000000, train_loss: 0.016422\n",
      "[>>VAL]: FOLD: 2, EPOCH: 24, valid_loss: 0.017805\n",
      "[TRAIN]: FOLD: 3, EPOCH: 0, LR: 0.003478, train_loss: 0.475242\n",
      "[>>VAL]: FOLD: 3, EPOCH: 0, valid_loss: 0.025630\n",
      "[TRAIN]: FOLD: 3, EPOCH: 1, LR: 0.009066, train_loss: 0.023736\n",
      "[>>VAL]: FOLD: 3, EPOCH: 1, valid_loss: 0.019414\n",
      "[TRAIN]: FOLD: 3, EPOCH: 2, LR: 0.009987, train_loss: 0.021662\n",
      "[>>VAL]: FOLD: 3, EPOCH: 2, valid_loss: 0.019056\n",
      "[TRAIN]: FOLD: 3, EPOCH: 3, LR: 0.009890, train_loss: 0.020678\n",
      "[>>VAL]: FOLD: 3, EPOCH: 3, valid_loss: 0.017652\n",
      "[TRAIN]: FOLD: 3, EPOCH: 4, LR: 0.009697, train_loss: 0.020236\n",
      "[>>VAL]: FOLD: 3, EPOCH: 4, valid_loss: 0.017749\n",
      "[TRAIN]: FOLD: 3, EPOCH: 5, LR: 0.009412, train_loss: 0.020180\n",
      "[>>VAL]: FOLD: 3, EPOCH: 5, valid_loss: 0.017566\n",
      "[TRAIN]: FOLD: 3, EPOCH: 6, LR: 0.009042, train_loss: 0.020183\n",
      "[>>VAL]: FOLD: 3, EPOCH: 6, valid_loss: 0.017814\n",
      "[TRAIN]: FOLD: 3, EPOCH: 7, LR: 0.008593, train_loss: 0.020287\n",
      "[>>VAL]: FOLD: 3, EPOCH: 7, valid_loss: 0.017723\n",
      "[TRAIN]: FOLD: 3, EPOCH: 8, LR: 0.008075, train_loss: 0.020278\n",
      "[>>VAL]: FOLD: 3, EPOCH: 8, valid_loss: 0.017599\n",
      "[TRAIN]: FOLD: 3, EPOCH: 9, LR: 0.007496, train_loss: 0.020256\n",
      "[>>VAL]: FOLD: 3, EPOCH: 9, valid_loss: 0.017730\n",
      "[TRAIN]: FOLD: 3, EPOCH: 10, LR: 0.006869, train_loss: 0.020240\n",
      "[>>VAL]: FOLD: 3, EPOCH: 10, valid_loss: 0.017618\n",
      "[TRAIN]: FOLD: 3, EPOCH: 11, LR: 0.006205, train_loss: 0.020199\n",
      "[>>VAL]: FOLD: 3, EPOCH: 11, valid_loss: 0.017698\n",
      "[TRAIN]: FOLD: 3, EPOCH: 12, LR: 0.005518, train_loss: 0.020101\n",
      "[>>VAL]: FOLD: 3, EPOCH: 12, valid_loss: 0.017374\n",
      "[TRAIN]: FOLD: 3, EPOCH: 13, LR: 0.004821, train_loss: 0.019950\n",
      "[>>VAL]: FOLD: 3, EPOCH: 13, valid_loss: 0.017300\n",
      "[TRAIN]: FOLD: 3, EPOCH: 14, LR: 0.004127, train_loss: 0.019895\n",
      "[>>VAL]: FOLD: 3, EPOCH: 14, valid_loss: 0.017385\n",
      "[TRAIN]: FOLD: 3, EPOCH: 15, LR: 0.003450, train_loss: 0.019708\n",
      "[>>VAL]: FOLD: 3, EPOCH: 15, valid_loss: 0.017255\n",
      "[TRAIN]: FOLD: 3, EPOCH: 16, LR: 0.002804, train_loss: 0.019477\n",
      "[>>VAL]: FOLD: 3, EPOCH: 16, valid_loss: 0.017249\n",
      "[TRAIN]: FOLD: 3, EPOCH: 17, LR: 0.002200, train_loss: 0.019269\n",
      "[>>VAL]: FOLD: 3, EPOCH: 17, valid_loss: 0.017290\n",
      "[TRAIN]: FOLD: 3, EPOCH: 18, LR: 0.001651, train_loss: 0.018926\n",
      "[>>VAL]: FOLD: 3, EPOCH: 18, valid_loss: 0.016923\n",
      "[TRAIN]: FOLD: 3, EPOCH: 19, LR: 0.001167, train_loss: 0.018581\n",
      "[>>VAL]: FOLD: 3, EPOCH: 19, valid_loss: 0.017007\n",
      "[TRAIN]: FOLD: 3, EPOCH: 20, LR: 0.000757, train_loss: 0.018142\n",
      "[>>VAL]: FOLD: 3, EPOCH: 20, valid_loss: 0.016888\n",
      "[TRAIN]: FOLD: 3, EPOCH: 21, LR: 0.000430, train_loss: 0.017685\n",
      "[>>VAL]: FOLD: 3, EPOCH: 21, valid_loss: 0.016896\n",
      "[TRAIN]: FOLD: 3, EPOCH: 22, LR: 0.000192, train_loss: 0.017218\n",
      "[>>VAL]: FOLD: 3, EPOCH: 22, valid_loss: 0.016882\n",
      "[TRAIN]: FOLD: 3, EPOCH: 23, LR: 0.000048, train_loss: 0.016838\n",
      "[>>VAL]: FOLD: 3, EPOCH: 23, valid_loss: 0.016848\n",
      "[TRAIN]: FOLD: 3, EPOCH: 24, LR: 0.000000, train_loss: 0.016653\n",
      "[>>VAL]: FOLD: 3, EPOCH: 24, valid_loss: 0.016863\n",
      "[TRAIN]: FOLD: 4, EPOCH: 0, LR: 0.003478, train_loss: 0.474210\n",
      "[>>VAL]: FOLD: 4, EPOCH: 0, valid_loss: 0.026360\n",
      "[TRAIN]: FOLD: 4, EPOCH: 1, LR: 0.009066, train_loss: 0.024055\n",
      "[>>VAL]: FOLD: 4, EPOCH: 1, valid_loss: 0.019278\n",
      "[TRAIN]: FOLD: 4, EPOCH: 2, LR: 0.009987, train_loss: 0.021991\n",
      "[>>VAL]: FOLD: 4, EPOCH: 2, valid_loss: 0.018491\n",
      "[TRAIN]: FOLD: 4, EPOCH: 3, LR: 0.009890, train_loss: 0.020707\n",
      "[>>VAL]: FOLD: 4, EPOCH: 3, valid_loss: 0.018362\n",
      "[TRAIN]: FOLD: 4, EPOCH: 4, LR: 0.009697, train_loss: 0.020250\n",
      "[>>VAL]: FOLD: 4, EPOCH: 4, valid_loss: 0.018016\n",
      "[TRAIN]: FOLD: 4, EPOCH: 5, LR: 0.009413, train_loss: 0.020160\n",
      "[>>VAL]: FOLD: 4, EPOCH: 5, valid_loss: 0.017962\n",
      "[TRAIN]: FOLD: 4, EPOCH: 6, LR: 0.009042, train_loss: 0.020184\n",
      "[>>VAL]: FOLD: 4, EPOCH: 6, valid_loss: 0.018113\n",
      "[TRAIN]: FOLD: 4, EPOCH: 7, LR: 0.008593, train_loss: 0.020265\n",
      "[>>VAL]: FOLD: 4, EPOCH: 7, valid_loss: 0.018025\n",
      "[TRAIN]: FOLD: 4, EPOCH: 8, LR: 0.008075, train_loss: 0.020187\n",
      "[>>VAL]: FOLD: 4, EPOCH: 8, valid_loss: 0.018015\n",
      "[TRAIN]: FOLD: 4, EPOCH: 9, LR: 0.007496, train_loss: 0.020271\n",
      "[>>VAL]: FOLD: 4, EPOCH: 9, valid_loss: 0.017893\n",
      "[TRAIN]: FOLD: 4, EPOCH: 10, LR: 0.006869, train_loss: 0.020151\n",
      "[>>VAL]: FOLD: 4, EPOCH: 10, valid_loss: 0.017937\n",
      "[TRAIN]: FOLD: 4, EPOCH: 11, LR: 0.006205, train_loss: 0.020132\n",
      "[>>VAL]: FOLD: 4, EPOCH: 11, valid_loss: 0.018053\n",
      "[TRAIN]: FOLD: 4, EPOCH: 12, LR: 0.005518, train_loss: 0.020051\n",
      "[>>VAL]: FOLD: 4, EPOCH: 12, valid_loss: 0.017897\n",
      "[TRAIN]: FOLD: 4, EPOCH: 13, LR: 0.004821, train_loss: 0.019945\n",
      "[>>VAL]: FOLD: 4, EPOCH: 13, valid_loss: 0.017816\n",
      "[TRAIN]: FOLD: 4, EPOCH: 14, LR: 0.004127, train_loss: 0.019803\n",
      "[>>VAL]: FOLD: 4, EPOCH: 14, valid_loss: 0.017631\n",
      "[TRAIN]: FOLD: 4, EPOCH: 15, LR: 0.003450, train_loss: 0.019632\n",
      "[>>VAL]: FOLD: 4, EPOCH: 15, valid_loss: 0.017714\n",
      "[TRAIN]: FOLD: 4, EPOCH: 16, LR: 0.002804, train_loss: 0.019456\n",
      "[>>VAL]: FOLD: 4, EPOCH: 16, valid_loss: 0.017606\n",
      "[TRAIN]: FOLD: 4, EPOCH: 17, LR: 0.002200, train_loss: 0.019204\n",
      "[>>VAL]: FOLD: 4, EPOCH: 17, valid_loss: 0.017507\n",
      "[TRAIN]: FOLD: 4, EPOCH: 18, LR: 0.001651, train_loss: 0.018867\n",
      "[>>VAL]: FOLD: 4, EPOCH: 18, valid_loss: 0.017576\n",
      "[TRAIN]: FOLD: 4, EPOCH: 19, LR: 0.001167, train_loss: 0.018478\n",
      "[>>VAL]: FOLD: 4, EPOCH: 19, valid_loss: 0.017526\n",
      "[TRAIN]: FOLD: 4, EPOCH: 20, LR: 0.000757, train_loss: 0.018020\n",
      "[>>VAL]: FOLD: 4, EPOCH: 20, valid_loss: 0.017442\n",
      "[TRAIN]: FOLD: 4, EPOCH: 21, LR: 0.000430, train_loss: 0.017481\n",
      "[>>VAL]: FOLD: 4, EPOCH: 21, valid_loss: 0.017380\n",
      "[TRAIN]: FOLD: 4, EPOCH: 22, LR: 0.000192, train_loss: 0.016978\n",
      "[>>VAL]: FOLD: 4, EPOCH: 22, valid_loss: 0.017469\n",
      "[TRAIN]: FOLD: 4, EPOCH: 23, LR: 0.000048, train_loss: 0.016539\n",
      "[>>VAL]: FOLD: 4, EPOCH: 23, valid_loss: 0.017485\n",
      "[TRAIN]: FOLD: 4, EPOCH: 24, LR: 0.000000, train_loss: 0.016351\n",
      "[>>VAL]: FOLD: 4, EPOCH: 24, valid_loss: 0.017487\n",
      "[TRAIN]: FOLD: 5, EPOCH: 0, LR: 0.003478, train_loss: 0.475517\n",
      "[>>VAL]: FOLD: 5, EPOCH: 0, valid_loss: 0.026310\n",
      "[TRAIN]: FOLD: 5, EPOCH: 1, LR: 0.009066, train_loss: 0.023846\n",
      "[>>VAL]: FOLD: 5, EPOCH: 1, valid_loss: 0.019695\n",
      "[TRAIN]: FOLD: 5, EPOCH: 2, LR: 0.009987, train_loss: 0.022123\n",
      "[>>VAL]: FOLD: 5, EPOCH: 2, valid_loss: 0.018536\n",
      "[TRAIN]: FOLD: 5, EPOCH: 3, LR: 0.009890, train_loss: 0.020703\n",
      "[>>VAL]: FOLD: 5, EPOCH: 3, valid_loss: 0.018580\n",
      "[TRAIN]: FOLD: 5, EPOCH: 4, LR: 0.009697, train_loss: 0.020256\n",
      "[>>VAL]: FOLD: 5, EPOCH: 4, valid_loss: 0.018239\n",
      "[TRAIN]: FOLD: 5, EPOCH: 5, LR: 0.009412, train_loss: 0.020071\n",
      "[>>VAL]: FOLD: 5, EPOCH: 5, valid_loss: 0.018496\n",
      "[TRAIN]: FOLD: 5, EPOCH: 6, LR: 0.009042, train_loss: 0.020031\n",
      "[>>VAL]: FOLD: 5, EPOCH: 6, valid_loss: 0.018798\n",
      "[TRAIN]: FOLD: 5, EPOCH: 7, LR: 0.008593, train_loss: 0.020076\n",
      "[>>VAL]: FOLD: 5, EPOCH: 7, valid_loss: 0.018829\n",
      "[TRAIN]: FOLD: 5, EPOCH: 8, LR: 0.008075, train_loss: 0.020164\n",
      "[>>VAL]: FOLD: 5, EPOCH: 8, valid_loss: 0.018556\n",
      "[TRAIN]: FOLD: 5, EPOCH: 9, LR: 0.007496, train_loss: 0.020122\n",
      "[>>VAL]: FOLD: 5, EPOCH: 9, valid_loss: 0.018192\n",
      "[TRAIN]: FOLD: 5, EPOCH: 10, LR: 0.006869, train_loss: 0.020114\n",
      "[>>VAL]: FOLD: 5, EPOCH: 10, valid_loss: 0.018242\n",
      "[TRAIN]: FOLD: 5, EPOCH: 11, LR: 0.006205, train_loss: 0.020037\n",
      "[>>VAL]: FOLD: 5, EPOCH: 11, valid_loss: 0.018251\n",
      "[TRAIN]: FOLD: 5, EPOCH: 12, LR: 0.005518, train_loss: 0.019926\n",
      "[>>VAL]: FOLD: 5, EPOCH: 12, valid_loss: 0.018309\n",
      "[TRAIN]: FOLD: 5, EPOCH: 13, LR: 0.004821, train_loss: 0.019854\n",
      "[>>VAL]: FOLD: 5, EPOCH: 13, valid_loss: 0.018626\n",
      "[TRAIN]: FOLD: 5, EPOCH: 14, LR: 0.004127, train_loss: 0.019708\n",
      "[>>VAL]: FOLD: 5, EPOCH: 14, valid_loss: 0.018288\n",
      "[TRAIN]: FOLD: 5, EPOCH: 15, LR: 0.003450, train_loss: 0.019554\n",
      "[>>VAL]: FOLD: 5, EPOCH: 15, valid_loss: 0.017950\n",
      "[TRAIN]: FOLD: 5, EPOCH: 16, LR: 0.002804, train_loss: 0.019266\n",
      "[>>VAL]: FOLD: 5, EPOCH: 16, valid_loss: 0.018079\n",
      "[TRAIN]: FOLD: 5, EPOCH: 17, LR: 0.002200, train_loss: 0.019141\n",
      "[>>VAL]: FOLD: 5, EPOCH: 17, valid_loss: 0.018059\n",
      "[TRAIN]: FOLD: 5, EPOCH: 18, LR: 0.001651, train_loss: 0.018846\n",
      "[>>VAL]: FOLD: 5, EPOCH: 18, valid_loss: 0.017984\n",
      "[TRAIN]: FOLD: 5, EPOCH: 19, LR: 0.001167, train_loss: 0.018482\n",
      "[>>VAL]: FOLD: 5, EPOCH: 19, valid_loss: 0.017867\n",
      "[TRAIN]: FOLD: 5, EPOCH: 20, LR: 0.000757, train_loss: 0.017973\n",
      "[>>VAL]: FOLD: 5, EPOCH: 20, valid_loss: 0.017957\n",
      "[TRAIN]: FOLD: 5, EPOCH: 21, LR: 0.000430, train_loss: 0.017509\n",
      "[>>VAL]: FOLD: 5, EPOCH: 21, valid_loss: 0.017924\n",
      "[TRAIN]: FOLD: 5, EPOCH: 22, LR: 0.000192, train_loss: 0.017040\n",
      "[>>VAL]: FOLD: 5, EPOCH: 22, valid_loss: 0.017950\n",
      "[TRAIN]: FOLD: 5, EPOCH: 23, LR: 0.000048, train_loss: 0.016662\n",
      "[>>VAL]: FOLD: 5, EPOCH: 23, valid_loss: 0.017915\n",
      "[TRAIN]: FOLD: 5, EPOCH: 24, LR: 0.000000, train_loss: 0.016458\n",
      "[>>VAL]: FOLD: 5, EPOCH: 24, valid_loss: 0.017925\n",
      "[TRAIN]: FOLD: 6, EPOCH: 0, LR: 0.003478, train_loss: 0.475444\n",
      "[>>VAL]: FOLD: 6, EPOCH: 0, valid_loss: 0.024772\n",
      "[TRAIN]: FOLD: 6, EPOCH: 1, LR: 0.009066, train_loss: 0.024005\n",
      "[>>VAL]: FOLD: 6, EPOCH: 1, valid_loss: 0.018604\n",
      "[TRAIN]: FOLD: 6, EPOCH: 2, LR: 0.009987, train_loss: 0.022232\n",
      "[>>VAL]: FOLD: 6, EPOCH: 2, valid_loss: 0.018874\n",
      "[TRAIN]: FOLD: 6, EPOCH: 3, LR: 0.009890, train_loss: 0.020817\n",
      "[>>VAL]: FOLD: 6, EPOCH: 3, valid_loss: 0.017337\n",
      "[TRAIN]: FOLD: 6, EPOCH: 4, LR: 0.009697, train_loss: 0.020318\n",
      "[>>VAL]: FOLD: 6, EPOCH: 4, valid_loss: 0.017614\n",
      "[TRAIN]: FOLD: 6, EPOCH: 5, LR: 0.009413, train_loss: 0.020356\n",
      "[>>VAL]: FOLD: 6, EPOCH: 5, valid_loss: 0.017429\n",
      "[TRAIN]: FOLD: 6, EPOCH: 6, LR: 0.009042, train_loss: 0.020287\n",
      "[>>VAL]: FOLD: 6, EPOCH: 6, valid_loss: 0.017320\n",
      "[TRAIN]: FOLD: 6, EPOCH: 7, LR: 0.008593, train_loss: 0.020329\n",
      "[>>VAL]: FOLD: 6, EPOCH: 7, valid_loss: 0.017372\n",
      "[TRAIN]: FOLD: 6, EPOCH: 8, LR: 0.008075, train_loss: 0.020284\n",
      "[>>VAL]: FOLD: 6, EPOCH: 8, valid_loss: 0.018328\n",
      "[TRAIN]: FOLD: 6, EPOCH: 9, LR: 0.007496, train_loss: 0.020274\n",
      "[>>VAL]: FOLD: 6, EPOCH: 9, valid_loss: 0.017306\n",
      "[TRAIN]: FOLD: 6, EPOCH: 10, LR: 0.006869, train_loss: 0.020246\n",
      "[>>VAL]: FOLD: 6, EPOCH: 10, valid_loss: 0.017484\n",
      "[TRAIN]: FOLD: 6, EPOCH: 11, LR: 0.006205, train_loss: 0.020210\n",
      "[>>VAL]: FOLD: 6, EPOCH: 11, valid_loss: 0.017417\n",
      "[TRAIN]: FOLD: 6, EPOCH: 12, LR: 0.005518, train_loss: 0.020146\n",
      "[>>VAL]: FOLD: 6, EPOCH: 12, valid_loss: 0.017449\n",
      "[TRAIN]: FOLD: 6, EPOCH: 13, LR: 0.004821, train_loss: 0.020051\n",
      "[>>VAL]: FOLD: 6, EPOCH: 13, valid_loss: 0.017201\n",
      "[TRAIN]: FOLD: 6, EPOCH: 14, LR: 0.004127, train_loss: 0.019859\n",
      "[>>VAL]: FOLD: 6, EPOCH: 14, valid_loss: 0.016921\n",
      "[TRAIN]: FOLD: 6, EPOCH: 15, LR: 0.003450, train_loss: 0.019690\n",
      "[>>VAL]: FOLD: 6, EPOCH: 15, valid_loss: 0.016810\n",
      "[TRAIN]: FOLD: 6, EPOCH: 16, LR: 0.002804, train_loss: 0.019598\n",
      "[>>VAL]: FOLD: 6, EPOCH: 16, valid_loss: 0.016884\n",
      "[TRAIN]: FOLD: 6, EPOCH: 17, LR: 0.002200, train_loss: 0.019281\n",
      "[>>VAL]: FOLD: 6, EPOCH: 17, valid_loss: 0.016777\n",
      "[TRAIN]: FOLD: 6, EPOCH: 18, LR: 0.001651, train_loss: 0.018988\n",
      "[>>VAL]: FOLD: 6, EPOCH: 18, valid_loss: 0.016725\n",
      "[TRAIN]: FOLD: 6, EPOCH: 19, LR: 0.001167, train_loss: 0.018614\n",
      "[>>VAL]: FOLD: 6, EPOCH: 19, valid_loss: 0.016745\n",
      "[TRAIN]: FOLD: 6, EPOCH: 20, LR: 0.000757, train_loss: 0.018242\n",
      "[>>VAL]: FOLD: 6, EPOCH: 20, valid_loss: 0.016683\n",
      "[TRAIN]: FOLD: 6, EPOCH: 21, LR: 0.000430, train_loss: 0.017722\n",
      "[>>VAL]: FOLD: 6, EPOCH: 21, valid_loss: 0.016727\n",
      "[TRAIN]: FOLD: 6, EPOCH: 22, LR: 0.000192, train_loss: 0.017269\n",
      "[>>VAL]: FOLD: 6, EPOCH: 22, valid_loss: 0.016748\n",
      "[TRAIN]: FOLD: 6, EPOCH: 23, LR: 0.000048, train_loss: 0.016907\n",
      "[>>VAL]: FOLD: 6, EPOCH: 23, valid_loss: 0.016744\n",
      "[TRAIN]: FOLD: 6, EPOCH: 24, LR: 0.000000, train_loss: 0.016735\n",
      "[>>VAL]: FOLD: 6, EPOCH: 24, valid_loss: 0.016762\n",
      "\n",
      ">> SEED: 5\n",
      "\n",
      "[TRAIN]: FOLD: 0, EPOCH: 0, LR: 0.003478, train_loss: 0.474099\n",
      "[>>VAL]: FOLD: 0, EPOCH: 0, valid_loss: 0.026915\n",
      "[TRAIN]: FOLD: 0, EPOCH: 1, LR: 0.009066, train_loss: 0.024042\n",
      "[>>VAL]: FOLD: 0, EPOCH: 1, valid_loss: 0.019562\n",
      "[TRAIN]: FOLD: 0, EPOCH: 2, LR: 0.009987, train_loss: 0.021767\n",
      "[>>VAL]: FOLD: 0, EPOCH: 2, valid_loss: 0.018378\n",
      "[TRAIN]: FOLD: 0, EPOCH: 3, LR: 0.009890, train_loss: 0.020671\n",
      "[>>VAL]: FOLD: 0, EPOCH: 3, valid_loss: 0.018023\n",
      "[TRAIN]: FOLD: 0, EPOCH: 4, LR: 0.009697, train_loss: 0.020263\n",
      "[>>VAL]: FOLD: 0, EPOCH: 4, valid_loss: 0.017981\n",
      "[TRAIN]: FOLD: 0, EPOCH: 5, LR: 0.009413, train_loss: 0.020241\n",
      "[>>VAL]: FOLD: 0, EPOCH: 5, valid_loss: 0.017925\n",
      "[TRAIN]: FOLD: 0, EPOCH: 6, LR: 0.009042, train_loss: 0.020237\n",
      "[>>VAL]: FOLD: 0, EPOCH: 6, valid_loss: 0.017918\n",
      "[TRAIN]: FOLD: 0, EPOCH: 7, LR: 0.008593, train_loss: 0.020269\n",
      "[>>VAL]: FOLD: 0, EPOCH: 7, valid_loss: 0.017899\n",
      "[TRAIN]: FOLD: 0, EPOCH: 8, LR: 0.008075, train_loss: 0.020202\n",
      "[>>VAL]: FOLD: 0, EPOCH: 8, valid_loss: 0.017783\n",
      "[TRAIN]: FOLD: 0, EPOCH: 9, LR: 0.007496, train_loss: 0.020261\n",
      "[>>VAL]: FOLD: 0, EPOCH: 9, valid_loss: 0.017904\n",
      "[TRAIN]: FOLD: 0, EPOCH: 10, LR: 0.006869, train_loss: 0.020148\n",
      "[>>VAL]: FOLD: 0, EPOCH: 10, valid_loss: 0.017796\n",
      "[TRAIN]: FOLD: 0, EPOCH: 11, LR: 0.006205, train_loss: 0.020148\n",
      "[>>VAL]: FOLD: 0, EPOCH: 11, valid_loss: 0.017738\n",
      "[TRAIN]: FOLD: 0, EPOCH: 12, LR: 0.005518, train_loss: 0.020033\n",
      "[>>VAL]: FOLD: 0, EPOCH: 12, valid_loss: 0.017684\n",
      "[TRAIN]: FOLD: 0, EPOCH: 13, LR: 0.004821, train_loss: 0.019963\n",
      "[>>VAL]: FOLD: 0, EPOCH: 13, valid_loss: 0.017857\n",
      "[TRAIN]: FOLD: 0, EPOCH: 14, LR: 0.004127, train_loss: 0.019801\n",
      "[>>VAL]: FOLD: 0, EPOCH: 14, valid_loss: 0.017681\n",
      "[TRAIN]: FOLD: 0, EPOCH: 15, LR: 0.003450, train_loss: 0.019686\n",
      "[>>VAL]: FOLD: 0, EPOCH: 15, valid_loss: 0.017499\n",
      "[TRAIN]: FOLD: 0, EPOCH: 16, LR: 0.002804, train_loss: 0.019484\n",
      "[>>VAL]: FOLD: 0, EPOCH: 16, valid_loss: 0.017499\n",
      "[TRAIN]: FOLD: 0, EPOCH: 17, LR: 0.002200, train_loss: 0.019216\n",
      "[>>VAL]: FOLD: 0, EPOCH: 17, valid_loss: 0.017300\n",
      "[TRAIN]: FOLD: 0, EPOCH: 18, LR: 0.001651, train_loss: 0.018948\n",
      "[>>VAL]: FOLD: 0, EPOCH: 18, valid_loss: 0.017377\n",
      "[TRAIN]: FOLD: 0, EPOCH: 19, LR: 0.001167, train_loss: 0.018516\n",
      "[>>VAL]: FOLD: 0, EPOCH: 19, valid_loss: 0.017276\n",
      "[TRAIN]: FOLD: 0, EPOCH: 20, LR: 0.000757, train_loss: 0.018129\n",
      "[>>VAL]: FOLD: 0, EPOCH: 20, valid_loss: 0.017348\n",
      "[TRAIN]: FOLD: 0, EPOCH: 21, LR: 0.000430, train_loss: 0.017664\n",
      "[>>VAL]: FOLD: 0, EPOCH: 21, valid_loss: 0.017171\n",
      "[TRAIN]: FOLD: 0, EPOCH: 22, LR: 0.000192, train_loss: 0.017158\n",
      "[>>VAL]: FOLD: 0, EPOCH: 22, valid_loss: 0.017226\n",
      "[TRAIN]: FOLD: 0, EPOCH: 23, LR: 0.000048, train_loss: 0.016819\n",
      "[>>VAL]: FOLD: 0, EPOCH: 23, valid_loss: 0.017248\n",
      "[TRAIN]: FOLD: 0, EPOCH: 24, LR: 0.000000, train_loss: 0.016635\n",
      "[>>VAL]: FOLD: 0, EPOCH: 24, valid_loss: 0.017245\n",
      "[TRAIN]: FOLD: 1, EPOCH: 0, LR: 0.003478, train_loss: 0.476240\n",
      "[>>VAL]: FOLD: 1, EPOCH: 0, valid_loss: 0.024247\n",
      "[TRAIN]: FOLD: 1, EPOCH: 1, LR: 0.009066, train_loss: 0.023801\n",
      "[>>VAL]: FOLD: 1, EPOCH: 1, valid_loss: 0.018682\n",
      "[TRAIN]: FOLD: 1, EPOCH: 2, LR: 0.009987, train_loss: 0.021999\n",
      "[>>VAL]: FOLD: 1, EPOCH: 2, valid_loss: 0.017909\n",
      "[TRAIN]: FOLD: 1, EPOCH: 3, LR: 0.009890, train_loss: 0.020757\n",
      "[>>VAL]: FOLD: 1, EPOCH: 3, valid_loss: 0.017571\n",
      "[TRAIN]: FOLD: 1, EPOCH: 4, LR: 0.009697, train_loss: 0.020240\n",
      "[>>VAL]: FOLD: 1, EPOCH: 4, valid_loss: 0.017542\n",
      "[TRAIN]: FOLD: 1, EPOCH: 5, LR: 0.009412, train_loss: 0.020269\n",
      "[>>VAL]: FOLD: 1, EPOCH: 5, valid_loss: 0.017816\n",
      "[TRAIN]: FOLD: 1, EPOCH: 6, LR: 0.009042, train_loss: 0.020256\n",
      "[>>VAL]: FOLD: 1, EPOCH: 6, valid_loss: 0.017878\n",
      "[TRAIN]: FOLD: 1, EPOCH: 7, LR: 0.008593, train_loss: 0.020274\n",
      "[>>VAL]: FOLD: 1, EPOCH: 7, valid_loss: 0.017493\n",
      "[TRAIN]: FOLD: 1, EPOCH: 8, LR: 0.008075, train_loss: 0.020241\n",
      "[>>VAL]: FOLD: 1, EPOCH: 8, valid_loss: 0.017812\n",
      "[TRAIN]: FOLD: 1, EPOCH: 9, LR: 0.007496, train_loss: 0.020261\n",
      "[>>VAL]: FOLD: 1, EPOCH: 9, valid_loss: 0.017222\n",
      "[TRAIN]: FOLD: 1, EPOCH: 10, LR: 0.006869, train_loss: 0.020228\n",
      "[>>VAL]: FOLD: 1, EPOCH: 10, valid_loss: 0.017672\n",
      "[TRAIN]: FOLD: 1, EPOCH: 11, LR: 0.006205, train_loss: 0.020131\n",
      "[>>VAL]: FOLD: 1, EPOCH: 11, valid_loss: 0.017378\n",
      "[TRAIN]: FOLD: 1, EPOCH: 12, LR: 0.005518, train_loss: 0.020133\n",
      "[>>VAL]: FOLD: 1, EPOCH: 12, valid_loss: 0.017626\n",
      "[TRAIN]: FOLD: 1, EPOCH: 13, LR: 0.004821, train_loss: 0.020002\n",
      "[>>VAL]: FOLD: 1, EPOCH: 13, valid_loss: 0.017411\n",
      "[TRAIN]: FOLD: 1, EPOCH: 14, LR: 0.004127, train_loss: 0.019893\n",
      "[>>VAL]: FOLD: 1, EPOCH: 14, valid_loss: 0.017349\n",
      "[TRAIN]: FOLD: 1, EPOCH: 15, LR: 0.003450, train_loss: 0.019751\n",
      "[>>VAL]: FOLD: 1, EPOCH: 15, valid_loss: 0.017283\n",
      "[TRAIN]: FOLD: 1, EPOCH: 16, LR: 0.002804, train_loss: 0.019514\n",
      "[>>VAL]: FOLD: 1, EPOCH: 16, valid_loss: 0.017265\n",
      "[TRAIN]: FOLD: 1, EPOCH: 17, LR: 0.002200, train_loss: 0.019265\n",
      "[>>VAL]: FOLD: 1, EPOCH: 17, valid_loss: 0.017102\n",
      "[TRAIN]: FOLD: 1, EPOCH: 18, LR: 0.001651, train_loss: 0.018949\n",
      "[>>VAL]: FOLD: 1, EPOCH: 18, valid_loss: 0.017131\n",
      "[TRAIN]: FOLD: 1, EPOCH: 19, LR: 0.001167, train_loss: 0.018672\n",
      "[>>VAL]: FOLD: 1, EPOCH: 19, valid_loss: 0.016968\n",
      "[TRAIN]: FOLD: 1, EPOCH: 20, LR: 0.000757, train_loss: 0.018238\n",
      "[>>VAL]: FOLD: 1, EPOCH: 20, valid_loss: 0.016992\n",
      "[TRAIN]: FOLD: 1, EPOCH: 21, LR: 0.000430, train_loss: 0.017736\n",
      "[>>VAL]: FOLD: 1, EPOCH: 21, valid_loss: 0.016996\n",
      "[TRAIN]: FOLD: 1, EPOCH: 22, LR: 0.000192, train_loss: 0.017295\n",
      "[>>VAL]: FOLD: 1, EPOCH: 22, valid_loss: 0.016988\n",
      "[TRAIN]: FOLD: 1, EPOCH: 23, LR: 0.000048, train_loss: 0.016934\n",
      "[>>VAL]: FOLD: 1, EPOCH: 23, valid_loss: 0.017006\n",
      "[TRAIN]: FOLD: 1, EPOCH: 24, LR: 0.000000, train_loss: 0.016749\n",
      "[>>VAL]: FOLD: 1, EPOCH: 24, valid_loss: 0.017019\n",
      "[TRAIN]: FOLD: 2, EPOCH: 0, LR: 0.003478, train_loss: 0.475337\n",
      "[>>VAL]: FOLD: 2, EPOCH: 0, valid_loss: 0.025356\n",
      "[TRAIN]: FOLD: 2, EPOCH: 1, LR: 0.009066, train_loss: 0.023990\n",
      "[>>VAL]: FOLD: 2, EPOCH: 1, valid_loss: 0.019941\n",
      "[TRAIN]: FOLD: 2, EPOCH: 2, LR: 0.009987, train_loss: 0.021876\n",
      "[>>VAL]: FOLD: 2, EPOCH: 2, valid_loss: 0.019100\n",
      "[TRAIN]: FOLD: 2, EPOCH: 3, LR: 0.009890, train_loss: 0.020774\n",
      "[>>VAL]: FOLD: 2, EPOCH: 3, valid_loss: 0.018615\n",
      "[TRAIN]: FOLD: 2, EPOCH: 4, LR: 0.009697, train_loss: 0.020152\n",
      "[>>VAL]: FOLD: 2, EPOCH: 4, valid_loss: 0.018243\n",
      "[TRAIN]: FOLD: 2, EPOCH: 5, LR: 0.009413, train_loss: 0.020064\n",
      "[>>VAL]: FOLD: 2, EPOCH: 5, valid_loss: 0.018533\n",
      "[TRAIN]: FOLD: 2, EPOCH: 6, LR: 0.009042, train_loss: 0.020109\n",
      "[>>VAL]: FOLD: 2, EPOCH: 6, valid_loss: 0.018667\n",
      "[TRAIN]: FOLD: 2, EPOCH: 7, LR: 0.008593, train_loss: 0.020192\n",
      "[>>VAL]: FOLD: 2, EPOCH: 7, valid_loss: 0.018459\n",
      "[TRAIN]: FOLD: 2, EPOCH: 8, LR: 0.008075, train_loss: 0.020127\n",
      "[>>VAL]: FOLD: 2, EPOCH: 8, valid_loss: 0.018362\n",
      "[TRAIN]: FOLD: 2, EPOCH: 9, LR: 0.007496, train_loss: 0.020150\n",
      "[>>VAL]: FOLD: 2, EPOCH: 9, valid_loss: 0.018543\n",
      "[TRAIN]: FOLD: 2, EPOCH: 10, LR: 0.006869, train_loss: 0.020109\n",
      "[>>VAL]: FOLD: 2, EPOCH: 10, valid_loss: 0.018231\n",
      "[TRAIN]: FOLD: 2, EPOCH: 11, LR: 0.006205, train_loss: 0.020036\n",
      "[>>VAL]: FOLD: 2, EPOCH: 11, valid_loss: 0.018262\n",
      "[TRAIN]: FOLD: 2, EPOCH: 12, LR: 0.005518, train_loss: 0.020033\n",
      "[>>VAL]: FOLD: 2, EPOCH: 12, valid_loss: 0.018357\n",
      "[TRAIN]: FOLD: 2, EPOCH: 13, LR: 0.004821, train_loss: 0.019902\n",
      "[>>VAL]: FOLD: 2, EPOCH: 13, valid_loss: 0.018229\n",
      "[TRAIN]: FOLD: 2, EPOCH: 14, LR: 0.004127, train_loss: 0.019744\n",
      "[>>VAL]: FOLD: 2, EPOCH: 14, valid_loss: 0.018066\n",
      "[TRAIN]: FOLD: 2, EPOCH: 15, LR: 0.003450, train_loss: 0.019665\n",
      "[>>VAL]: FOLD: 2, EPOCH: 15, valid_loss: 0.018187\n",
      "[TRAIN]: FOLD: 2, EPOCH: 16, LR: 0.002804, train_loss: 0.019388\n",
      "[>>VAL]: FOLD: 2, EPOCH: 16, valid_loss: 0.017946\n",
      "[TRAIN]: FOLD: 2, EPOCH: 17, LR: 0.002200, train_loss: 0.019101\n",
      "[>>VAL]: FOLD: 2, EPOCH: 17, valid_loss: 0.017801\n",
      "[TRAIN]: FOLD: 2, EPOCH: 18, LR: 0.001651, train_loss: 0.018819\n",
      "[>>VAL]: FOLD: 2, EPOCH: 18, valid_loss: 0.017895\n",
      "[TRAIN]: FOLD: 2, EPOCH: 19, LR: 0.001167, train_loss: 0.018507\n",
      "[>>VAL]: FOLD: 2, EPOCH: 19, valid_loss: 0.017851\n",
      "[TRAIN]: FOLD: 2, EPOCH: 20, LR: 0.000757, train_loss: 0.018044\n",
      "[>>VAL]: FOLD: 2, EPOCH: 20, valid_loss: 0.017812\n",
      "[TRAIN]: FOLD: 2, EPOCH: 21, LR: 0.000430, train_loss: 0.017566\n",
      "[>>VAL]: FOLD: 2, EPOCH: 21, valid_loss: 0.017834\n",
      "[TRAIN]: FOLD: 2, EPOCH: 22, LR: 0.000192, train_loss: 0.017081\n",
      "[>>VAL]: FOLD: 2, EPOCH: 22, valid_loss: 0.017832\n",
      "[TRAIN]: FOLD: 2, EPOCH: 23, LR: 0.000048, train_loss: 0.016701\n",
      "[>>VAL]: FOLD: 2, EPOCH: 23, valid_loss: 0.017875\n",
      "[TRAIN]: FOLD: 2, EPOCH: 24, LR: 0.000000, train_loss: 0.016532\n",
      "[>>VAL]: FOLD: 2, EPOCH: 24, valid_loss: 0.017898\n",
      "[TRAIN]: FOLD: 3, EPOCH: 0, LR: 0.003478, train_loss: 0.476541\n",
      "[>>VAL]: FOLD: 3, EPOCH: 0, valid_loss: 0.025816\n",
      "[TRAIN]: FOLD: 3, EPOCH: 1, LR: 0.009066, train_loss: 0.023841\n",
      "[>>VAL]: FOLD: 3, EPOCH: 1, valid_loss: 0.019423\n",
      "[TRAIN]: FOLD: 3, EPOCH: 2, LR: 0.009987, train_loss: 0.021834\n",
      "[>>VAL]: FOLD: 3, EPOCH: 2, valid_loss: 0.021435\n",
      "[TRAIN]: FOLD: 3, EPOCH: 3, LR: 0.009890, train_loss: 0.020635\n",
      "[>>VAL]: FOLD: 3, EPOCH: 3, valid_loss: 0.018024\n",
      "[TRAIN]: FOLD: 3, EPOCH: 4, LR: 0.009697, train_loss: 0.020366\n",
      "[>>VAL]: FOLD: 3, EPOCH: 4, valid_loss: 0.017517\n",
      "[TRAIN]: FOLD: 3, EPOCH: 5, LR: 0.009412, train_loss: 0.020243\n",
      "[>>VAL]: FOLD: 3, EPOCH: 5, valid_loss: 0.017609\n",
      "[TRAIN]: FOLD: 3, EPOCH: 6, LR: 0.009042, train_loss: 0.020303\n",
      "[>>VAL]: FOLD: 3, EPOCH: 6, valid_loss: 0.017627\n",
      "[TRAIN]: FOLD: 3, EPOCH: 7, LR: 0.008593, train_loss: 0.020287\n",
      "[>>VAL]: FOLD: 3, EPOCH: 7, valid_loss: 0.017490\n",
      "[TRAIN]: FOLD: 3, EPOCH: 8, LR: 0.008075, train_loss: 0.020326\n",
      "[>>VAL]: FOLD: 3, EPOCH: 8, valid_loss: 0.017590\n",
      "[TRAIN]: FOLD: 3, EPOCH: 9, LR: 0.007496, train_loss: 0.020328\n",
      "[>>VAL]: FOLD: 3, EPOCH: 9, valid_loss: 0.017372\n",
      "[TRAIN]: FOLD: 3, EPOCH: 10, LR: 0.006869, train_loss: 0.020252\n",
      "[>>VAL]: FOLD: 3, EPOCH: 10, valid_loss: 0.017647\n",
      "[TRAIN]: FOLD: 3, EPOCH: 11, LR: 0.006205, train_loss: 0.020239\n",
      "[>>VAL]: FOLD: 3, EPOCH: 11, valid_loss: 0.017589\n",
      "[TRAIN]: FOLD: 3, EPOCH: 12, LR: 0.005518, train_loss: 0.020168\n",
      "[>>VAL]: FOLD: 3, EPOCH: 12, valid_loss: 0.017304\n",
      "[TRAIN]: FOLD: 3, EPOCH: 13, LR: 0.004821, train_loss: 0.020006\n",
      "[>>VAL]: FOLD: 3, EPOCH: 13, valid_loss: 0.017421\n",
      "[TRAIN]: FOLD: 3, EPOCH: 14, LR: 0.004127, train_loss: 0.019903\n",
      "[>>VAL]: FOLD: 3, EPOCH: 14, valid_loss: 0.017641\n",
      "[TRAIN]: FOLD: 3, EPOCH: 15, LR: 0.003450, train_loss: 0.019695\n",
      "[>>VAL]: FOLD: 3, EPOCH: 15, valid_loss: 0.017086\n",
      "[TRAIN]: FOLD: 3, EPOCH: 16, LR: 0.002804, train_loss: 0.019511\n",
      "[>>VAL]: FOLD: 3, EPOCH: 16, valid_loss: 0.017247\n",
      "[TRAIN]: FOLD: 3, EPOCH: 17, LR: 0.002200, train_loss: 0.019258\n",
      "[>>VAL]: FOLD: 3, EPOCH: 17, valid_loss: 0.017210\n",
      "[TRAIN]: FOLD: 3, EPOCH: 18, LR: 0.001651, train_loss: 0.018946\n",
      "[>>VAL]: FOLD: 3, EPOCH: 18, valid_loss: 0.016936\n",
      "[TRAIN]: FOLD: 3, EPOCH: 19, LR: 0.001167, train_loss: 0.018619\n",
      "[>>VAL]: FOLD: 3, EPOCH: 19, valid_loss: 0.016899\n",
      "[TRAIN]: FOLD: 3, EPOCH: 20, LR: 0.000757, train_loss: 0.018172\n",
      "[>>VAL]: FOLD: 3, EPOCH: 20, valid_loss: 0.016865\n",
      "[TRAIN]: FOLD: 3, EPOCH: 21, LR: 0.000430, train_loss: 0.017632\n",
      "[>>VAL]: FOLD: 3, EPOCH: 21, valid_loss: 0.016900\n",
      "[TRAIN]: FOLD: 3, EPOCH: 22, LR: 0.000192, train_loss: 0.017193\n",
      "[>>VAL]: FOLD: 3, EPOCH: 22, valid_loss: 0.016897\n",
      "[TRAIN]: FOLD: 3, EPOCH: 23, LR: 0.000048, train_loss: 0.016780\n",
      "[>>VAL]: FOLD: 3, EPOCH: 23, valid_loss: 0.016876\n",
      "[TRAIN]: FOLD: 3, EPOCH: 24, LR: 0.000000, train_loss: 0.016546\n",
      "[>>VAL]: FOLD: 3, EPOCH: 24, valid_loss: 0.016863\n",
      "[TRAIN]: FOLD: 4, EPOCH: 0, LR: 0.003478, train_loss: 0.473963\n",
      "[>>VAL]: FOLD: 4, EPOCH: 0, valid_loss: 0.024606\n",
      "[TRAIN]: FOLD: 4, EPOCH: 1, LR: 0.009066, train_loss: 0.023759\n",
      "[>>VAL]: FOLD: 4, EPOCH: 1, valid_loss: 0.019240\n",
      "[TRAIN]: FOLD: 4, EPOCH: 2, LR: 0.009987, train_loss: 0.021862\n",
      "[>>VAL]: FOLD: 4, EPOCH: 2, valid_loss: 0.018532\n",
      "[TRAIN]: FOLD: 4, EPOCH: 3, LR: 0.009890, train_loss: 0.020586\n",
      "[>>VAL]: FOLD: 4, EPOCH: 3, valid_loss: 0.018190\n",
      "[TRAIN]: FOLD: 4, EPOCH: 4, LR: 0.009697, train_loss: 0.020239\n",
      "[>>VAL]: FOLD: 4, EPOCH: 4, valid_loss: 0.018288\n",
      "[TRAIN]: FOLD: 4, EPOCH: 5, LR: 0.009413, train_loss: 0.020152\n",
      "[>>VAL]: FOLD: 4, EPOCH: 5, valid_loss: 0.018185\n",
      "[TRAIN]: FOLD: 4, EPOCH: 6, LR: 0.009042, train_loss: 0.020253\n",
      "[>>VAL]: FOLD: 4, EPOCH: 6, valid_loss: 0.018177\n",
      "[TRAIN]: FOLD: 4, EPOCH: 7, LR: 0.008593, train_loss: 0.020193\n",
      "[>>VAL]: FOLD: 4, EPOCH: 7, valid_loss: 0.018312\n",
      "[TRAIN]: FOLD: 4, EPOCH: 8, LR: 0.008075, train_loss: 0.020197\n",
      "[>>VAL]: FOLD: 4, EPOCH: 8, valid_loss: 0.018056\n",
      "[TRAIN]: FOLD: 4, EPOCH: 9, LR: 0.007496, train_loss: 0.020166\n",
      "[>>VAL]: FOLD: 4, EPOCH: 9, valid_loss: 0.018222\n",
      "[TRAIN]: FOLD: 4, EPOCH: 10, LR: 0.006869, train_loss: 0.020121\n",
      "[>>VAL]: FOLD: 4, EPOCH: 10, valid_loss: 0.018266\n",
      "[TRAIN]: FOLD: 4, EPOCH: 11, LR: 0.006205, train_loss: 0.020031\n",
      "[>>VAL]: FOLD: 4, EPOCH: 11, valid_loss: 0.017950\n",
      "[TRAIN]: FOLD: 4, EPOCH: 12, LR: 0.005518, train_loss: 0.019991\n",
      "[>>VAL]: FOLD: 4, EPOCH: 12, valid_loss: 0.017984\n",
      "[TRAIN]: FOLD: 4, EPOCH: 13, LR: 0.004821, train_loss: 0.019901\n",
      "[>>VAL]: FOLD: 4, EPOCH: 13, valid_loss: 0.017845\n",
      "[TRAIN]: FOLD: 4, EPOCH: 14, LR: 0.004127, train_loss: 0.019754\n",
      "[>>VAL]: FOLD: 4, EPOCH: 14, valid_loss: 0.017791\n",
      "[TRAIN]: FOLD: 4, EPOCH: 15, LR: 0.003450, train_loss: 0.019679\n",
      "[>>VAL]: FOLD: 4, EPOCH: 15, valid_loss: 0.017809\n",
      "[TRAIN]: FOLD: 4, EPOCH: 16, LR: 0.002804, train_loss: 0.019477\n",
      "[>>VAL]: FOLD: 4, EPOCH: 16, valid_loss: 0.017705\n",
      "[TRAIN]: FOLD: 4, EPOCH: 17, LR: 0.002200, train_loss: 0.019223\n",
      "[>>VAL]: FOLD: 4, EPOCH: 17, valid_loss: 0.017569\n",
      "[TRAIN]: FOLD: 4, EPOCH: 18, LR: 0.001651, train_loss: 0.018908\n",
      "[>>VAL]: FOLD: 4, EPOCH: 18, valid_loss: 0.017455\n",
      "[TRAIN]: FOLD: 4, EPOCH: 19, LR: 0.001167, train_loss: 0.018518\n",
      "[>>VAL]: FOLD: 4, EPOCH: 19, valid_loss: 0.017495\n",
      "[TRAIN]: FOLD: 4, EPOCH: 20, LR: 0.000757, train_loss: 0.018128\n",
      "[>>VAL]: FOLD: 4, EPOCH: 20, valid_loss: 0.017446\n",
      "[TRAIN]: FOLD: 4, EPOCH: 21, LR: 0.000430, train_loss: 0.017613\n",
      "[>>VAL]: FOLD: 4, EPOCH: 21, valid_loss: 0.017475\n",
      "[TRAIN]: FOLD: 4, EPOCH: 22, LR: 0.000192, train_loss: 0.017115\n",
      "[>>VAL]: FOLD: 4, EPOCH: 22, valid_loss: 0.017499\n",
      "[TRAIN]: FOLD: 4, EPOCH: 23, LR: 0.000048, train_loss: 0.016741\n",
      "[>>VAL]: FOLD: 4, EPOCH: 23, valid_loss: 0.017512\n",
      "[TRAIN]: FOLD: 4, EPOCH: 24, LR: 0.000000, train_loss: 0.016534\n",
      "[>>VAL]: FOLD: 4, EPOCH: 24, valid_loss: 0.017477\n",
      "[TRAIN]: FOLD: 5, EPOCH: 0, LR: 0.003478, train_loss: 0.475800\n",
      "[>>VAL]: FOLD: 5, EPOCH: 0, valid_loss: 0.024419\n",
      "[TRAIN]: FOLD: 5, EPOCH: 1, LR: 0.009066, train_loss: 0.023833\n",
      "[>>VAL]: FOLD: 5, EPOCH: 1, valid_loss: 0.019675\n",
      "[TRAIN]: FOLD: 5, EPOCH: 2, LR: 0.009987, train_loss: 0.021802\n",
      "[>>VAL]: FOLD: 5, EPOCH: 2, valid_loss: 0.018561\n",
      "[TRAIN]: FOLD: 5, EPOCH: 3, LR: 0.009890, train_loss: 0.020671\n",
      "[>>VAL]: FOLD: 5, EPOCH: 3, valid_loss: 0.018908\n",
      "[TRAIN]: FOLD: 5, EPOCH: 4, LR: 0.009697, train_loss: 0.020234\n",
      "[>>VAL]: FOLD: 5, EPOCH: 4, valid_loss: 0.018442\n",
      "[TRAIN]: FOLD: 5, EPOCH: 5, LR: 0.009412, train_loss: 0.020178\n",
      "[>>VAL]: FOLD: 5, EPOCH: 5, valid_loss: 0.018218\n",
      "[TRAIN]: FOLD: 5, EPOCH: 6, LR: 0.009042, train_loss: 0.020150\n",
      "[>>VAL]: FOLD: 5, EPOCH: 6, valid_loss: 0.018379\n",
      "[TRAIN]: FOLD: 5, EPOCH: 7, LR: 0.008593, train_loss: 0.020147\n",
      "[>>VAL]: FOLD: 5, EPOCH: 7, valid_loss: 0.018411\n",
      "[TRAIN]: FOLD: 5, EPOCH: 8, LR: 0.008075, train_loss: 0.020134\n",
      "[>>VAL]: FOLD: 5, EPOCH: 8, valid_loss: 0.018238\n",
      "[TRAIN]: FOLD: 5, EPOCH: 9, LR: 0.007496, train_loss: 0.020110\n",
      "[>>VAL]: FOLD: 5, EPOCH: 9, valid_loss: 0.018164\n",
      "[TRAIN]: FOLD: 5, EPOCH: 10, LR: 0.006869, train_loss: 0.020139\n",
      "[>>VAL]: FOLD: 5, EPOCH: 10, valid_loss: 0.018216\n",
      "[TRAIN]: FOLD: 5, EPOCH: 11, LR: 0.006205, train_loss: 0.020097\n",
      "[>>VAL]: FOLD: 5, EPOCH: 11, valid_loss: 0.018842\n",
      "[TRAIN]: FOLD: 5, EPOCH: 12, LR: 0.005518, train_loss: 0.020022\n",
      "[>>VAL]: FOLD: 5, EPOCH: 12, valid_loss: 0.018391\n",
      "[TRAIN]: FOLD: 5, EPOCH: 13, LR: 0.004821, train_loss: 0.019926\n",
      "[>>VAL]: FOLD: 5, EPOCH: 13, valid_loss: 0.018063\n",
      "[TRAIN]: FOLD: 5, EPOCH: 14, LR: 0.004127, train_loss: 0.019778\n",
      "[>>VAL]: FOLD: 5, EPOCH: 14, valid_loss: 0.018087\n",
      "[TRAIN]: FOLD: 5, EPOCH: 15, LR: 0.003450, train_loss: 0.019674\n",
      "[>>VAL]: FOLD: 5, EPOCH: 15, valid_loss: 0.017995\n",
      "[TRAIN]: FOLD: 5, EPOCH: 16, LR: 0.002804, train_loss: 0.019399\n",
      "[>>VAL]: FOLD: 5, EPOCH: 16, valid_loss: 0.017936\n",
      "[TRAIN]: FOLD: 5, EPOCH: 17, LR: 0.002200, train_loss: 0.019171\n",
      "[>>VAL]: FOLD: 5, EPOCH: 17, valid_loss: 0.017830\n",
      "[TRAIN]: FOLD: 5, EPOCH: 18, LR: 0.001651, train_loss: 0.018903\n",
      "[>>VAL]: FOLD: 5, EPOCH: 18, valid_loss: 0.017846\n",
      "[TRAIN]: FOLD: 5, EPOCH: 19, LR: 0.001167, train_loss: 0.018567\n",
      "[>>VAL]: FOLD: 5, EPOCH: 19, valid_loss: 0.017733\n",
      "[TRAIN]: FOLD: 5, EPOCH: 20, LR: 0.000757, train_loss: 0.018132\n",
      "[>>VAL]: FOLD: 5, EPOCH: 20, valid_loss: 0.017946\n",
      "[TRAIN]: FOLD: 5, EPOCH: 21, LR: 0.000430, train_loss: 0.017636\n",
      "[>>VAL]: FOLD: 5, EPOCH: 21, valid_loss: 0.017801\n",
      "[TRAIN]: FOLD: 5, EPOCH: 22, LR: 0.000192, train_loss: 0.017232\n",
      "[>>VAL]: FOLD: 5, EPOCH: 22, valid_loss: 0.017897\n",
      "[TRAIN]: FOLD: 5, EPOCH: 23, LR: 0.000048, train_loss: 0.016865\n",
      "[>>VAL]: FOLD: 5, EPOCH: 23, valid_loss: 0.017848\n",
      "[TRAIN]: FOLD: 5, EPOCH: 24, LR: 0.000000, train_loss: 0.016685\n",
      "[>>VAL]: FOLD: 5, EPOCH: 24, valid_loss: 0.017859\n",
      "[TRAIN]: FOLD: 6, EPOCH: 0, LR: 0.003478, train_loss: 0.474472\n",
      "[>>VAL]: FOLD: 6, EPOCH: 0, valid_loss: 0.024799\n",
      "[TRAIN]: FOLD: 6, EPOCH: 1, LR: 0.009066, train_loss: 0.024120\n",
      "[>>VAL]: FOLD: 6, EPOCH: 1, valid_loss: 0.018947\n",
      "[TRAIN]: FOLD: 6, EPOCH: 2, LR: 0.009987, train_loss: 0.022838\n",
      "[>>VAL]: FOLD: 6, EPOCH: 2, valid_loss: 0.017769\n",
      "[TRAIN]: FOLD: 6, EPOCH: 3, LR: 0.009890, train_loss: 0.020914\n",
      "[>>VAL]: FOLD: 6, EPOCH: 3, valid_loss: 0.017440\n",
      "[TRAIN]: FOLD: 6, EPOCH: 4, LR: 0.009697, train_loss: 0.020400\n",
      "[>>VAL]: FOLD: 6, EPOCH: 4, valid_loss: 0.017565\n",
      "[TRAIN]: FOLD: 6, EPOCH: 5, LR: 0.009413, train_loss: 0.020237\n",
      "[>>VAL]: FOLD: 6, EPOCH: 5, valid_loss: 0.017005\n",
      "[TRAIN]: FOLD: 6, EPOCH: 6, LR: 0.009042, train_loss: 0.020256\n",
      "[>>VAL]: FOLD: 6, EPOCH: 6, valid_loss: 0.017393\n",
      "[TRAIN]: FOLD: 6, EPOCH: 7, LR: 0.008593, train_loss: 0.020276\n",
      "[>>VAL]: FOLD: 6, EPOCH: 7, valid_loss: 0.017587\n",
      "[TRAIN]: FOLD: 6, EPOCH: 8, LR: 0.008075, train_loss: 0.020242\n",
      "[>>VAL]: FOLD: 6, EPOCH: 8, valid_loss: 0.017221\n",
      "[TRAIN]: FOLD: 6, EPOCH: 9, LR: 0.007496, train_loss: 0.020247\n",
      "[>>VAL]: FOLD: 6, EPOCH: 9, valid_loss: 0.017196\n",
      "[TRAIN]: FOLD: 6, EPOCH: 10, LR: 0.006869, train_loss: 0.020241\n",
      "[>>VAL]: FOLD: 6, EPOCH: 10, valid_loss: 0.017509\n",
      "[TRAIN]: FOLD: 6, EPOCH: 11, LR: 0.006205, train_loss: 0.020241\n",
      "[>>VAL]: FOLD: 6, EPOCH: 11, valid_loss: 0.017046\n",
      "[TRAIN]: FOLD: 6, EPOCH: 12, LR: 0.005518, train_loss: 0.020098\n",
      "[>>VAL]: FOLD: 6, EPOCH: 12, valid_loss: 0.017072\n",
      "[TRAIN]: FOLD: 6, EPOCH: 13, LR: 0.004821, train_loss: 0.020005\n",
      "[>>VAL]: FOLD: 6, EPOCH: 13, valid_loss: 0.016978\n",
      "[TRAIN]: FOLD: 6, EPOCH: 14, LR: 0.004127, train_loss: 0.019881\n",
      "[>>VAL]: FOLD: 6, EPOCH: 14, valid_loss: 0.017111\n",
      "[TRAIN]: FOLD: 6, EPOCH: 15, LR: 0.003450, train_loss: 0.019700\n",
      "[>>VAL]: FOLD: 6, EPOCH: 15, valid_loss: 0.016743\n",
      "[TRAIN]: FOLD: 6, EPOCH: 16, LR: 0.002804, train_loss: 0.019449\n",
      "[>>VAL]: FOLD: 6, EPOCH: 16, valid_loss: 0.017105\n",
      "[TRAIN]: FOLD: 6, EPOCH: 17, LR: 0.002200, train_loss: 0.019324\n",
      "[>>VAL]: FOLD: 6, EPOCH: 17, valid_loss: 0.016953\n",
      "[TRAIN]: FOLD: 6, EPOCH: 18, LR: 0.001651, train_loss: 0.018983\n",
      "[>>VAL]: FOLD: 6, EPOCH: 18, valid_loss: 0.016682\n",
      "[TRAIN]: FOLD: 6, EPOCH: 19, LR: 0.001167, train_loss: 0.018591\n",
      "[>>VAL]: FOLD: 6, EPOCH: 19, valid_loss: 0.016796\n",
      "[TRAIN]: FOLD: 6, EPOCH: 20, LR: 0.000757, train_loss: 0.018116\n",
      "[>>VAL]: FOLD: 6, EPOCH: 20, valid_loss: 0.016658\n",
      "[TRAIN]: FOLD: 6, EPOCH: 21, LR: 0.000430, train_loss: 0.017663\n",
      "[>>VAL]: FOLD: 6, EPOCH: 21, valid_loss: 0.016708\n",
      "[TRAIN]: FOLD: 6, EPOCH: 22, LR: 0.000192, train_loss: 0.017136\n",
      "[>>VAL]: FOLD: 6, EPOCH: 22, valid_loss: 0.016730\n",
      "[TRAIN]: FOLD: 6, EPOCH: 23, LR: 0.000048, train_loss: 0.016715\n",
      "[>>VAL]: FOLD: 6, EPOCH: 23, valid_loss: 0.016773\n",
      "[TRAIN]: FOLD: 6, EPOCH: 24, LR: 0.000000, train_loss: 0.016500\n",
      "[>>VAL]: FOLD: 6, EPOCH: 24, valid_loss: 0.016776\n",
      "\n",
      ">> SEED: 6\n",
      "\n",
      "[TRAIN]: FOLD: 0, EPOCH: 0, LR: 0.003478, train_loss: 0.473544\n",
      "[>>VAL]: FOLD: 0, EPOCH: 0, valid_loss: 0.025151\n",
      "[TRAIN]: FOLD: 0, EPOCH: 1, LR: 0.009066, train_loss: 0.023745\n",
      "[>>VAL]: FOLD: 0, EPOCH: 1, valid_loss: 0.019882\n",
      "[TRAIN]: FOLD: 0, EPOCH: 2, LR: 0.009987, train_loss: 0.021753\n",
      "[>>VAL]: FOLD: 0, EPOCH: 2, valid_loss: 0.019397\n",
      "[TRAIN]: FOLD: 0, EPOCH: 3, LR: 0.009890, train_loss: 0.020601\n",
      "[>>VAL]: FOLD: 0, EPOCH: 3, valid_loss: 0.017874\n",
      "[TRAIN]: FOLD: 0, EPOCH: 4, LR: 0.009697, train_loss: 0.020222\n",
      "[>>VAL]: FOLD: 0, EPOCH: 4, valid_loss: 0.017924\n",
      "[TRAIN]: FOLD: 0, EPOCH: 5, LR: 0.009413, train_loss: 0.020178\n",
      "[>>VAL]: FOLD: 0, EPOCH: 5, valid_loss: 0.017842\n",
      "[TRAIN]: FOLD: 0, EPOCH: 6, LR: 0.009042, train_loss: 0.020234\n",
      "[>>VAL]: FOLD: 0, EPOCH: 6, valid_loss: 0.018084\n",
      "[TRAIN]: FOLD: 0, EPOCH: 7, LR: 0.008593, train_loss: 0.020253\n",
      "[>>VAL]: FOLD: 0, EPOCH: 7, valid_loss: 0.017794\n",
      "[TRAIN]: FOLD: 0, EPOCH: 8, LR: 0.008075, train_loss: 0.020180\n",
      "[>>VAL]: FOLD: 0, EPOCH: 8, valid_loss: 0.018006\n",
      "[TRAIN]: FOLD: 0, EPOCH: 9, LR: 0.007496, train_loss: 0.020202\n",
      "[>>VAL]: FOLD: 0, EPOCH: 9, valid_loss: 0.017870\n",
      "[TRAIN]: FOLD: 0, EPOCH: 10, LR: 0.006869, train_loss: 0.020218\n",
      "[>>VAL]: FOLD: 0, EPOCH: 10, valid_loss: 0.017968\n",
      "[TRAIN]: FOLD: 0, EPOCH: 11, LR: 0.006205, train_loss: 0.020190\n",
      "[>>VAL]: FOLD: 0, EPOCH: 11, valid_loss: 0.017880\n",
      "[TRAIN]: FOLD: 0, EPOCH: 12, LR: 0.005518, train_loss: 0.020044\n",
      "[>>VAL]: FOLD: 0, EPOCH: 12, valid_loss: 0.017899\n",
      "[TRAIN]: FOLD: 0, EPOCH: 13, LR: 0.004821, train_loss: 0.019916\n",
      "[>>VAL]: FOLD: 0, EPOCH: 13, valid_loss: 0.017566\n",
      "[TRAIN]: FOLD: 0, EPOCH: 14, LR: 0.004127, train_loss: 0.019824\n",
      "[>>VAL]: FOLD: 0, EPOCH: 14, valid_loss: 0.017726\n",
      "[TRAIN]: FOLD: 0, EPOCH: 15, LR: 0.003450, train_loss: 0.019634\n",
      "[>>VAL]: FOLD: 0, EPOCH: 15, valid_loss: 0.017549\n",
      "[TRAIN]: FOLD: 0, EPOCH: 16, LR: 0.002804, train_loss: 0.019478\n",
      "[>>VAL]: FOLD: 0, EPOCH: 16, valid_loss: 0.017466\n",
      "[TRAIN]: FOLD: 0, EPOCH: 17, LR: 0.002200, train_loss: 0.019217\n",
      "[>>VAL]: FOLD: 0, EPOCH: 17, valid_loss: 0.017512\n",
      "[TRAIN]: FOLD: 0, EPOCH: 18, LR: 0.001651, train_loss: 0.018931\n",
      "[>>VAL]: FOLD: 0, EPOCH: 18, valid_loss: 0.017371\n",
      "[TRAIN]: FOLD: 0, EPOCH: 19, LR: 0.001167, train_loss: 0.018529\n",
      "[>>VAL]: FOLD: 0, EPOCH: 19, valid_loss: 0.017335\n",
      "[TRAIN]: FOLD: 0, EPOCH: 20, LR: 0.000757, train_loss: 0.018119\n",
      "[>>VAL]: FOLD: 0, EPOCH: 20, valid_loss: 0.017378\n",
      "[TRAIN]: FOLD: 0, EPOCH: 21, LR: 0.000430, train_loss: 0.017661\n",
      "[>>VAL]: FOLD: 0, EPOCH: 21, valid_loss: 0.017342\n",
      "[TRAIN]: FOLD: 0, EPOCH: 22, LR: 0.000192, train_loss: 0.017140\n",
      "[>>VAL]: FOLD: 0, EPOCH: 22, valid_loss: 0.017316\n",
      "[TRAIN]: FOLD: 0, EPOCH: 23, LR: 0.000048, train_loss: 0.016755\n",
      "[>>VAL]: FOLD: 0, EPOCH: 23, valid_loss: 0.017350\n",
      "[TRAIN]: FOLD: 0, EPOCH: 24, LR: 0.000000, train_loss: 0.016591\n",
      "[>>VAL]: FOLD: 0, EPOCH: 24, valid_loss: 0.017397\n",
      "[TRAIN]: FOLD: 1, EPOCH: 0, LR: 0.003478, train_loss: 0.474211\n",
      "[>>VAL]: FOLD: 1, EPOCH: 0, valid_loss: 0.027618\n",
      "[TRAIN]: FOLD: 1, EPOCH: 1, LR: 0.009066, train_loss: 0.024037\n",
      "[>>VAL]: FOLD: 1, EPOCH: 1, valid_loss: 0.018858\n",
      "[TRAIN]: FOLD: 1, EPOCH: 2, LR: 0.009987, train_loss: 0.022173\n",
      "[>>VAL]: FOLD: 1, EPOCH: 2, valid_loss: 0.018011\n",
      "[TRAIN]: FOLD: 1, EPOCH: 3, LR: 0.009890, train_loss: 0.020787\n",
      "[>>VAL]: FOLD: 1, EPOCH: 3, valid_loss: 0.017849\n",
      "[TRAIN]: FOLD: 1, EPOCH: 4, LR: 0.009697, train_loss: 0.020555\n",
      "[>>VAL]: FOLD: 1, EPOCH: 4, valid_loss: 0.017979\n",
      "[TRAIN]: FOLD: 1, EPOCH: 5, LR: 0.009412, train_loss: 0.020279\n",
      "[>>VAL]: FOLD: 1, EPOCH: 5, valid_loss: 0.017688\n",
      "[TRAIN]: FOLD: 1, EPOCH: 6, LR: 0.009042, train_loss: 0.020348\n",
      "[>>VAL]: FOLD: 1, EPOCH: 6, valid_loss: 0.017694\n",
      "[TRAIN]: FOLD: 1, EPOCH: 7, LR: 0.008593, train_loss: 0.020288\n",
      "[>>VAL]: FOLD: 1, EPOCH: 7, valid_loss: 0.017780\n",
      "[TRAIN]: FOLD: 1, EPOCH: 8, LR: 0.008075, train_loss: 0.020275\n",
      "[>>VAL]: FOLD: 1, EPOCH: 8, valid_loss: 0.017564\n",
      "[TRAIN]: FOLD: 1, EPOCH: 9, LR: 0.007496, train_loss: 0.020271\n",
      "[>>VAL]: FOLD: 1, EPOCH: 9, valid_loss: 0.017427\n",
      "[TRAIN]: FOLD: 1, EPOCH: 10, LR: 0.006869, train_loss: 0.020295\n",
      "[>>VAL]: FOLD: 1, EPOCH: 10, valid_loss: 0.017670\n",
      "[TRAIN]: FOLD: 1, EPOCH: 11, LR: 0.006205, train_loss: 0.020186\n",
      "[>>VAL]: FOLD: 1, EPOCH: 11, valid_loss: 0.017508\n",
      "[TRAIN]: FOLD: 1, EPOCH: 12, LR: 0.005518, train_loss: 0.020095\n",
      "[>>VAL]: FOLD: 1, EPOCH: 12, valid_loss: 0.017591\n",
      "[TRAIN]: FOLD: 1, EPOCH: 13, LR: 0.004821, train_loss: 0.020062\n",
      "[>>VAL]: FOLD: 1, EPOCH: 13, valid_loss: 0.017540\n",
      "[TRAIN]: FOLD: 1, EPOCH: 14, LR: 0.004127, train_loss: 0.019934\n",
      "[>>VAL]: FOLD: 1, EPOCH: 14, valid_loss: 0.017490\n",
      "[TRAIN]: FOLD: 1, EPOCH: 15, LR: 0.003450, train_loss: 0.019723\n",
      "[>>VAL]: FOLD: 1, EPOCH: 15, valid_loss: 0.017268\n",
      "[TRAIN]: FOLD: 1, EPOCH: 16, LR: 0.002804, train_loss: 0.019484\n",
      "[>>VAL]: FOLD: 1, EPOCH: 16, valid_loss: 0.017311\n",
      "[TRAIN]: FOLD: 1, EPOCH: 17, LR: 0.002200, train_loss: 0.019261\n",
      "[>>VAL]: FOLD: 1, EPOCH: 17, valid_loss: 0.017130\n",
      "[TRAIN]: FOLD: 1, EPOCH: 18, LR: 0.001651, train_loss: 0.018959\n",
      "[>>VAL]: FOLD: 1, EPOCH: 18, valid_loss: 0.017009\n",
      "[TRAIN]: FOLD: 1, EPOCH: 19, LR: 0.001167, train_loss: 0.018670\n",
      "[>>VAL]: FOLD: 1, EPOCH: 19, valid_loss: 0.017153\n",
      "[TRAIN]: FOLD: 1, EPOCH: 20, LR: 0.000757, train_loss: 0.018198\n",
      "[>>VAL]: FOLD: 1, EPOCH: 20, valid_loss: 0.017078\n",
      "[TRAIN]: FOLD: 1, EPOCH: 21, LR: 0.000430, train_loss: 0.017688\n",
      "[>>VAL]: FOLD: 1, EPOCH: 21, valid_loss: 0.017007\n",
      "[TRAIN]: FOLD: 1, EPOCH: 22, LR: 0.000192, train_loss: 0.017206\n",
      "[>>VAL]: FOLD: 1, EPOCH: 22, valid_loss: 0.017051\n",
      "[TRAIN]: FOLD: 1, EPOCH: 23, LR: 0.000048, train_loss: 0.016828\n",
      "[>>VAL]: FOLD: 1, EPOCH: 23, valid_loss: 0.017031\n",
      "[TRAIN]: FOLD: 1, EPOCH: 24, LR: 0.000000, train_loss: 0.016616\n",
      "[>>VAL]: FOLD: 1, EPOCH: 24, valid_loss: 0.017040\n",
      "[TRAIN]: FOLD: 2, EPOCH: 0, LR: 0.003478, train_loss: 0.474037\n",
      "[>>VAL]: FOLD: 2, EPOCH: 0, valid_loss: 0.025935\n",
      "[TRAIN]: FOLD: 2, EPOCH: 1, LR: 0.009066, train_loss: 0.023758\n",
      "[>>VAL]: FOLD: 2, EPOCH: 1, valid_loss: 0.019659\n",
      "[TRAIN]: FOLD: 2, EPOCH: 2, LR: 0.009987, train_loss: 0.021709\n",
      "[>>VAL]: FOLD: 2, EPOCH: 2, valid_loss: 0.021627\n",
      "[TRAIN]: FOLD: 2, EPOCH: 3, LR: 0.009890, train_loss: 0.020789\n",
      "[>>VAL]: FOLD: 2, EPOCH: 3, valid_loss: 0.018388\n",
      "[TRAIN]: FOLD: 2, EPOCH: 4, LR: 0.009697, train_loss: 0.020118\n",
      "[>>VAL]: FOLD: 2, EPOCH: 4, valid_loss: 0.018409\n",
      "[TRAIN]: FOLD: 2, EPOCH: 5, LR: 0.009413, train_loss: 0.020133\n",
      "[>>VAL]: FOLD: 2, EPOCH: 5, valid_loss: 0.018549\n",
      "[TRAIN]: FOLD: 2, EPOCH: 6, LR: 0.009042, train_loss: 0.020108\n",
      "[>>VAL]: FOLD: 2, EPOCH: 6, valid_loss: 0.018297\n",
      "[TRAIN]: FOLD: 2, EPOCH: 7, LR: 0.008593, train_loss: 0.020094\n",
      "[>>VAL]: FOLD: 2, EPOCH: 7, valid_loss: 0.018482\n",
      "[TRAIN]: FOLD: 2, EPOCH: 8, LR: 0.008075, train_loss: 0.020172\n",
      "[>>VAL]: FOLD: 2, EPOCH: 8, valid_loss: 0.018563\n",
      "[TRAIN]: FOLD: 2, EPOCH: 9, LR: 0.007496, train_loss: 0.020107\n",
      "[>>VAL]: FOLD: 2, EPOCH: 9, valid_loss: 0.018439\n",
      "[TRAIN]: FOLD: 2, EPOCH: 10, LR: 0.006869, train_loss: 0.020116\n",
      "[>>VAL]: FOLD: 2, EPOCH: 10, valid_loss: 0.018343\n",
      "[TRAIN]: FOLD: 2, EPOCH: 11, LR: 0.006205, train_loss: 0.020089\n",
      "[>>VAL]: FOLD: 2, EPOCH: 11, valid_loss: 0.018327\n",
      "[TRAIN]: FOLD: 2, EPOCH: 12, LR: 0.005518, train_loss: 0.020003\n",
      "[>>VAL]: FOLD: 2, EPOCH: 12, valid_loss: 0.018321\n",
      "[TRAIN]: FOLD: 2, EPOCH: 13, LR: 0.004821, train_loss: 0.019861\n",
      "[>>VAL]: FOLD: 2, EPOCH: 13, valid_loss: 0.018103\n",
      "[TRAIN]: FOLD: 2, EPOCH: 14, LR: 0.004127, train_loss: 0.019704\n",
      "[>>VAL]: FOLD: 2, EPOCH: 14, valid_loss: 0.018115\n",
      "[TRAIN]: FOLD: 2, EPOCH: 15, LR: 0.003450, train_loss: 0.019577\n",
      "[>>VAL]: FOLD: 2, EPOCH: 15, valid_loss: 0.018022\n",
      "[TRAIN]: FOLD: 2, EPOCH: 16, LR: 0.002804, train_loss: 0.019353\n",
      "[>>VAL]: FOLD: 2, EPOCH: 16, valid_loss: 0.017927\n",
      "[TRAIN]: FOLD: 2, EPOCH: 17, LR: 0.002200, train_loss: 0.019153\n",
      "[>>VAL]: FOLD: 2, EPOCH: 17, valid_loss: 0.017766\n",
      "[TRAIN]: FOLD: 2, EPOCH: 18, LR: 0.001651, train_loss: 0.018851\n",
      "[>>VAL]: FOLD: 2, EPOCH: 18, valid_loss: 0.017960\n",
      "[TRAIN]: FOLD: 2, EPOCH: 19, LR: 0.001167, train_loss: 0.018467\n",
      "[>>VAL]: FOLD: 2, EPOCH: 19, valid_loss: 0.017867\n",
      "[TRAIN]: FOLD: 2, EPOCH: 20, LR: 0.000757, train_loss: 0.018031\n",
      "[>>VAL]: FOLD: 2, EPOCH: 20, valid_loss: 0.017841\n",
      "[TRAIN]: FOLD: 2, EPOCH: 21, LR: 0.000430, train_loss: 0.017588\n",
      "[>>VAL]: FOLD: 2, EPOCH: 21, valid_loss: 0.017927\n",
      "[TRAIN]: FOLD: 2, EPOCH: 22, LR: 0.000192, train_loss: 0.017104\n",
      "[>>VAL]: FOLD: 2, EPOCH: 22, valid_loss: 0.017851\n",
      "[TRAIN]: FOLD: 2, EPOCH: 23, LR: 0.000048, train_loss: 0.016739\n",
      "[>>VAL]: FOLD: 2, EPOCH: 23, valid_loss: 0.017889\n",
      "[TRAIN]: FOLD: 2, EPOCH: 24, LR: 0.000000, train_loss: 0.016553\n",
      "[>>VAL]: FOLD: 2, EPOCH: 24, valid_loss: 0.017870\n",
      "[TRAIN]: FOLD: 3, EPOCH: 0, LR: 0.003478, train_loss: 0.474171\n",
      "[>>VAL]: FOLD: 3, EPOCH: 0, valid_loss: 0.025033\n",
      "[TRAIN]: FOLD: 3, EPOCH: 1, LR: 0.009066, train_loss: 0.024167\n",
      "[>>VAL]: FOLD: 3, EPOCH: 1, valid_loss: 0.019165\n",
      "[TRAIN]: FOLD: 3, EPOCH: 2, LR: 0.009987, train_loss: 0.021723\n",
      "[>>VAL]: FOLD: 3, EPOCH: 2, valid_loss: 0.018719\n",
      "[TRAIN]: FOLD: 3, EPOCH: 3, LR: 0.009890, train_loss: 0.020650\n",
      "[>>VAL]: FOLD: 3, EPOCH: 3, valid_loss: 0.017701\n",
      "[TRAIN]: FOLD: 3, EPOCH: 4, LR: 0.009697, train_loss: 0.020249\n",
      "[>>VAL]: FOLD: 3, EPOCH: 4, valid_loss: 0.017750\n",
      "[TRAIN]: FOLD: 3, EPOCH: 5, LR: 0.009412, train_loss: 0.020265\n",
      "[>>VAL]: FOLD: 3, EPOCH: 5, valid_loss: 0.017916\n",
      "[TRAIN]: FOLD: 3, EPOCH: 6, LR: 0.009042, train_loss: 0.020281\n",
      "[>>VAL]: FOLD: 3, EPOCH: 6, valid_loss: 0.017821\n",
      "[TRAIN]: FOLD: 3, EPOCH: 7, LR: 0.008593, train_loss: 0.020256\n",
      "[>>VAL]: FOLD: 3, EPOCH: 7, valid_loss: 0.017771\n",
      "[TRAIN]: FOLD: 3, EPOCH: 8, LR: 0.008075, train_loss: 0.020315\n",
      "[>>VAL]: FOLD: 3, EPOCH: 8, valid_loss: 0.017437\n",
      "[TRAIN]: FOLD: 3, EPOCH: 9, LR: 0.007496, train_loss: 0.020224\n",
      "[>>VAL]: FOLD: 3, EPOCH: 9, valid_loss: 0.017405\n",
      "[TRAIN]: FOLD: 3, EPOCH: 10, LR: 0.006869, train_loss: 0.020247\n",
      "[>>VAL]: FOLD: 3, EPOCH: 10, valid_loss: 0.017901\n",
      "[TRAIN]: FOLD: 3, EPOCH: 11, LR: 0.006205, train_loss: 0.020191\n",
      "[>>VAL]: FOLD: 3, EPOCH: 11, valid_loss: 0.017398\n",
      "[TRAIN]: FOLD: 3, EPOCH: 12, LR: 0.005518, train_loss: 0.020128\n",
      "[>>VAL]: FOLD: 3, EPOCH: 12, valid_loss: 0.017352\n",
      "[TRAIN]: FOLD: 3, EPOCH: 13, LR: 0.004821, train_loss: 0.020064\n",
      "[>>VAL]: FOLD: 3, EPOCH: 13, valid_loss: 0.017420\n",
      "[TRAIN]: FOLD: 3, EPOCH: 14, LR: 0.004127, train_loss: 0.019951\n",
      "[>>VAL]: FOLD: 3, EPOCH: 14, valid_loss: 0.017454\n",
      "[TRAIN]: FOLD: 3, EPOCH: 15, LR: 0.003450, train_loss: 0.019783\n",
      "[>>VAL]: FOLD: 3, EPOCH: 15, valid_loss: 0.017287\n",
      "[TRAIN]: FOLD: 3, EPOCH: 16, LR: 0.002804, train_loss: 0.019519\n",
      "[>>VAL]: FOLD: 3, EPOCH: 16, valid_loss: 0.017181\n",
      "[TRAIN]: FOLD: 3, EPOCH: 17, LR: 0.002200, train_loss: 0.019303\n",
      "[>>VAL]: FOLD: 3, EPOCH: 17, valid_loss: 0.017062\n",
      "[TRAIN]: FOLD: 3, EPOCH: 18, LR: 0.001651, train_loss: 0.018965\n",
      "[>>VAL]: FOLD: 3, EPOCH: 18, valid_loss: 0.016925\n",
      "[TRAIN]: FOLD: 3, EPOCH: 19, LR: 0.001167, train_loss: 0.018629\n",
      "[>>VAL]: FOLD: 3, EPOCH: 19, valid_loss: 0.016900\n",
      "[TRAIN]: FOLD: 3, EPOCH: 20, LR: 0.000757, train_loss: 0.018211\n",
      "[>>VAL]: FOLD: 3, EPOCH: 20, valid_loss: 0.016844\n",
      "[TRAIN]: FOLD: 3, EPOCH: 21, LR: 0.000430, train_loss: 0.017754\n",
      "[>>VAL]: FOLD: 3, EPOCH: 21, valid_loss: 0.016830\n",
      "[TRAIN]: FOLD: 3, EPOCH: 22, LR: 0.000192, train_loss: 0.017241\n",
      "[>>VAL]: FOLD: 3, EPOCH: 22, valid_loss: 0.016892\n",
      "[TRAIN]: FOLD: 3, EPOCH: 23, LR: 0.000048, train_loss: 0.016862\n",
      "[>>VAL]: FOLD: 3, EPOCH: 23, valid_loss: 0.016843\n",
      "[TRAIN]: FOLD: 3, EPOCH: 24, LR: 0.000000, train_loss: 0.016721\n",
      "[>>VAL]: FOLD: 3, EPOCH: 24, valid_loss: 0.016871\n",
      "[TRAIN]: FOLD: 4, EPOCH: 0, LR: 0.003478, train_loss: 0.473471\n",
      "[>>VAL]: FOLD: 4, EPOCH: 0, valid_loss: 0.025218\n",
      "[TRAIN]: FOLD: 4, EPOCH: 1, LR: 0.009066, train_loss: 0.023871\n",
      "[>>VAL]: FOLD: 4, EPOCH: 1, valid_loss: 0.019099\n",
      "[TRAIN]: FOLD: 4, EPOCH: 2, LR: 0.009987, train_loss: 0.021789\n",
      "[>>VAL]: FOLD: 4, EPOCH: 2, valid_loss: 0.019270\n",
      "[TRAIN]: FOLD: 4, EPOCH: 3, LR: 0.009890, train_loss: 0.020552\n",
      "[>>VAL]: FOLD: 4, EPOCH: 3, valid_loss: 0.018087\n",
      "[TRAIN]: FOLD: 4, EPOCH: 4, LR: 0.009697, train_loss: 0.020166\n",
      "[>>VAL]: FOLD: 4, EPOCH: 4, valid_loss: 0.018044\n",
      "[TRAIN]: FOLD: 4, EPOCH: 5, LR: 0.009413, train_loss: 0.020180\n",
      "[>>VAL]: FOLD: 4, EPOCH: 5, valid_loss: 0.018249\n",
      "[TRAIN]: FOLD: 4, EPOCH: 6, LR: 0.009042, train_loss: 0.020181\n",
      "[>>VAL]: FOLD: 4, EPOCH: 6, valid_loss: 0.018118\n",
      "[TRAIN]: FOLD: 4, EPOCH: 7, LR: 0.008593, train_loss: 0.020210\n",
      "[>>VAL]: FOLD: 4, EPOCH: 7, valid_loss: 0.018180\n",
      "[TRAIN]: FOLD: 4, EPOCH: 8, LR: 0.008075, train_loss: 0.020194\n",
      "[>>VAL]: FOLD: 4, EPOCH: 8, valid_loss: 0.018049\n",
      "[TRAIN]: FOLD: 4, EPOCH: 9, LR: 0.007496, train_loss: 0.020180\n",
      "[>>VAL]: FOLD: 4, EPOCH: 9, valid_loss: 0.018134\n",
      "[TRAIN]: FOLD: 4, EPOCH: 10, LR: 0.006869, train_loss: 0.020141\n",
      "[>>VAL]: FOLD: 4, EPOCH: 10, valid_loss: 0.018612\n",
      "[TRAIN]: FOLD: 4, EPOCH: 11, LR: 0.006205, train_loss: 0.020170\n",
      "[>>VAL]: FOLD: 4, EPOCH: 11, valid_loss: 0.017973\n",
      "[TRAIN]: FOLD: 4, EPOCH: 12, LR: 0.005518, train_loss: 0.020007\n",
      "[>>VAL]: FOLD: 4, EPOCH: 12, valid_loss: 0.017855\n",
      "[TRAIN]: FOLD: 4, EPOCH: 13, LR: 0.004821, train_loss: 0.020011\n",
      "[>>VAL]: FOLD: 4, EPOCH: 13, valid_loss: 0.018059\n",
      "[TRAIN]: FOLD: 4, EPOCH: 14, LR: 0.004127, train_loss: 0.019828\n",
      "[>>VAL]: FOLD: 4, EPOCH: 14, valid_loss: 0.017936\n",
      "[TRAIN]: FOLD: 4, EPOCH: 15, LR: 0.003450, train_loss: 0.019674\n",
      "[>>VAL]: FOLD: 4, EPOCH: 15, valid_loss: 0.017968\n",
      "[TRAIN]: FOLD: 4, EPOCH: 16, LR: 0.002804, train_loss: 0.019498\n",
      "[>>VAL]: FOLD: 4, EPOCH: 16, valid_loss: 0.017585\n",
      "[TRAIN]: FOLD: 4, EPOCH: 17, LR: 0.002200, train_loss: 0.019238\n",
      "[>>VAL]: FOLD: 4, EPOCH: 17, valid_loss: 0.017582\n",
      "[TRAIN]: FOLD: 4, EPOCH: 18, LR: 0.001651, train_loss: 0.018958\n",
      "[>>VAL]: FOLD: 4, EPOCH: 18, valid_loss: 0.017531\n",
      "[TRAIN]: FOLD: 4, EPOCH: 19, LR: 0.001167, train_loss: 0.018579\n",
      "[>>VAL]: FOLD: 4, EPOCH: 19, valid_loss: 0.017401\n",
      "[TRAIN]: FOLD: 4, EPOCH: 20, LR: 0.000757, train_loss: 0.018207\n",
      "[>>VAL]: FOLD: 4, EPOCH: 20, valid_loss: 0.017452\n",
      "[TRAIN]: FOLD: 4, EPOCH: 21, LR: 0.000430, train_loss: 0.017722\n",
      "[>>VAL]: FOLD: 4, EPOCH: 21, valid_loss: 0.017417\n",
      "[TRAIN]: FOLD: 4, EPOCH: 22, LR: 0.000192, train_loss: 0.017250\n",
      "[>>VAL]: FOLD: 4, EPOCH: 22, valid_loss: 0.017452\n",
      "[TRAIN]: FOLD: 4, EPOCH: 23, LR: 0.000048, train_loss: 0.016889\n",
      "[>>VAL]: FOLD: 4, EPOCH: 23, valid_loss: 0.017456\n",
      "[TRAIN]: FOLD: 4, EPOCH: 24, LR: 0.000000, train_loss: 0.016692\n",
      "[>>VAL]: FOLD: 4, EPOCH: 24, valid_loss: 0.017442\n",
      "[TRAIN]: FOLD: 5, EPOCH: 0, LR: 0.003478, train_loss: 0.474462\n",
      "[>>VAL]: FOLD: 5, EPOCH: 0, valid_loss: 0.026344\n",
      "[TRAIN]: FOLD: 5, EPOCH: 1, LR: 0.009066, train_loss: 0.023976\n",
      "[>>VAL]: FOLD: 5, EPOCH: 1, valid_loss: 0.019716\n",
      "[TRAIN]: FOLD: 5, EPOCH: 2, LR: 0.009987, train_loss: 0.021668\n",
      "[>>VAL]: FOLD: 5, EPOCH: 2, valid_loss: 0.018581\n",
      "[TRAIN]: FOLD: 5, EPOCH: 3, LR: 0.009890, train_loss: 0.020600\n",
      "[>>VAL]: FOLD: 5, EPOCH: 3, valid_loss: 0.018690\n",
      "[TRAIN]: FOLD: 5, EPOCH: 4, LR: 0.009697, train_loss: 0.020286\n",
      "[>>VAL]: FOLD: 5, EPOCH: 4, valid_loss: 0.018381\n",
      "[TRAIN]: FOLD: 5, EPOCH: 5, LR: 0.009412, train_loss: 0.020071\n",
      "[>>VAL]: FOLD: 5, EPOCH: 5, valid_loss: 0.018421\n",
      "[TRAIN]: FOLD: 5, EPOCH: 6, LR: 0.009042, train_loss: 0.020195\n",
      "[>>VAL]: FOLD: 5, EPOCH: 6, valid_loss: 0.018351\n",
      "[TRAIN]: FOLD: 5, EPOCH: 7, LR: 0.008593, train_loss: 0.020152\n",
      "[>>VAL]: FOLD: 5, EPOCH: 7, valid_loss: 0.018439\n",
      "[TRAIN]: FOLD: 5, EPOCH: 8, LR: 0.008075, train_loss: 0.020140\n",
      "[>>VAL]: FOLD: 5, EPOCH: 8, valid_loss: 0.018160\n",
      "[TRAIN]: FOLD: 5, EPOCH: 9, LR: 0.007496, train_loss: 0.020165\n",
      "[>>VAL]: FOLD: 5, EPOCH: 9, valid_loss: 0.018176\n",
      "[TRAIN]: FOLD: 5, EPOCH: 10, LR: 0.006869, train_loss: 0.020123\n",
      "[>>VAL]: FOLD: 5, EPOCH: 10, valid_loss: 0.018233\n",
      "[TRAIN]: FOLD: 5, EPOCH: 11, LR: 0.006205, train_loss: 0.020095\n",
      "[>>VAL]: FOLD: 5, EPOCH: 11, valid_loss: 0.018241\n",
      "[TRAIN]: FOLD: 5, EPOCH: 12, LR: 0.005518, train_loss: 0.019960\n",
      "[>>VAL]: FOLD: 5, EPOCH: 12, valid_loss: 0.018249\n",
      "[TRAIN]: FOLD: 5, EPOCH: 13, LR: 0.004821, train_loss: 0.019915\n",
      "[>>VAL]: FOLD: 5, EPOCH: 13, valid_loss: 0.017996\n",
      "[TRAIN]: FOLD: 5, EPOCH: 14, LR: 0.004127, train_loss: 0.019750\n",
      "[>>VAL]: FOLD: 5, EPOCH: 14, valid_loss: 0.018088\n",
      "[TRAIN]: FOLD: 5, EPOCH: 15, LR: 0.003450, train_loss: 0.019572\n",
      "[>>VAL]: FOLD: 5, EPOCH: 15, valid_loss: 0.017877\n",
      "[TRAIN]: FOLD: 5, EPOCH: 16, LR: 0.002804, train_loss: 0.019386\n",
      "[>>VAL]: FOLD: 5, EPOCH: 16, valid_loss: 0.018046\n",
      "[TRAIN]: FOLD: 5, EPOCH: 17, LR: 0.002200, train_loss: 0.019117\n",
      "[>>VAL]: FOLD: 5, EPOCH: 17, valid_loss: 0.018147\n",
      "[TRAIN]: FOLD: 5, EPOCH: 18, LR: 0.001651, train_loss: 0.018830\n",
      "[>>VAL]: FOLD: 5, EPOCH: 18, valid_loss: 0.017865\n",
      "[TRAIN]: FOLD: 5, EPOCH: 19, LR: 0.001167, train_loss: 0.018432\n",
      "[>>VAL]: FOLD: 5, EPOCH: 19, valid_loss: 0.017935\n",
      "[TRAIN]: FOLD: 5, EPOCH: 20, LR: 0.000757, train_loss: 0.017994\n",
      "[>>VAL]: FOLD: 5, EPOCH: 20, valid_loss: 0.017915\n",
      "[TRAIN]: FOLD: 5, EPOCH: 21, LR: 0.000430, train_loss: 0.017500\n",
      "[>>VAL]: FOLD: 5, EPOCH: 21, valid_loss: 0.017812\n",
      "[TRAIN]: FOLD: 5, EPOCH: 22, LR: 0.000192, train_loss: 0.016966\n",
      "[>>VAL]: FOLD: 5, EPOCH: 22, valid_loss: 0.017866\n",
      "[TRAIN]: FOLD: 5, EPOCH: 23, LR: 0.000048, train_loss: 0.016628\n",
      "[>>VAL]: FOLD: 5, EPOCH: 23, valid_loss: 0.017879\n",
      "[TRAIN]: FOLD: 5, EPOCH: 24, LR: 0.000000, train_loss: 0.016450\n",
      "[>>VAL]: FOLD: 5, EPOCH: 24, valid_loss: 0.017835\n",
      "[TRAIN]: FOLD: 6, EPOCH: 0, LR: 0.003478, train_loss: 0.474281\n",
      "[>>VAL]: FOLD: 6, EPOCH: 0, valid_loss: 0.024937\n",
      "[TRAIN]: FOLD: 6, EPOCH: 1, LR: 0.009066, train_loss: 0.023913\n",
      "[>>VAL]: FOLD: 6, EPOCH: 1, valid_loss: 0.019160\n",
      "[TRAIN]: FOLD: 6, EPOCH: 2, LR: 0.009987, train_loss: 0.021959\n",
      "[>>VAL]: FOLD: 6, EPOCH: 2, valid_loss: 0.017660\n",
      "[TRAIN]: FOLD: 6, EPOCH: 3, LR: 0.009890, train_loss: 0.020739\n",
      "[>>VAL]: FOLD: 6, EPOCH: 3, valid_loss: 0.017381\n",
      "[TRAIN]: FOLD: 6, EPOCH: 4, LR: 0.009697, train_loss: 0.020335\n",
      "[>>VAL]: FOLD: 6, EPOCH: 4, valid_loss: 0.018537\n",
      "[TRAIN]: FOLD: 6, EPOCH: 5, LR: 0.009413, train_loss: 0.020321\n",
      "[>>VAL]: FOLD: 6, EPOCH: 5, valid_loss: 0.017493\n",
      "[TRAIN]: FOLD: 6, EPOCH: 6, LR: 0.009042, train_loss: 0.020257\n",
      "[>>VAL]: FOLD: 6, EPOCH: 6, valid_loss: 0.017518\n",
      "[TRAIN]: FOLD: 6, EPOCH: 7, LR: 0.008593, train_loss: 0.020353\n",
      "[>>VAL]: FOLD: 6, EPOCH: 7, valid_loss: 0.017604\n",
      "[TRAIN]: FOLD: 6, EPOCH: 8, LR: 0.008075, train_loss: 0.020271\n",
      "[>>VAL]: FOLD: 6, EPOCH: 8, valid_loss: 0.017500\n",
      "[TRAIN]: FOLD: 6, EPOCH: 9, LR: 0.007496, train_loss: 0.020304\n",
      "[>>VAL]: FOLD: 6, EPOCH: 9, valid_loss: 0.017293\n",
      "[TRAIN]: FOLD: 6, EPOCH: 10, LR: 0.006869, train_loss: 0.020263\n",
      "[>>VAL]: FOLD: 6, EPOCH: 10, valid_loss: 0.017315\n",
      "[TRAIN]: FOLD: 6, EPOCH: 11, LR: 0.006205, train_loss: 0.020193\n",
      "[>>VAL]: FOLD: 6, EPOCH: 11, valid_loss: 0.017341\n",
      "[TRAIN]: FOLD: 6, EPOCH: 12, LR: 0.005518, train_loss: 0.020145\n",
      "[>>VAL]: FOLD: 6, EPOCH: 12, valid_loss: 0.017133\n",
      "[TRAIN]: FOLD: 6, EPOCH: 13, LR: 0.004821, train_loss: 0.020142\n",
      "[>>VAL]: FOLD: 6, EPOCH: 13, valid_loss: 0.017131\n",
      "[TRAIN]: FOLD: 6, EPOCH: 14, LR: 0.004127, train_loss: 0.019932\n",
      "[>>VAL]: FOLD: 6, EPOCH: 14, valid_loss: 0.017188\n",
      "[TRAIN]: FOLD: 6, EPOCH: 15, LR: 0.003450, train_loss: 0.019730\n",
      "[>>VAL]: FOLD: 6, EPOCH: 15, valid_loss: 0.016964\n",
      "[TRAIN]: FOLD: 6, EPOCH: 16, LR: 0.002804, train_loss: 0.019575\n",
      "[>>VAL]: FOLD: 6, EPOCH: 16, valid_loss: 0.016765\n",
      "[TRAIN]: FOLD: 6, EPOCH: 17, LR: 0.002200, train_loss: 0.019288\n",
      "[>>VAL]: FOLD: 6, EPOCH: 17, valid_loss: 0.016853\n",
      "[TRAIN]: FOLD: 6, EPOCH: 18, LR: 0.001651, train_loss: 0.019076\n",
      "[>>VAL]: FOLD: 6, EPOCH: 18, valid_loss: 0.016681\n",
      "[TRAIN]: FOLD: 6, EPOCH: 19, LR: 0.001167, train_loss: 0.018680\n",
      "[>>VAL]: FOLD: 6, EPOCH: 19, valid_loss: 0.016734\n",
      "[TRAIN]: FOLD: 6, EPOCH: 20, LR: 0.000757, train_loss: 0.018275\n",
      "[>>VAL]: FOLD: 6, EPOCH: 20, valid_loss: 0.016768\n",
      "[TRAIN]: FOLD: 6, EPOCH: 21, LR: 0.000430, train_loss: 0.017821\n",
      "[>>VAL]: FOLD: 6, EPOCH: 21, valid_loss: 0.016586\n",
      "[TRAIN]: FOLD: 6, EPOCH: 22, LR: 0.000192, train_loss: 0.017358\n",
      "[>>VAL]: FOLD: 6, EPOCH: 22, valid_loss: 0.016564\n",
      "[TRAIN]: FOLD: 6, EPOCH: 23, LR: 0.000048, train_loss: 0.017007\n",
      "[>>VAL]: FOLD: 6, EPOCH: 23, valid_loss: 0.016670\n",
      "[TRAIN]: FOLD: 6, EPOCH: 24, LR: 0.000000, train_loss: 0.016812\n",
      "[>>VAL]: FOLD: 6, EPOCH: 24, valid_loss: 0.016672\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0, 1, 2, 3, 4, 5, 6]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "# create cv folds\n",
    "cv_fold = create_folds(num_starts=len(SEED), num_splits=NFOLDS)\n",
    "folds = train.copy()\n",
    "print(cv_fold)\n",
    "\n",
    "for seed in SEED:\n",
    "    print(f\"\\n>> SEED: {seed}\\n\")\n",
    "    \n",
    "    folds['kfold'] = cv_fold[seed]\n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T04:28:29.603837Z",
     "iopub.status.busy": "2020-11-16T04:28:29.602760Z",
     "iopub.status.idle": "2020-11-16T04:28:30.741417Z",
     "shell.execute_reply": "2020-11-16T04:28:30.741872Z"
    },
    "papermill": {
     "duration": 1.611542,
     "end_time": "2020-11-16T04:28:30.742082",
     "exception": false,
     "start_time": "2020-11-16T04:28:29.130540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.015633752402519272\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T04:28:31.688542Z",
     "iopub.status.busy": "2020-11-16T04:28:31.687121Z",
     "iopub.status.idle": "2020-11-16T04:28:33.765635Z",
     "shell.execute_reply": "2020-11-16T04:28:33.764024Z"
    },
    "papermill": {
     "duration": 2.556573,
     "end_time": "2020-11-16T04:28:33.765826",
     "exception": false,
     "start_time": "2020-11-16T04:28:31.209253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 2121.853575,
   "end_time": "2020-11-16T04:28:35.675807",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-16T03:53:13.822232",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
